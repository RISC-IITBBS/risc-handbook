{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RISC Handbook Robotics in its long journey has inspired this handbook which is organized in four layers which includes mechanical system designing, electronics, machine automation and simulation.","title":"Home"},{"location":"#risc-handbook","text":"Robotics in its long journey has inspired this handbook which is organized in four layers which includes mechanical system designing, electronics, machine automation and simulation.","title":"RISC Handbook"},{"location":"about/","text":"About Us The Robotics and Intelligence Systems Club RISC , IIT Bhubaneswar is a group of robotics and technology enthusiasts who explore the world of technology, learn and make projects based on Robotics, Internet of Things (IoT), Machine Learning, Computer Simulations, etc. RISC is home to many of institutes robotics enthusiasts who spend a great chunk of their time in designing and prototyping robots which can perform any required task. RISC provides a platform for students to explore and learn about modern technology. We also organize regular workshops to inspire students across varied technical backgrounds to develop their ideas and expose them to the wonders of robotics. We are open to anyone with a general interest in engineering and who wants to explore robotics, so feel free to get in touch with us. The motto of this society is to encourage and guide the members to learn newer technologies and make projects through which they get experience to solve real-life problems, possibly establishing a foundation for the ones who are looking at robotics as a career. This handbook is part of an effort to provide an organised set of learning resources to make it easy for anyone to get started with the field of robotics. Robotics is a highly broad field that is expanding quickly while investigating novel and unusual ideas. Our current efforts are concentrated on adding more pertinent data and resources to the handbook, which now only contains topics relating to basic robotics. Any contributions or ideas you may have that could help us enhance or add new information to the manual are welcome and appreciated. Please don\u2019t hesitate to submit a issue or a PR to the repository.","title":"About Us"},{"location":"about/#about-us","text":"The Robotics and Intelligence Systems Club RISC , IIT Bhubaneswar is a group of robotics and technology enthusiasts who explore the world of technology, learn and make projects based on Robotics, Internet of Things (IoT), Machine Learning, Computer Simulations, etc. RISC is home to many of institutes robotics enthusiasts who spend a great chunk of their time in designing and prototyping robots which can perform any required task. RISC provides a platform for students to explore and learn about modern technology. We also organize regular workshops to inspire students across varied technical backgrounds to develop their ideas and expose them to the wonders of robotics. We are open to anyone with a general interest in engineering and who wants to explore robotics, so feel free to get in touch with us. The motto of this society is to encourage and guide the members to learn newer technologies and make projects through which they get experience to solve real-life problems, possibly establishing a foundation for the ones who are looking at robotics as a career. This handbook is part of an effort to provide an organised set of learning resources to make it easy for anyone to get started with the field of robotics. Robotics is a highly broad field that is expanding quickly while investigating novel and unusual ideas. Our current efforts are concentrated on adding more pertinent data and resources to the handbook, which now only contains topics relating to basic robotics. Any contributions or ideas you may have that could help us enhance or add new information to the manual are welcome and appreciated. Please don\u2019t hesitate to submit a issue or a PR to the repository.","title":"About Us"},{"location":"roadmap/","text":"A Beginners Guide to Robotics Robotics is actively engaged in the expanding problems of new developing sectors as it strives to reach the human frontier. The new generation of robots will increasingly interact, explore, and collaborate with humans, affecting people and their lives. The scientific endeavour of a half-century of robotic discoveries that created robotics as a contemporary scientific subject has resulted in the credible prospect of practical robots among humans. The field\u2019s vibrant expansion and robust growth over the previous decade has spurred our desire to innovate. Following materials are compiled to help you get started in this field. How to Begin? The most important thing for a novice is to begin learning a language since it opens up a world of possibilities in terms of projects to work on and activities to accomplish. Also bear in mind that after you\u2019ve mastered one language, learning another is pretty simple. Different languages offer different benefits and could be use for a particular purpose respectively. Python Python is also very popular due to its use in machine learning and also because it can be used to develop ROS packages. Resources Web Tutorial Youtube Tutorials C C is a important language whilst doing hands-on robotics.Arduino uses a wrapper around C.If the robotics device in question has limitations in memory, then standard C programming language is a better technology choice. Resources FreeCodeCamp Video Tutorials GeeksforGeeks Resources Beej\u2019s Guide Youtube Tutorial C++ The Arduino microcontroller uses a programming language based on C++. C++ allows interaction with low level hardware, and also real time performance. C and C++ are very mature programming languages. To ensure the best performance of a robot, it will be better to use C++. As the robotics is very dependent on the real time performance, C and C++ are the best options. Resources YouTube Tutorials GeeksforGeeks Resources Web Tutorial Elixir (for more advanced stuff) Elixir is a dynamic, concurrent, functional language designed for building scalable and maintainable applications. Resources Web Tutorial Youtube Tutorial Development Environment It\u2019s not as simple as entering into a text editor to write code. A compiler, external libraries, path environments, a terminal, version control, documentation, and other components are usually present. Don\u2019t worry if you don\u2019t understand what these terms signify; they collectively form your development environment. To begin, ensure that you are familiar with the following. Linux Operating System : The most well-known and widely used open source operating system is Linux. Linux is an operating system that lies beneath all of the other software on a computer, accepting requests from those programmes and transmitting them to the computer\u2019s hardware.One can use linux OS (either through ( dual booting | Youtube Tutorial ), virtual machine or WSL ) Linux Terminal : The Linux terminal is a text-based interface used to control a Linux computer. It\u2019s just one of the many tools provided to Linux users for accomplishing any given task, but it\u2019s widely considered the most efficient method available. YouTube Tutorial Git & Github : The Git version control system, as the name suggests, is a system that records all the modifications made to a file or set of data so that a specific version may be called up later if needed. The system makes sure that all the team members are working on the file\u2019s latest version, and everyone can work simultaneously on the same project. GitHub is a Git repository hosting service that provides a web-based graphical interface. YouTube Tutorial | Udemy Course Automation Robot Operating System (ROS) The Robot Operating System (ROS) is not an actual operating system, but a framework and set of tools that provide functionality of an operating system on a heterogeneous computer cluster. Its usefulness is not limited to robots, but the majority of tools provided are focused on working with peripheral hardware. Resources Check out these Youtube Videos( Link 1 | Link 2 ) ROS Tutorials FAQ :- ROS Answers Also refer this blog Path Planning Path planning is the process of determining a path or trajectory for a robot by avoiding obstacles or adhering to set dynamic or kinematic constraints. It\u2019s something we do instinctively as humans, but robots find it difficult, so we try to make them intelligent by using path planning algorithms. Path planning is essential in robot automation because most robots must plan a path. Even in the case of robotic arms, moving the end effector from one spatial coordinate to another necessitates the planning of a trajectory that the arm must follow. The constraints and dimensions for planning the path or trajectory are different from those used in ground robot planning. Resources Book Open Motion Planning Library (for implementation of algorithms in C/C++). GitHub Repository (in python) Simultaneous Localization and Mapping (SLAM) SLAM (simultaneous localization and mapping) is a method used for autonomous vehicles that lets you build a map and localize your vehicle in that map at the same time. SLAM algorithms allow the vehicle to map out unknown environments. Engineers use the map information to carry out tasks such as path planning and obstacle avoidance. Resources Autonomous Navigation - playlist by MATLAB Youtube Course Robot Perception Robot perception is undervalued by beginners due to a lack of understanding of the difficulties involved. It\u2019s difficult to imagine how difficult it would be for a robot to observe, analyse, and extract usable data from a three - dimensional environment, because we\u2019re used to picking and putting objects with extreme precision in front of us. It\u2019s simple for us to stroll without stumbling over a branch. However, robots face a much more difficult situation. This element of developing intelligent robots is addressed in Robot Perception. Resources CS521 Notes Checkout Depth Maps Blog The Robotics Institute Carnegie Mellon University paper. Sensors play an important role in any robotic task. High-quality Cameras, LiDARs etc are used. To get started with perception by using images, OpenCV is a good starting point. For perception using Point Clouds, Point Cloud Library is a good starting point(PCL can only be used via C++). There are many advancements that are taking place. With the advent of Neural Networks, Convolution Neural Networks(CNN\u2019s) are used to extract and analyse important information from depth maps thus enabling image and point cloud segmentation , classification tasks etc. Machine Learning / AI Much of the computer based tools we use follow the same principle - they are a collection of straightforward instructions for the computer to follow so that it can solve a task. Machine Learning on the other hand, is about how the computer can learn to solve a task from examples, much like we humans learn. Resources Courses Machine Learning - by Andrew NG Deep Learning - offered by DeepLearning.ai is a more advanced course by Andrew NG focusing on Deep Learning. Computer Vision (recommended to do this before the other two) Natural Language Processing Reinforcement Learning (also check out this book) Software Tools & Framework Numpy: Mathematics and Linear Algebra library for python. YouTube Tutorial | Documentation Matplotlib: Python library for plotting. YouTube Tutorial | Documentation SciKitLearn: Machine Learning toolkit in python. YouTube Tutorial | Documentation OpenCV: Computer vision toolkit YouTube Tutorial | Documentation Pytorch: Deep Learning framework YouTube Tutorial | Documentation Tensorflow: Deep Learning framework YouTube Tutorial | Documentation Control Systems Control systems aid in regulating the robot\u2019s actions and movements. Because the dynamics change over time, we require controllers. When the robot goes first on smooth concrete, then on carpeted flooring, or when it walks up a slope, then down it. Therefore, creating a good controller requires physical modelling of the system. A controller receives a reference state from us. The controller also has sensor feedback, and it uses both to generate the control signal necessary to get to the reference state. The System receives this control signal. How the system responds to this control input is determined by the system dynamics. Hopefully, the System will reach our intended reference state if the controller is effective. Resources Control of Mobile Robots - course by Magnus Egerstedt (Georgia Tech) Understanding PID Control - Playlist by MATLAB explains PID control in detail. Linear-Quadratic Regulator - by MATLAB explains about LQR Model Predictive Control - by Lasse Peters is well explained. Practical Control Systems - Playlist by MATLAB State Space - Playlist by MATLAB teaches State space equations, pole placement and concepts like controllability and is important for learning math behind Control Theory. Electronics The electronics system of a robot is made up of sensors and actuators that are interfaced with the microcontroller using drivers. Interfacing is done with basic electronics components like as wires, resistors, and capacitors, and the whole assembly is installed on a breadboard, prototyping board, or printed circuit board (PCB).Single board computers (SBC) are used for advanced functioning. Single Board Computers A single-board computer (SBC) is a complete computer built on a single circuit board, with microprocessor(s), memory, input/output (I/O) and other features required of a functional computer. Single-board computers are commonly made as demonstration or development systems, for educational systems, or for use as embedded computer controllers. Rasberry pi is good to start with. Microcontrollers Arduino is a low cost, open source and easy to learn microcontroller. The syntax used to program Arduino is similar to that of C/C++ and a software called Arduino IDE is used to program it. The Arduino IDE is open source software which is written in Java and will work on a variety of platforms: Windows, Mac, and Linux. The IDE enables you to write code in a special environment with syntax highlighting and other features which will make coding easier, and then easily load your code onto the device with a simple click of a button. Resources Web Tutorials Youtube Tutorial TinkedCad (for online simulation) Sensors A sensor monitors environmental conditions such as fluid levels, temperatures, vibrations, or voltage. When these environmental conditions change, they send an electrical signal to the sensor, which can then send the data or an alert back to a centralized computer system or adjust the functioning of a particular piece of equipment. Ex. wheel encoders, temperature sensors, depth cameras (Kinect), LiDARs, Ultrasonic sensors, etc. Actuators An actuator, on the other hand, causes movement. It takes an electrical signal and combines it with an energy source to create physical motion. An actuator may be pneumatic, hydraulic, electric, thermal, or magnetic. Ex. Motors (DC, Stepper, Servo, BLDC),Linear Actuators (Solenoid or a linear servo), etc. PCB Designing easyEDA is good to start with. One could follow official tutorial for better understanding. Youtube Tutorial Mechanical Designing CAD SOLIDWORKS is a major CAD tool used to develop mechatronics systems from beginning to end. At the initial stage, the software is used for planning, visual ideation, modeling, feasibility assessment, prototyping, and project management. The software is then used for design and building of mechanical, electrical, and software elements. Finally, the software can be used for management, including device management, analytics, data automation, and cloud services.","title":"Roadmap"},{"location":"roadmap/#a-beginners-guide-to-robotics","text":"Robotics is actively engaged in the expanding problems of new developing sectors as it strives to reach the human frontier. The new generation of robots will increasingly interact, explore, and collaborate with humans, affecting people and their lives. The scientific endeavour of a half-century of robotic discoveries that created robotics as a contemporary scientific subject has resulted in the credible prospect of practical robots among humans. The field\u2019s vibrant expansion and robust growth over the previous decade has spurred our desire to innovate. Following materials are compiled to help you get started in this field.","title":"A Beginners Guide to Robotics"},{"location":"roadmap/#how-to-begin","text":"The most important thing for a novice is to begin learning a language since it opens up a world of possibilities in terms of projects to work on and activities to accomplish. Also bear in mind that after you\u2019ve mastered one language, learning another is pretty simple. Different languages offer different benefits and could be use for a particular purpose respectively.","title":"How to Begin?"},{"location":"roadmap/#python","text":"Python is also very popular due to its use in machine learning and also because it can be used to develop ROS packages. Resources Web Tutorial Youtube Tutorials","title":"Python"},{"location":"roadmap/#c","text":"C is a important language whilst doing hands-on robotics.Arduino uses a wrapper around C.If the robotics device in question has limitations in memory, then standard C programming language is a better technology choice. Resources FreeCodeCamp Video Tutorials GeeksforGeeks Resources Beej\u2019s Guide Youtube Tutorial","title":"C"},{"location":"roadmap/#c_1","text":"The Arduino microcontroller uses a programming language based on C++. C++ allows interaction with low level hardware, and also real time performance. C and C++ are very mature programming languages. To ensure the best performance of a robot, it will be better to use C++. As the robotics is very dependent on the real time performance, C and C++ are the best options. Resources YouTube Tutorials GeeksforGeeks Resources Web Tutorial","title":"C++"},{"location":"roadmap/#elixir","text":"(for more advanced stuff) Elixir is a dynamic, concurrent, functional language designed for building scalable and maintainable applications. Resources Web Tutorial Youtube Tutorial","title":"Elixir"},{"location":"roadmap/#development-environment","text":"It\u2019s not as simple as entering into a text editor to write code. A compiler, external libraries, path environments, a terminal, version control, documentation, and other components are usually present. Don\u2019t worry if you don\u2019t understand what these terms signify; they collectively form your development environment. To begin, ensure that you are familiar with the following. Linux Operating System : The most well-known and widely used open source operating system is Linux. Linux is an operating system that lies beneath all of the other software on a computer, accepting requests from those programmes and transmitting them to the computer\u2019s hardware.One can use linux OS (either through ( dual booting | Youtube Tutorial ), virtual machine or WSL ) Linux Terminal : The Linux terminal is a text-based interface used to control a Linux computer. It\u2019s just one of the many tools provided to Linux users for accomplishing any given task, but it\u2019s widely considered the most efficient method available. YouTube Tutorial Git & Github : The Git version control system, as the name suggests, is a system that records all the modifications made to a file or set of data so that a specific version may be called up later if needed. The system makes sure that all the team members are working on the file\u2019s latest version, and everyone can work simultaneously on the same project. GitHub is a Git repository hosting service that provides a web-based graphical interface. YouTube Tutorial | Udemy Course","title":"Development Environment"},{"location":"roadmap/#automation","text":"","title":"Automation"},{"location":"roadmap/#robot-operating-system-ros","text":"The Robot Operating System (ROS) is not an actual operating system, but a framework and set of tools that provide functionality of an operating system on a heterogeneous computer cluster. Its usefulness is not limited to robots, but the majority of tools provided are focused on working with peripheral hardware. Resources Check out these Youtube Videos( Link 1 | Link 2 ) ROS Tutorials FAQ :- ROS Answers Also refer this blog","title":"Robot Operating System (ROS)"},{"location":"roadmap/#path-planning","text":"Path planning is the process of determining a path or trajectory for a robot by avoiding obstacles or adhering to set dynamic or kinematic constraints. It\u2019s something we do instinctively as humans, but robots find it difficult, so we try to make them intelligent by using path planning algorithms. Path planning is essential in robot automation because most robots must plan a path. Even in the case of robotic arms, moving the end effector from one spatial coordinate to another necessitates the planning of a trajectory that the arm must follow. The constraints and dimensions for planning the path or trajectory are different from those used in ground robot planning. Resources Book Open Motion Planning Library (for implementation of algorithms in C/C++). GitHub Repository (in python)","title":"Path Planning"},{"location":"roadmap/#simultaneous-localization-and-mapping-slam","text":"SLAM (simultaneous localization and mapping) is a method used for autonomous vehicles that lets you build a map and localize your vehicle in that map at the same time. SLAM algorithms allow the vehicle to map out unknown environments. Engineers use the map information to carry out tasks such as path planning and obstacle avoidance. Resources Autonomous Navigation - playlist by MATLAB Youtube Course","title":"Simultaneous Localization and Mapping (SLAM)"},{"location":"roadmap/#robot-perception","text":"Robot perception is undervalued by beginners due to a lack of understanding of the difficulties involved. It\u2019s difficult to imagine how difficult it would be for a robot to observe, analyse, and extract usable data from a three - dimensional environment, because we\u2019re used to picking and putting objects with extreme precision in front of us. It\u2019s simple for us to stroll without stumbling over a branch. However, robots face a much more difficult situation. This element of developing intelligent robots is addressed in Robot Perception. Resources CS521 Notes Checkout Depth Maps Blog The Robotics Institute Carnegie Mellon University paper. Sensors play an important role in any robotic task. High-quality Cameras, LiDARs etc are used. To get started with perception by using images, OpenCV is a good starting point. For perception using Point Clouds, Point Cloud Library is a good starting point(PCL can only be used via C++). There are many advancements that are taking place. With the advent of Neural Networks, Convolution Neural Networks(CNN\u2019s) are used to extract and analyse important information from depth maps thus enabling image and point cloud segmentation , classification tasks etc.","title":"Robot Perception"},{"location":"roadmap/#machine-learning-ai","text":"Much of the computer based tools we use follow the same principle - they are a collection of straightforward instructions for the computer to follow so that it can solve a task. Machine Learning on the other hand, is about how the computer can learn to solve a task from examples, much like we humans learn. Resources Courses Machine Learning - by Andrew NG Deep Learning - offered by DeepLearning.ai is a more advanced course by Andrew NG focusing on Deep Learning. Computer Vision (recommended to do this before the other two) Natural Language Processing Reinforcement Learning (also check out this book) Software Tools & Framework Numpy: Mathematics and Linear Algebra library for python. YouTube Tutorial | Documentation Matplotlib: Python library for plotting. YouTube Tutorial | Documentation SciKitLearn: Machine Learning toolkit in python. YouTube Tutorial | Documentation OpenCV: Computer vision toolkit YouTube Tutorial | Documentation Pytorch: Deep Learning framework YouTube Tutorial | Documentation Tensorflow: Deep Learning framework YouTube Tutorial | Documentation","title":"Machine Learning / AI"},{"location":"roadmap/#control-systems","text":"Control systems aid in regulating the robot\u2019s actions and movements. Because the dynamics change over time, we require controllers. When the robot goes first on smooth concrete, then on carpeted flooring, or when it walks up a slope, then down it. Therefore, creating a good controller requires physical modelling of the system. A controller receives a reference state from us. The controller also has sensor feedback, and it uses both to generate the control signal necessary to get to the reference state. The System receives this control signal. How the system responds to this control input is determined by the system dynamics. Hopefully, the System will reach our intended reference state if the controller is effective. Resources Control of Mobile Robots - course by Magnus Egerstedt (Georgia Tech) Understanding PID Control - Playlist by MATLAB explains PID control in detail. Linear-Quadratic Regulator - by MATLAB explains about LQR Model Predictive Control - by Lasse Peters is well explained. Practical Control Systems - Playlist by MATLAB State Space - Playlist by MATLAB teaches State space equations, pole placement and concepts like controllability and is important for learning math behind Control Theory.","title":"Control Systems"},{"location":"roadmap/#electronics","text":"The electronics system of a robot is made up of sensors and actuators that are interfaced with the microcontroller using drivers. Interfacing is done with basic electronics components like as wires, resistors, and capacitors, and the whole assembly is installed on a breadboard, prototyping board, or printed circuit board (PCB).Single board computers (SBC) are used for advanced functioning.","title":"Electronics"},{"location":"roadmap/#single-board-computers","text":"A single-board computer (SBC) is a complete computer built on a single circuit board, with microprocessor(s), memory, input/output (I/O) and other features required of a functional computer. Single-board computers are commonly made as demonstration or development systems, for educational systems, or for use as embedded computer controllers. Rasberry pi is good to start with.","title":"Single Board Computers"},{"location":"roadmap/#microcontrollers","text":"Arduino is a low cost, open source and easy to learn microcontroller. The syntax used to program Arduino is similar to that of C/C++ and a software called Arduino IDE is used to program it. The Arduino IDE is open source software which is written in Java and will work on a variety of platforms: Windows, Mac, and Linux. The IDE enables you to write code in a special environment with syntax highlighting and other features which will make coding easier, and then easily load your code onto the device with a simple click of a button. Resources Web Tutorials Youtube Tutorial TinkedCad (for online simulation)","title":"Microcontrollers"},{"location":"roadmap/#sensors","text":"A sensor monitors environmental conditions such as fluid levels, temperatures, vibrations, or voltage. When these environmental conditions change, they send an electrical signal to the sensor, which can then send the data or an alert back to a centralized computer system or adjust the functioning of a particular piece of equipment. Ex. wheel encoders, temperature sensors, depth cameras (Kinect), LiDARs, Ultrasonic sensors, etc.","title":"Sensors"},{"location":"roadmap/#actuators","text":"An actuator, on the other hand, causes movement. It takes an electrical signal and combines it with an energy source to create physical motion. An actuator may be pneumatic, hydraulic, electric, thermal, or magnetic. Ex. Motors (DC, Stepper, Servo, BLDC),Linear Actuators (Solenoid or a linear servo), etc.","title":"Actuators"},{"location":"roadmap/#pcb-designing","text":"easyEDA is good to start with. One could follow official tutorial for better understanding. Youtube Tutorial","title":"PCB Designing"},{"location":"roadmap/#mechanical-designing","text":"","title":"Mechanical Designing"},{"location":"roadmap/#cad","text":"SOLIDWORKS is a major CAD tool used to develop mechatronics systems from beginning to end. At the initial stage, the software is used for planning, visual ideation, modeling, feasibility assessment, prototyping, and project management. The software is then used for design and building of mechanical, electrical, and software elements. Finally, the software can be used for management, including device management, analytics, data automation, and cloud services.","title":"CAD"},{"location":"automation/intro/","text":"Introduction Without the capacity to accomplish things on their own, robots would be quite worthless. Robots are on their approach to becoming totally autonomous today, thanks to ever more advanced machine learning algorithms. Planning, Controls, and State Estimation comprises Automation. We must plan our actions from the minute we get up in the morning until our heads hit the pillow at night. A major challenge in developing autonomous robots is figuring out how to give them the ability to make their own decisions in a range of settings. The computational process of travelling from one location to another in the presence of barriers is known as motion planning. A robot\u2019s movements and sensory processing are controlled by the Robot control system.We require robot controllers since the dynamics (system plant) change over time. For example, when the robot travels up and down a slope, or when it travels on smooth concrete before moving to a carpeted floor. Estimating a robot\u2019s state, such as location and orientation, as it moves around the world is a fundamental part of robotics today. To locate themselves in a three-dimensional world, most robots and autonomous vehicles rely on noisy data from sensors such as cameras or laser rangefinders, or a combination of these.","title":"Introduction"},{"location":"automation/intro/#introduction","text":"Without the capacity to accomplish things on their own, robots would be quite worthless. Robots are on their approach to becoming totally autonomous today, thanks to ever more advanced machine learning algorithms. Planning, Controls, and State Estimation comprises Automation. We must plan our actions from the minute we get up in the morning until our heads hit the pillow at night. A major challenge in developing autonomous robots is figuring out how to give them the ability to make their own decisions in a range of settings. The computational process of travelling from one location to another in the presence of barriers is known as motion planning. A robot\u2019s movements and sensory processing are controlled by the Robot control system.We require robot controllers since the dynamics (system plant) change over time. For example, when the robot travels up and down a slope, or when it travels on smooth concrete before moving to a carpeted floor. Estimating a robot\u2019s state, such as location and orientation, as it moves around the world is a fundamental part of robotics today. To locate themselves in a three-dimensional world, most robots and autonomous vehicles rely on noisy data from sensors such as cameras or laser rangefinders, or a combination of these.","title":"Introduction"},{"location":"automation/ControlTheory/Control_Theory/","text":"Control Theory A robot can exhibit a number of different behaviors, depending on the task and its environment. It can act as a source of programmed motions for tasks such as moving an object from one place to another or tracing a trajectory. It can act as a source of forces, as when applying a polishing wheel to a workpiece. In tasks such as writing on a chalkboard, it must control forces in some directions (the force must press the chalk against the board) and motions in others (the motion must be in the plane of the board). When the purpose of the robot is to act as a haptic display, rendering a virtual environment, we may want it to act like a spring, damper, or mass, yielding in response to forces applied to it. In each of these cases, it is the job of the robot controller to convert the task specification to forces and torques at the actuators. Control strategies that achieve the behaviors described above are known as motion control , force control , hybrid motion-force control , or impedance control . A typical control block diagram is shown above The sensors are typically: potentiometers, encoders, or resolvers for joint position and angle sensing; tachometers for joint velocity sensing; joint force-torque sensors; and/or multi-axis force-torque sensors. Types of control systems Open Loop control system A control system in which the control action is totally independent of output of the system then it is called open loop control system . A manual control system is also an open loop control system. The figure below shows a control system block diagram of an open loop control system in which process output is totally independent of the controller action. Practical examples of Open loop control system: Electric Hand Drier \u2013 Hot air (output) comes out as long as you keep your hand under the machine, irrespective of how much your hand is dried. Automatic Washing Machine \u2013 This machine runs according to the pre-set time irrespective of washing is completed or not. Bread Toaster \u2013 This machine runs as per adjusted time irrespective of toasting is completed or not. Closed Loop control system Control system in which the output has an effect on the input quantity in such a manner that the input quantity will adjust itself based on the output generated is called closed loop control system . Open loop control system can be converted in to closed loop control system by providing a feedback. Figure below shows the block diagram of closed loop control system in which feedback is taken from output and fed in to input. Practical example of Closed loop control system: Missile Launched and Auto Tracked by Radar \u2013 The direction of missile is controlled by comparing the target and position of the missile. An Air Conditioner \u2013 An air conditioner functions depending upon the temperature of the room. Cooling System in Car \u2013 It operates depending upon the temperature which it controls. Core topics in Control Theory Before we design any controller, we have to consider the key factors that will drive the robot and how are we supposed to build the controller that will drive us to the best results which are also known as control objectives . These factors are listed below: 1. Stability : By this, we mean to measure the level of stability in the signal which will drive the object and also keep a check on the fluctuation of the signal. For eg. if we are making a cruise controller for a car, then the controller should give a stable signal after the car has reached the cruising speed and the speed should remain constant (no fluctuations). 2. Tracking : It is necessary to give controls after analyzing the response given due to the input signal. For instance, in a cruise controller, after setting up cruising speed, it is necessary for the controller to keep a regular check on the speed by which it can decide whether to accelerate or retard. 3. Robustness : Robust control systems often incorporate advanced topologies which include multiple feedback loops and feed-forward paths. The control laws may be represented by high order transfer functions required to simultaneously accomplish desired disturbance rejection performance with robust closed loop operation. For example, the controller should not be hard coded to function only for a certain velocity ,say 50 miles/hour if designing a cruise control. 4. Disturbance : It refers to the noise (not useful signal) that the controller might signal while sending or any sort of attenuation that can happen. It actually depends on the quality of instruments used in making a controller and also due to some external factors. 5. Optimality : It is a set of differential equations that describe the paths of the control variables that minimize the cost function. Laplace transform The Laplace transform plays a important role in control theory. It appears in the description of linear time invariant systems, where it changes convolution operators into multiplication operators and allows to define the transfer function of a system. The properties of systems can be then translated into properties of the transfer function. It allows the use of graphical methods to predict system performance without solving the differential equations of the system. These include response, steady state behavior, and transient behavior. Laplace Vs Fourier transform Laplace transform: \\(F(s)=\\int_{0}^{\\infty}f(t)e^{-st}dt \\qquad f^{'}(t)\\Rightarrow sF(s)\\) Fourier transform: \\(F(\\omega) = \\int_{-\\infty}^{\\infty}f(t)e^{-j\\omega t}dt\\) Laplace transforms often depend on the initial value of the function whereas Fourier transforms are independent of the initial value. The transforms are only the same if the function is the same both sides of the y-axis (so the unit step function is different). To understand Laplace transform in detail read this article Closed Loop Transfer Function A closed-loop transfer function in control theory is a mathematical expression describing the net result of the effects of a closed feedback loop on the input signal to the circuits enclosed by the loop. Where: block G represents the open-loop gains of the controller or system and is the forward path, and block H represents the gain of the sensor, transducer or measurement system in the feedback path. To find the transfer function of the closed-loop system above, we must first calculate the output signal \u03b8 o in terms of the input signal \u03b8 i . To do so, we can easily write the equations of the given block-diagram as follows. The output from the system is equal to: Output = G x Error Note that the error signal, \u03b8 e is also the input to the feed-forward block: G The output from the summing point is equal to: Error = Input - H x Output If H = 1 (unity feedback) then: The output from the summing point will be: Error (\u03b8 e ) = Input - Output Eliminating the error term, then: The output is equal to: Output = G x (Input - H x Output) Therefore: G x Input = Output + G x H x Output Rearranging the above gives us the closed-loop transfer function of: Controllability Types of Feedback Control Positive Feedback In a \u201cpositive feedback control system\u201d, the set point and output values are added together by the controller as the feedback is \u201cin-phase\u201d with the input. The effect of positive (or regenerative) feedback is to \u201cincrease\u201d the systems gain, i.e, the overall gain with positive feedback applied will be greater than the gain without feedback] Negative Feedback In a \u201cnegative feedback control system\u201d, the set point and output values are subtracted from each other as the feedback is \u201cout-of-phase\u201d with the original input. The effect of negative (or degenerative) feedback is to \u201creduce\u201d the gain. As a rule negative feedback systems are more stable than positive feedback systems. Negative feedback also makes systems more immune to random variations in component values and inputs. To know more about different types of control systems you can read this article.","title":"Introduction to Control Theory"},{"location":"automation/ControlTheory/Control_Theory/#control-theory","text":"A robot can exhibit a number of different behaviors, depending on the task and its environment. It can act as a source of programmed motions for tasks such as moving an object from one place to another or tracing a trajectory. It can act as a source of forces, as when applying a polishing wheel to a workpiece. In tasks such as writing on a chalkboard, it must control forces in some directions (the force must press the chalk against the board) and motions in others (the motion must be in the plane of the board). When the purpose of the robot is to act as a haptic display, rendering a virtual environment, we may want it to act like a spring, damper, or mass, yielding in response to forces applied to it. In each of these cases, it is the job of the robot controller to convert the task specification to forces and torques at the actuators. Control strategies that achieve the behaviors described above are known as motion control , force control , hybrid motion-force control , or impedance control . A typical control block diagram is shown above The sensors are typically: potentiometers, encoders, or resolvers for joint position and angle sensing; tachometers for joint velocity sensing; joint force-torque sensors; and/or multi-axis force-torque sensors.","title":"Control Theory"},{"location":"automation/ControlTheory/Control_Theory/#types-of-control-systems","text":"","title":"Types of control systems"},{"location":"automation/ControlTheory/Control_Theory/#open-loop-control-system","text":"A control system in which the control action is totally independent of output of the system then it is called open loop control system . A manual control system is also an open loop control system. The figure below shows a control system block diagram of an open loop control system in which process output is totally independent of the controller action. Practical examples of Open loop control system: Electric Hand Drier \u2013 Hot air (output) comes out as long as you keep your hand under the machine, irrespective of how much your hand is dried. Automatic Washing Machine \u2013 This machine runs according to the pre-set time irrespective of washing is completed or not. Bread Toaster \u2013 This machine runs as per adjusted time irrespective of toasting is completed or not.","title":"Open Loop control system"},{"location":"automation/ControlTheory/Control_Theory/#closed-loop-control-system","text":"Control system in which the output has an effect on the input quantity in such a manner that the input quantity will adjust itself based on the output generated is called closed loop control system . Open loop control system can be converted in to closed loop control system by providing a feedback. Figure below shows the block diagram of closed loop control system in which feedback is taken from output and fed in to input. Practical example of Closed loop control system: Missile Launched and Auto Tracked by Radar \u2013 The direction of missile is controlled by comparing the target and position of the missile. An Air Conditioner \u2013 An air conditioner functions depending upon the temperature of the room. Cooling System in Car \u2013 It operates depending upon the temperature which it controls.","title":"Closed Loop control system"},{"location":"automation/ControlTheory/Control_Theory/#core-topics-in-control-theory","text":"Before we design any controller, we have to consider the key factors that will drive the robot and how are we supposed to build the controller that will drive us to the best results which are also known as control objectives . These factors are listed below: 1. Stability : By this, we mean to measure the level of stability in the signal which will drive the object and also keep a check on the fluctuation of the signal. For eg. if we are making a cruise controller for a car, then the controller should give a stable signal after the car has reached the cruising speed and the speed should remain constant (no fluctuations). 2. Tracking : It is necessary to give controls after analyzing the response given due to the input signal. For instance, in a cruise controller, after setting up cruising speed, it is necessary for the controller to keep a regular check on the speed by which it can decide whether to accelerate or retard. 3. Robustness : Robust control systems often incorporate advanced topologies which include multiple feedback loops and feed-forward paths. The control laws may be represented by high order transfer functions required to simultaneously accomplish desired disturbance rejection performance with robust closed loop operation. For example, the controller should not be hard coded to function only for a certain velocity ,say 50 miles/hour if designing a cruise control. 4. Disturbance : It refers to the noise (not useful signal) that the controller might signal while sending or any sort of attenuation that can happen. It actually depends on the quality of instruments used in making a controller and also due to some external factors. 5. Optimality : It is a set of differential equations that describe the paths of the control variables that minimize the cost function.","title":"Core topics in Control Theory"},{"location":"automation/ControlTheory/Control_Theory/#laplace-transform","text":"The Laplace transform plays a important role in control theory. It appears in the description of linear time invariant systems, where it changes convolution operators into multiplication operators and allows to define the transfer function of a system. The properties of systems can be then translated into properties of the transfer function. It allows the use of graphical methods to predict system performance without solving the differential equations of the system. These include response, steady state behavior, and transient behavior.","title":"Laplace transform"},{"location":"automation/ControlTheory/Control_Theory/#laplace-vs-fourier-transform","text":"Laplace transform: \\(F(s)=\\int_{0}^{\\infty}f(t)e^{-st}dt \\qquad f^{'}(t)\\Rightarrow sF(s)\\) Fourier transform: \\(F(\\omega) = \\int_{-\\infty}^{\\infty}f(t)e^{-j\\omega t}dt\\) Laplace transforms often depend on the initial value of the function whereas Fourier transforms are independent of the initial value. The transforms are only the same if the function is the same both sides of the y-axis (so the unit step function is different). To understand Laplace transform in detail read this article","title":"Laplace Vs Fourier transform"},{"location":"automation/ControlTheory/Control_Theory/#closed-loop-transfer-function","text":"A closed-loop transfer function in control theory is a mathematical expression describing the net result of the effects of a closed feedback loop on the input signal to the circuits enclosed by the loop. Where: block G represents the open-loop gains of the controller or system and is the forward path, and block H represents the gain of the sensor, transducer or measurement system in the feedback path. To find the transfer function of the closed-loop system above, we must first calculate the output signal \u03b8 o in terms of the input signal \u03b8 i . To do so, we can easily write the equations of the given block-diagram as follows. The output from the system is equal to: Output = G x Error Note that the error signal, \u03b8 e is also the input to the feed-forward block: G The output from the summing point is equal to: Error = Input - H x Output If H = 1 (unity feedback) then: The output from the summing point will be: Error (\u03b8 e ) = Input - Output Eliminating the error term, then: The output is equal to: Output = G x (Input - H x Output) Therefore: G x Input = Output + G x H x Output Rearranging the above gives us the closed-loop transfer function of:","title":"Closed Loop Transfer Function"},{"location":"automation/ControlTheory/Control_Theory/#controllability","text":"","title":"Controllability"},{"location":"automation/ControlTheory/Control_Theory/#types-of-feedback-control","text":"","title":"Types of Feedback Control"},{"location":"automation/ControlTheory/Control_Theory/#positive-feedback","text":"In a \u201cpositive feedback control system\u201d, the set point and output values are added together by the controller as the feedback is \u201cin-phase\u201d with the input. The effect of positive (or regenerative) feedback is to \u201cincrease\u201d the systems gain, i.e, the overall gain with positive feedback applied will be greater than the gain without feedback]","title":"Positive Feedback"},{"location":"automation/ControlTheory/Control_Theory/#negative-feedback","text":"In a \u201cnegative feedback control system\u201d, the set point and output values are subtracted from each other as the feedback is \u201cout-of-phase\u201d with the original input. The effect of negative (or degenerative) feedback is to \u201creduce\u201d the gain. As a rule negative feedback systems are more stable than positive feedback systems. Negative feedback also makes systems more immune to random variations in component values and inputs. To know more about different types of control systems you can read this article.","title":"Negative Feedback"},{"location":"automation/ControlTheory/LQR/","text":"Linear-Quadratic Regulator(LQR) Controller The theory of optimal control is concerned with operating a dynamic system at minimum cost. The case where the system dynamics are described by a set of linear differential equations and the cost is described by a quadratic function is called the LQ problem. One of the main results in the theory is that the solution is provided by the linear\u2013quadratic regulator ( LQR ). The settings of a (regulating) controller governing either a machine or process (like an airplane or chemical reactor) are found by using a mathematical algorithm that minimizes a cost function with weighting factors needed to be supplied. A cost function is a function that maps an event or values of one or more variables onto a real number intuitively representing some \u201ccost\u201d associated with the event. The cost function is often defined as a sum of the deviations of key measurements, like altitude or process temperature, from their desired values. The algorithm thus finds those controller settings that minimize undesired deviations. The magnitude of the control action itself may also be included in the cost function. Finite horizon LQR For a continuous-time linear system, defined on \\(t \\epsilon [t_0,t_1]\\) , described by: \\(\\dot{x} = Ax + Bu\\) with a quadratic cost function defined as: \\(J = x^T (t_1)F(t_1)x(t_1) + \\int_{t_0}^{t_1} (x^TQx + u^TRu + 2x^TNu) \\,dt\\) the feedback control law that minimizes the value of the cost is: \\(u = -Kx\\) where K is given by: \\(K = R^{-1}(B^TP(t) + N^t)\\) and P is found by solving the continuous time Riccati differential equation : \\(A^TP(t) + P(t)A - (P(t)B+N)R^{-1}(B^TP(t) + N^T) + Q = - \\dot{P}(t)\\) with the boundary condition: \\(P(t_1)=F(t_1)\\) To learn more in detail about LQR controller watch this video by Steve Brunton Linear Quadratic Gaussian (LQG) control theory Here, Given a linear model of the plant in a statespace description, and assuming that the disturbance and measurement noise are Gaussian stochastic processes with known power spectral densities, the designer translates the design specifications into a quadratic performance criterion consisting of some state variables and control signal inputs. The object of design then is to minimize the performance criterion by using appropriate state or measurement feedback controllers while guaranteeing the closed-loop stability. When LQG controller problem is solved in a deterministic setting, known as an H 2 optimal control problem, in which the H 2 norm of a certain transfer function from an exogenous disturbance to a pertinent controlled output of a given plant is minimized by appropriate use of an internally stabilizing controller. To learn about robust controllers and LQG control problem in detail watch this video H\u221e (i.e. \u201c H-infinity \u201d) methods are used in control theory to synthesize controllers to achieve stabilization with guaranteed performance. To use H \u221e methods, a control designer expresses the control problem as a mathematical optimization problem and then finds the controller that solves this optimization. H \u221e techniques have the advantage over classical control techniques in that H \u221e techniques are readily applicable to problems involving multivariate systems with cross-coupling between channels.","title":"Linear Quadratic Regulator"},{"location":"automation/ControlTheory/LQR/#linear-quadratic-regulatorlqr-controller","text":"The theory of optimal control is concerned with operating a dynamic system at minimum cost. The case where the system dynamics are described by a set of linear differential equations and the cost is described by a quadratic function is called the LQ problem. One of the main results in the theory is that the solution is provided by the linear\u2013quadratic regulator ( LQR ). The settings of a (regulating) controller governing either a machine or process (like an airplane or chemical reactor) are found by using a mathematical algorithm that minimizes a cost function with weighting factors needed to be supplied. A cost function is a function that maps an event or values of one or more variables onto a real number intuitively representing some \u201ccost\u201d associated with the event. The cost function is often defined as a sum of the deviations of key measurements, like altitude or process temperature, from their desired values. The algorithm thus finds those controller settings that minimize undesired deviations. The magnitude of the control action itself may also be included in the cost function.","title":"Linear-Quadratic Regulator(LQR) Controller"},{"location":"automation/ControlTheory/LQR/#finite-horizon-lqr","text":"For a continuous-time linear system, defined on \\(t \\epsilon [t_0,t_1]\\) , described by: \\(\\dot{x} = Ax + Bu\\) with a quadratic cost function defined as: \\(J = x^T (t_1)F(t_1)x(t_1) + \\int_{t_0}^{t_1} (x^TQx + u^TRu + 2x^TNu) \\,dt\\) the feedback control law that minimizes the value of the cost is: \\(u = -Kx\\) where K is given by: \\(K = R^{-1}(B^TP(t) + N^t)\\) and P is found by solving the continuous time Riccati differential equation : \\(A^TP(t) + P(t)A - (P(t)B+N)R^{-1}(B^TP(t) + N^T) + Q = - \\dot{P}(t)\\) with the boundary condition: \\(P(t_1)=F(t_1)\\) To learn more in detail about LQR controller watch this video by Steve Brunton","title":"Finite horizon LQR"},{"location":"automation/ControlTheory/LQR/#linear-quadratic-gaussian-lqg-control-theory","text":"Here, Given a linear model of the plant in a statespace description, and assuming that the disturbance and measurement noise are Gaussian stochastic processes with known power spectral densities, the designer translates the design specifications into a quadratic performance criterion consisting of some state variables and control signal inputs. The object of design then is to minimize the performance criterion by using appropriate state or measurement feedback controllers while guaranteeing the closed-loop stability. When LQG controller problem is solved in a deterministic setting, known as an H 2 optimal control problem, in which the H 2 norm of a certain transfer function from an exogenous disturbance to a pertinent controlled output of a given plant is minimized by appropriate use of an internally stabilizing controller. To learn about robust controllers and LQG control problem in detail watch this video H\u221e (i.e. \u201c H-infinity \u201d) methods are used in control theory to synthesize controllers to achieve stabilization with guaranteed performance. To use H \u221e methods, a control designer expresses the control problem as a mathematical optimization problem and then finds the controller that solves this optimization. H \u221e techniques have the advantage over classical control techniques in that H \u221e techniques are readily applicable to problems involving multivariate systems with cross-coupling between channels.","title":"Linear Quadratic Gaussian (LQG) control theory"},{"location":"automation/ControlTheory/MPC/","text":"Model Based Controllers Model-based control uses information about the dynamics of the system\u2019s structure and its behavior in time to obtain a better control result regarding stability and performance of the controlled system. Take the following simple example: Let \\(\\frac{d^2x}{dt^2}= f(x)+u\\) be the system to be controlled, where x - state vector, f(x) - nonlinear vector function, u - control vector. Suppose we have some estimation est(x) than we use a control law like \\(u = -est(x)+u_{st}\\) where u st be some maybe linear PID control law \\(u_{st} = K_px + K_d\\frac{dx}{dt} + K_i\\int xdt\\) So we get \\(\\frac{d^2x}{dt^2} = \\Delta f + K_px + K_d\\frac{dx}{dt} + K_i\\int xdt\\) where \\(\\Delta f =f(x) - est(x)\\) If the model uncertainties are small enough we get a linear system with a disturbance Delta f which can be stabilized using appropriate control gains K p , K d , K I . Above given is just an example of model based controller in real life model based controller are way more complex than this. Model Predictive Control(MPC) is the most widely known model based controller. Model Predictive Controllers rely on the dynamic models of the process, most often linear empirical models obtained by system identification. Model predictive control offers several important advantages: (1) the process model captures the dynamic and static interactions between input, output, and disturbance variables, (2) constraints on inputs and outputs are considered in a systematic manner, (3) the control calculations can be coordinated with the calculation of optimum set points, and (4) accurate model predictions can provide early warnings of potential problems. The mathematics and concepts involved in MPC are a bit complex and require a decent understanding of mathematics of control theory. To study more about MPC controller read this material by NTNU You can also check this video by Steve Brunton to get a more detailed idea Some of the other resources you should check to understand control theory and various controllers in more detail are: Control Bootcamp playlist by Steve Brunton Control Systems Lectures by Brian Douglas Control of Mobile Robots course by Georgia Tech University on Coursera Modern Robotics - Mechanical, Planning and Control by Kevin.M.Lynch and Frank.C.Park MIT Courseware Control Theory Notes","title":"Model Predictive Control"},{"location":"automation/ControlTheory/MPC/#model-based-controllers","text":"Model-based control uses information about the dynamics of the system\u2019s structure and its behavior in time to obtain a better control result regarding stability and performance of the controlled system. Take the following simple example: Let \\(\\frac{d^2x}{dt^2}= f(x)+u\\) be the system to be controlled, where x - state vector, f(x) - nonlinear vector function, u - control vector. Suppose we have some estimation est(x) than we use a control law like \\(u = -est(x)+u_{st}\\) where u st be some maybe linear PID control law \\(u_{st} = K_px + K_d\\frac{dx}{dt} + K_i\\int xdt\\) So we get \\(\\frac{d^2x}{dt^2} = \\Delta f + K_px + K_d\\frac{dx}{dt} + K_i\\int xdt\\) where \\(\\Delta f =f(x) - est(x)\\) If the model uncertainties are small enough we get a linear system with a disturbance Delta f which can be stabilized using appropriate control gains K p , K d , K I . Above given is just an example of model based controller in real life model based controller are way more complex than this. Model Predictive Control(MPC) is the most widely known model based controller. Model Predictive Controllers rely on the dynamic models of the process, most often linear empirical models obtained by system identification. Model predictive control offers several important advantages: (1) the process model captures the dynamic and static interactions between input, output, and disturbance variables, (2) constraints on inputs and outputs are considered in a systematic manner, (3) the control calculations can be coordinated with the calculation of optimum set points, and (4) accurate model predictions can provide early warnings of potential problems. The mathematics and concepts involved in MPC are a bit complex and require a decent understanding of mathematics of control theory. To study more about MPC controller read this material by NTNU You can also check this video by Steve Brunton to get a more detailed idea Some of the other resources you should check to understand control theory and various controllers in more detail are: Control Bootcamp playlist by Steve Brunton Control Systems Lectures by Brian Douglas Control of Mobile Robots course by Georgia Tech University on Coursera Modern Robotics - Mechanical, Planning and Control by Kevin.M.Lynch and Frank.C.Park MIT Courseware Control Theory Notes","title":"Model Based Controllers"},{"location":"automation/ControlTheory/PID_Controller/","text":"Linear Control Techniques Linear Control technique is the most widely used technique for designing control systems in robotics because of its simple implementation when your system is operating in vicinity of a particular point. Some of the common linear control system design techniques, includes the well-known PID control, H 2 and H \\(\\infty\\) optimal control, linear quadratic regulator (LQR) with loop transfer recovery design (LTR) , and some newly developed design techniques, such as the robust and perfect tracking (RPT) method. PID Controller PID control is the most popular technique used in industries because it is relatively easy and simple to design and implement. Most importantly, it works in most practical situations, although its performance is somewhat limited owing to its restricted structure. Hence, a PID control law has the following general form for the input command: \\(u(t) = K~p~e(t) + K~i~\\int e(t) + K~d~\\frac{de(t)}{dt}\\) where \\(e = q - q~d~\\) is the error signal, and \\(K~p~, K~i~\\) and \\(K~d~\\) are positive constant gains associated with proportional, integral, and derivative controllers. Consider the control system , in which G(s) is the plant to be controlled and K(s) is the PID controller, it can be characterized by the following transfer function: \\(K(s) = K~p~(1+\\frac{1}{Tis}+Tds)\\) The control system design is then to determine the parameters K p , T i and T d such that the resulting dosed-loop system yields a certain desired performance, i.e. it meets certain prescribed design specifications. Proportional factor The proportional factor is easiest to understand: The output of the proportional factor is the product of gain and measured error \u03b5. Hence, larger proportional gain or error makes for greater output from the proportional factor. Setting the proportional gain too high causes a controller to repeatedly overshoot the setpoint, leading to oscillation. The downside to a proportional-only loop is that when error becomes too small, loop output becomes negligible. Therefore, even when the proportional loop reaches steady state, there is still error. The larger the proportional gain, the smaller the steady state error \u2014 but the larger the proportional gain, the more likely the loop is to become unstable. This dilemma leads to inevitable steady-state error called offset . Integral Factor The main function of an integral control is to eliminate the steady state error and make the system follow the set point at steady state conditions. The integral controller leads to an increasing control command for a positive error, and a decreasing control command for a negative error. The downside to the integral factor is that it strongly contributes to controller output overshoot past the target setpoint. The shorter the integral time, the more aggressively the integral works. Derivative Factor The purpose of derivative control is to improve the closed-loop stability of a system. A derivative controller has a predicting action by extrapolating the error using a tangent to the error curve. The derivative factor is the least understood and used of the three factors. In fact, a majority of PID loops in the real world are really just PI loops. A properly used derivative allows for more aggressive proportional and integral factors. PID Tuning Method The determination of corresponding PID parameter values for getting the optimum performance from the process is called tuning. This is obviously a crucial part in case of all closed loop control systems. There are number of tuning methods have been introduced to obtain fast and acceptable performance. Trial and Error Method This is the simple method of tuning a PID controller. Once we get the clear understanding of PID parameters, the trial and error method become relatively easy. Set integral and derivative terms to zero first and then increase the proportional gain until the output of the control loop oscillates at a constant rate. This increase of proportional gain should be in such that response the system becomes faster provided it should not make system unstable. Once the P-response is fast enough, set the integral term, so that the oscillations will be gradually reduced. Change this I-value until the steady state error is reduced, but it may increase overshoot. Once P and I parameters have been set to a desired values with minimal steady state error, increase the derivative gain until the system reacts quickly to its set point. Increasing derivative term decreases the overshoot of the controller response. Zeigler-Nichols Method It is another popular method for tuning PID controllers. Ziegler and Nichols presented two classical methods for determining values of proportional gain, integral time and derivative time based on transient response characteristics of a given plant or system. First Method Obtain a unit step response of the plant experimentally and it may look\u2018s\u2019 shaped curve as shown in figure below. This method applies, if obtained response exhibit s-shaped curve for unit step input otherwise it cannot be applied. This curve can also be obtained by dynamic simulation of the plant. Obtain two constants, delay time L and time constant T by drawing a tangent line at the inflection point of the s-shaped curve. Set the parameters of K p , T i , and T d values from the table given below for three types of controllers. Second Method It is very similar to the trial and error method where integral and derivative terms are set to the zero, i.e., making Ti infinity and Td zero. Increase the proportional gain such that the output exhibits sustained oscillations. If the system does not produce sustained oscillations then this method cannot be applied. The gain at which sustained oscillations produced is called as critical gain. Once the sustain oscillations are produced, set the values of Ti and Td as per the given table for P, PI and PID controllers based on critical gain and critical period.","title":"PID Controller"},{"location":"automation/ControlTheory/PID_Controller/#linear-control-techniques","text":"Linear Control technique is the most widely used technique for designing control systems in robotics because of its simple implementation when your system is operating in vicinity of a particular point. Some of the common linear control system design techniques, includes the well-known PID control, H 2 and H \\(\\infty\\) optimal control, linear quadratic regulator (LQR) with loop transfer recovery design (LTR) , and some newly developed design techniques, such as the robust and perfect tracking (RPT) method.","title":"Linear Control Techniques"},{"location":"automation/ControlTheory/PID_Controller/#pid-controller","text":"PID control is the most popular technique used in industries because it is relatively easy and simple to design and implement. Most importantly, it works in most practical situations, although its performance is somewhat limited owing to its restricted structure. Hence, a PID control law has the following general form for the input command: \\(u(t) = K~p~e(t) + K~i~\\int e(t) + K~d~\\frac{de(t)}{dt}\\) where \\(e = q - q~d~\\) is the error signal, and \\(K~p~, K~i~\\) and \\(K~d~\\) are positive constant gains associated with proportional, integral, and derivative controllers. Consider the control system , in which G(s) is the plant to be controlled and K(s) is the PID controller, it can be characterized by the following transfer function: \\(K(s) = K~p~(1+\\frac{1}{Tis}+Tds)\\) The control system design is then to determine the parameters K p , T i and T d such that the resulting dosed-loop system yields a certain desired performance, i.e. it meets certain prescribed design specifications.","title":"PID Controller"},{"location":"automation/ControlTheory/PID_Controller/#proportional-factor","text":"The proportional factor is easiest to understand: The output of the proportional factor is the product of gain and measured error \u03b5. Hence, larger proportional gain or error makes for greater output from the proportional factor. Setting the proportional gain too high causes a controller to repeatedly overshoot the setpoint, leading to oscillation. The downside to a proportional-only loop is that when error becomes too small, loop output becomes negligible. Therefore, even when the proportional loop reaches steady state, there is still error. The larger the proportional gain, the smaller the steady state error \u2014 but the larger the proportional gain, the more likely the loop is to become unstable. This dilemma leads to inevitable steady-state error called offset .","title":"Proportional factor"},{"location":"automation/ControlTheory/PID_Controller/#integral-factor","text":"The main function of an integral control is to eliminate the steady state error and make the system follow the set point at steady state conditions. The integral controller leads to an increasing control command for a positive error, and a decreasing control command for a negative error. The downside to the integral factor is that it strongly contributes to controller output overshoot past the target setpoint. The shorter the integral time, the more aggressively the integral works.","title":"Integral Factor"},{"location":"automation/ControlTheory/PID_Controller/#derivative-factor","text":"The purpose of derivative control is to improve the closed-loop stability of a system. A derivative controller has a predicting action by extrapolating the error using a tangent to the error curve. The derivative factor is the least understood and used of the three factors. In fact, a majority of PID loops in the real world are really just PI loops. A properly used derivative allows for more aggressive proportional and integral factors.","title":"Derivative Factor"},{"location":"automation/ControlTheory/PID_Controller/#pid-tuning-method","text":"The determination of corresponding PID parameter values for getting the optimum performance from the process is called tuning. This is obviously a crucial part in case of all closed loop control systems. There are number of tuning methods have been introduced to obtain fast and acceptable performance.","title":"PID Tuning Method"},{"location":"automation/ControlTheory/PID_Controller/#trial-and-error-method","text":"This is the simple method of tuning a PID controller. Once we get the clear understanding of PID parameters, the trial and error method become relatively easy. Set integral and derivative terms to zero first and then increase the proportional gain until the output of the control loop oscillates at a constant rate. This increase of proportional gain should be in such that response the system becomes faster provided it should not make system unstable. Once the P-response is fast enough, set the integral term, so that the oscillations will be gradually reduced. Change this I-value until the steady state error is reduced, but it may increase overshoot. Once P and I parameters have been set to a desired values with minimal steady state error, increase the derivative gain until the system reacts quickly to its set point. Increasing derivative term decreases the overshoot of the controller response.","title":"Trial and Error Method"},{"location":"automation/ControlTheory/PID_Controller/#zeigler-nichols-method","text":"It is another popular method for tuning PID controllers. Ziegler and Nichols presented two classical methods for determining values of proportional gain, integral time and derivative time based on transient response characteristics of a given plant or system.","title":"Zeigler-Nichols Method"},{"location":"automation/ControlTheory/PID_Controller/#first-method","text":"Obtain a unit step response of the plant experimentally and it may look\u2018s\u2019 shaped curve as shown in figure below. This method applies, if obtained response exhibit s-shaped curve for unit step input otherwise it cannot be applied. This curve can also be obtained by dynamic simulation of the plant. Obtain two constants, delay time L and time constant T by drawing a tangent line at the inflection point of the s-shaped curve. Set the parameters of K p , T i , and T d values from the table given below for three types of controllers.","title":"First Method"},{"location":"automation/ControlTheory/PID_Controller/#second-method","text":"It is very similar to the trial and error method where integral and derivative terms are set to the zero, i.e., making Ti infinity and Td zero. Increase the proportional gain such that the output exhibits sustained oscillations. If the system does not produce sustained oscillations then this method cannot be applied. The gain at which sustained oscillations produced is called as critical gain. Once the sustain oscillations are produced, set the values of Ti and Td as per the given table for P, PI and PID controllers based on critical gain and critical period.","title":"Second Method"},{"location":"automation/PathPlanners/APF/","text":"Artificial Potential Field Algorithm for Path Planning Over the past few years, research into using robots to reduce human labour has increased. Robotics has emerged as a new field for the benefit of people, from employing mobile robots for military operations on land and underwater to using them in restaurants to prepare food for patrons. Unmanned vehicle course planning and obstacle identification while limiting input energy and obtaining the best outcomes, however, is a significant challenge. The question of how to employ various methods to develop an obstacle distribution model and how to attain the required outcomes while making a few assumptions in a real-world system has been the subject of some recent literary works. One of the most fundamental and often used algorithms for such a situation is the potential field algorithm. In accordance with the literature sources studied and the outcomes of the experiment done, this paper will provide a quick review of how various algorithms can be employed for path planning reasons as well as how the potential field algorithm aids in obstacle detection. Working principle of Potential Field Algorithm Any physical field that complies with Laplace\u2019s equation is a potential field. Electromagnetic, gravitational, and electrical fields are a few typical examples of potential fields. To control a robot\u2019s movement within a given area, a potential field algorithm makes use of the artificial potential field. We simplify the division of a space into a grid of cells with obstacles and a goal node. The potential field functions, which will be discussed further in the explanation, are used by the algorithm to assign an artificial potential field to every point on earth. From the highest potential to the lowest potential, the robot simulates. In this case, the starting node will have the highest potential while the goal node has the lowest potential. Since the UAV moves from lowest to highest potential, we can say that. Types Of Potential Fields Two kinds of artificial potential fields are generated within the system: Attractive field and Repulsive fields. The goal node exhibits an attractive field while the obstacles in the system produce repulsive fields. Force of repulsion is inversely proportional to Distance from the robot to obstacles. Hence, the generated total force at each point of the graph is: U(total) = U(attraction) + U(repulsion) Attractive Fields The following function can be used for generating the force generated by the goal node. Here, x and y are the coordinates of the starting node, (xgoal,ygoal) are the coordinates of the goal node and C is a constant. Repulsive Fields Two kinds of repulsive forces are produced within the system: 1. Repulsive forces by the boundaries: This force remains uniform throughout the system and hence, doesn\u2019t affect the calculations; this force is useful in keeping the robot away from the boundaries. The following equation can be used to find the repulsive forces exhibited by the boundaries: where gi is a linear function that represents the boundary of the convex region, \u03b4 is a constant number with a small value and s is the number of boundary face segments. 2. Repulsive forces by the obstacles: The force of repulsion from obstacles can be calculated through the formula given below. Here, pmax is the highest potential, (x0,y0) are the coordinates of the center of an obstacle and l is the side length of the obstacle: Hence, the resultant force on the environment is: P = Po + P(goal) where, Po = max{Pi} Local Minima Trap The local minima trap problem is a problem for potential field algorithms. This happens when all artificial forces\u2014both attracting and repulsive\u2014are balanced out, as happens, for example, when an obstacle is directly in the path of the UAV or when there are many impediments close together. This problem can be solved in a number of ways. The solution method we employ here introduces a fictitious barrier in the vicinity of the local minima to deter the migrating object. Pseudo Code for Algorithm t = 0 , xc ( 0 ) = xstart , Flag = 0 , calculate the potential function while Next decision is not goal do if Flag = 0 then Go to the next position with lowest potential else if Flag = 1 then Change the cell weight and treat the cells as occupied by an obstacle Update the potential of each cell. end end if the bot is trapped in a cell or visits the same place multiple times then Flag = 1 , searchfor the trapping points / points end if the bot flees from the local minima then Flag = 0 , end X t +! <- cell nearby with lowest potential function t <- t +1 end Time Complexity of the Algorithm Evaluation of forces in the configuration space is a requirement of potential field algorithms, and the complexity of these algorithms is frequently O(MD), where M is the total number of nodes in the computation space and D is the dimension of the space. Robot path planning is a good example of this algorithm in use. References CS765 McGill University Notes","title":"Artificial Potential Fields"},{"location":"automation/PathPlanners/APF/#artificial-potential-field-algorithm-for-path-planning","text":"Over the past few years, research into using robots to reduce human labour has increased. Robotics has emerged as a new field for the benefit of people, from employing mobile robots for military operations on land and underwater to using them in restaurants to prepare food for patrons. Unmanned vehicle course planning and obstacle identification while limiting input energy and obtaining the best outcomes, however, is a significant challenge. The question of how to employ various methods to develop an obstacle distribution model and how to attain the required outcomes while making a few assumptions in a real-world system has been the subject of some recent literary works. One of the most fundamental and often used algorithms for such a situation is the potential field algorithm. In accordance with the literature sources studied and the outcomes of the experiment done, this paper will provide a quick review of how various algorithms can be employed for path planning reasons as well as how the potential field algorithm aids in obstacle detection.","title":"Artificial Potential Field Algorithm for Path Planning"},{"location":"automation/PathPlanners/APF/#working-principle-of-potential-field-algorithm","text":"Any physical field that complies with Laplace\u2019s equation is a potential field. Electromagnetic, gravitational, and electrical fields are a few typical examples of potential fields. To control a robot\u2019s movement within a given area, a potential field algorithm makes use of the artificial potential field. We simplify the division of a space into a grid of cells with obstacles and a goal node. The potential field functions, which will be discussed further in the explanation, are used by the algorithm to assign an artificial potential field to every point on earth. From the highest potential to the lowest potential, the robot simulates. In this case, the starting node will have the highest potential while the goal node has the lowest potential. Since the UAV moves from lowest to highest potential, we can say that.","title":"Working principle of Potential Field Algorithm"},{"location":"automation/PathPlanners/APF/#types-of-potential-fields","text":"Two kinds of artificial potential fields are generated within the system: Attractive field and Repulsive fields. The goal node exhibits an attractive field while the obstacles in the system produce repulsive fields. Force of repulsion is inversely proportional to Distance from the robot to obstacles. Hence, the generated total force at each point of the graph is: U(total) = U(attraction) + U(repulsion)","title":"Types Of Potential Fields"},{"location":"automation/PathPlanners/APF/#attractive-fields","text":"The following function can be used for generating the force generated by the goal node. Here, x and y are the coordinates of the starting node, (xgoal,ygoal) are the coordinates of the goal node and C is a constant.","title":"Attractive Fields"},{"location":"automation/PathPlanners/APF/#repulsive-fields","text":"Two kinds of repulsive forces are produced within the system: 1. Repulsive forces by the boundaries: This force remains uniform throughout the system and hence, doesn\u2019t affect the calculations; this force is useful in keeping the robot away from the boundaries. The following equation can be used to find the repulsive forces exhibited by the boundaries: where gi is a linear function that represents the boundary of the convex region, \u03b4 is a constant number with a small value and s is the number of boundary face segments. 2. Repulsive forces by the obstacles: The force of repulsion from obstacles can be calculated through the formula given below. Here, pmax is the highest potential, (x0,y0) are the coordinates of the center of an obstacle and l is the side length of the obstacle: Hence, the resultant force on the environment is: P = Po + P(goal) where, Po = max{Pi}","title":"Repulsive Fields"},{"location":"automation/PathPlanners/APF/#local-minima-trap","text":"The local minima trap problem is a problem for potential field algorithms. This happens when all artificial forces\u2014both attracting and repulsive\u2014are balanced out, as happens, for example, when an obstacle is directly in the path of the UAV or when there are many impediments close together. This problem can be solved in a number of ways. The solution method we employ here introduces a fictitious barrier in the vicinity of the local minima to deter the migrating object.","title":"Local Minima Trap"},{"location":"automation/PathPlanners/APF/#pseudo-code-for-algorithm","text":"t = 0 , xc ( 0 ) = xstart , Flag = 0 , calculate the potential function while Next decision is not goal do if Flag = 0 then Go to the next position with lowest potential else if Flag = 1 then Change the cell weight and treat the cells as occupied by an obstacle Update the potential of each cell. end end if the bot is trapped in a cell or visits the same place multiple times then Flag = 1 , searchfor the trapping points / points end if the bot flees from the local minima then Flag = 0 , end X t +! <- cell nearby with lowest potential function t <- t +1 end","title":"Pseudo Code for Algorithm"},{"location":"automation/PathPlanners/APF/#time-complexity-of-the-algorithm","text":"Evaluation of forces in the configuration space is a requirement of potential field algorithms, and the complexity of these algorithms is frequently O(MD), where M is the total number of nodes in the computation space and D is the dimension of the space. Robot path planning is a good example of this algorithm in use.","title":"Time Complexity of the Algorithm"},{"location":"automation/PathPlanners/APF/#references","text":"CS765 McGill University Notes","title":"References"},{"location":"automation/PathPlanners/Astar/","text":"A-Star Algorithm A-star is a graph-based, path search algorithm. It is used in many fields of computer science as a search algorithm. It is often used due to its completeness, optimality, and optimal efficiency. Salient Features of the Algorithm Resolution complete and Resolution optimal : The algorithm finds the optimal solution to the given problem at a chosen discretization, if one exits. A-Star uses a hueristic to estimate the total cost of a solution constrained to pass through a state. Thus, it searches in order of decreasing solution quality and is optimally efficient . Any other optimal algorithm using the same hueristic will expand at least as many vertices as A-Star. Idea of Hueristics Functions Hueristic functions are used to map every node in the graph to a non-negative value. Criteria for Hueristics Functions Should be a monotonic function Should satisfy \\(H(goal) = 0\\) For any two adjacent nodes \\(x\\) and \\(y\\) : \\(H(x, y) \\leq H(y) + d(x, y)\\) \\(d(x, y) = EdgeCost(x, y)\\) These properties ensure that for all nodes \\(n\\) : \\(H(n) \\leq length of Shortest Path(n, GOAL)\\) For path Planning on a grid: Euclidean Distance: \\(H(x_n, y_n) = \\sqrt{(x_n-x_g)^2 + (y_n-y_g)^2}\\) Manhattan Distance: \\(H(x_n, y_n) = \\lvert(x_n - x_g) + (y_n - y_g)\\rvert\\) Where \\(x_n\\) , \\(y_n\\) and \\(x_g\\) , \\(y_g\\) are the \\(x\\) , \\(y\\) coordinates of a the node and the goal respectively. Psuedo Code for the Algorithm def Astar ( start , goal , graph ): # Set the g, f values for all nodes in the graph for node in graph : node . f = Infinity node . g = Infinity # Create an empty list to store visited nodes nodes = [] # Add Start to nodes list nodes . add ( start ) # Loop to traverse the graph while nodes is not EMPTY : # Obtain bode with the least f-value CURRENT = argmin ( node , criteria = node . f ) # Check if current node is the goal Node # which means the graph has been completely traversed if CURRENT == goal : report \"SUCCESS\" break # Update parameters for adjacent nodes for adjacent_node in CURRENT . adjacent_nodes : if adjacent_node . g > CURRENT . g + cost of edge from n to current : adjacent_node . g = CURRENT . g + cost of edge from n to current adjacent_node . f = adjacent_node . g + H ( node ) adjacent_node . parent = CURRENT # Add the adjacent node to nodes list if not there already if adjacent_node not in nodes : nodes . add ( adjacent_node ) Notations in the Psuedo Code explained : g-value = distance between a node and the start node H-function = Hueristic funciton f-value = g-value + Hueristic value of the node References Original paper on A-Star path planning algorithm. Psuedo Code A-star Youtube Video","title":"A* Algorithm"},{"location":"automation/PathPlanners/Astar/#a-star-algorithm","text":"A-star is a graph-based, path search algorithm. It is used in many fields of computer science as a search algorithm. It is often used due to its completeness, optimality, and optimal efficiency.","title":"A-Star Algorithm"},{"location":"automation/PathPlanners/Astar/#salient-features-of-the-algorithm","text":"Resolution complete and Resolution optimal : The algorithm finds the optimal solution to the given problem at a chosen discretization, if one exits. A-Star uses a hueristic to estimate the total cost of a solution constrained to pass through a state. Thus, it searches in order of decreasing solution quality and is optimally efficient . Any other optimal algorithm using the same hueristic will expand at least as many vertices as A-Star.","title":"Salient Features of the Algorithm"},{"location":"automation/PathPlanners/Astar/#idea-of-hueristics-functions","text":"Hueristic functions are used to map every node in the graph to a non-negative value.","title":"Idea of Hueristics Functions"},{"location":"automation/PathPlanners/Astar/#criteria-for-hueristics-functions","text":"Should be a monotonic function Should satisfy \\(H(goal) = 0\\) For any two adjacent nodes \\(x\\) and \\(y\\) : \\(H(x, y) \\leq H(y) + d(x, y)\\) \\(d(x, y) = EdgeCost(x, y)\\) These properties ensure that for all nodes \\(n\\) : \\(H(n) \\leq length of Shortest Path(n, GOAL)\\)","title":"Criteria for Hueristics Functions"},{"location":"automation/PathPlanners/Astar/#for-path-planning-on-a-grid","text":"Euclidean Distance: \\(H(x_n, y_n) = \\sqrt{(x_n-x_g)^2 + (y_n-y_g)^2}\\) Manhattan Distance: \\(H(x_n, y_n) = \\lvert(x_n - x_g) + (y_n - y_g)\\rvert\\) Where \\(x_n\\) , \\(y_n\\) and \\(x_g\\) , \\(y_g\\) are the \\(x\\) , \\(y\\) coordinates of a the node and the goal respectively.","title":"For path Planning on a grid:"},{"location":"automation/PathPlanners/Astar/#psuedo-code-for-the-algorithm","text":"def Astar ( start , goal , graph ): # Set the g, f values for all nodes in the graph for node in graph : node . f = Infinity node . g = Infinity # Create an empty list to store visited nodes nodes = [] # Add Start to nodes list nodes . add ( start ) # Loop to traverse the graph while nodes is not EMPTY : # Obtain bode with the least f-value CURRENT = argmin ( node , criteria = node . f ) # Check if current node is the goal Node # which means the graph has been completely traversed if CURRENT == goal : report \"SUCCESS\" break # Update parameters for adjacent nodes for adjacent_node in CURRENT . adjacent_nodes : if adjacent_node . g > CURRENT . g + cost of edge from n to current : adjacent_node . g = CURRENT . g + cost of edge from n to current adjacent_node . f = adjacent_node . g + H ( node ) adjacent_node . parent = CURRENT # Add the adjacent node to nodes list if not there already if adjacent_node not in nodes : nodes . add ( adjacent_node ) Notations in the Psuedo Code explained : g-value = distance between a node and the start node H-function = Hueristic funciton f-value = g-value + Hueristic value of the node","title":"Psuedo Code for the Algorithm"},{"location":"automation/PathPlanners/Astar/#references","text":"Original paper on A-Star path planning algorithm. Psuedo Code A-star Youtube Video","title":"References"},{"location":"automation/PathPlanners/Dijkstra/","text":"Dijkstra\u2019s Algorithm Dijkstra\u2019s Algorithm is an algorithm for finding the shortest path between one source node and all the other nodes in a graph, thereby producing a shortest-path-tree . Psuedo Code # Set the distances if all nodes in the graph to infinty for node in graph : node . distance = INFINITY # Create an empty list nodes = [] # Set the start distance to ZERO START . distance = 0 # Add start to the list nodes . add ( START ) # Loop to update distances while nodes is not empty : CURRENT = argmin ( node , criteria = node . distance ) if CURRENT == GOAL : report \"Success\" break for adjacent_node in CURRENT . adjacent_nodes : if adjacent_node . distance > CURRENT . distance + cost of edge from CURRENT to adjacent_node : adjacent_node . distance = CURRENT . distance + cost of edge from CURRENT to adjacent_node adjacent_node . parent = CURRENT # Add adjacent_node to the list, if it is not already present if adjacent_node not in nodes : nodes . add ( adjacent_node ) References Psuedo Code for Dijkstra\u2019s Algorithm Dijkstra\u2019s Algorithm Youtube Video","title":"Dijkstra's Algorithm"},{"location":"automation/PathPlanners/Dijkstra/#dijkstras-algorithm","text":"Dijkstra\u2019s Algorithm is an algorithm for finding the shortest path between one source node and all the other nodes in a graph, thereby producing a shortest-path-tree .","title":"Dijkstra's Algorithm"},{"location":"automation/PathPlanners/Dijkstra/#psuedo-code","text":"# Set the distances if all nodes in the graph to infinty for node in graph : node . distance = INFINITY # Create an empty list nodes = [] # Set the start distance to ZERO START . distance = 0 # Add start to the list nodes . add ( START ) # Loop to update distances while nodes is not empty : CURRENT = argmin ( node , criteria = node . distance ) if CURRENT == GOAL : report \"Success\" break for adjacent_node in CURRENT . adjacent_nodes : if adjacent_node . distance > CURRENT . distance + cost of edge from CURRENT to adjacent_node : adjacent_node . distance = CURRENT . distance + cost of edge from CURRENT to adjacent_node adjacent_node . parent = CURRENT # Add adjacent_node to the list, if it is not already present if adjacent_node not in nodes : nodes . add ( adjacent_node )","title":"Psuedo Code"},{"location":"automation/PathPlanners/Dijkstra/#references","text":"Psuedo Code for Dijkstra\u2019s Algorithm Dijkstra\u2019s Algorithm Youtube Video","title":"References"},{"location":"automation/PathPlanners/GA/","text":"Genetic Algorithm The class of evolutionary algorithms that includes genetic algorithms was largely influenced by biological evolution. We are all aware of the basic principles of biological evolution, which include the choice of parents, reproduction, and offspring mutation. To produce offspring that are biologically superior to their parents is the primary goal of evolution. A genetic algorithm attempts to imitate Darwin\u2019s Theory of Evolution by Natural Selection. It is based primarily on this theory. The basic idea is to choose the population\u2019s best individuals to serve as parents, then ask them to increase the size of their generation by reproducing and bearing children. However, when genes from both parents cross over during reproduction, this can result in mutations, which are errors that can occur. The process continues, resulting in a healthier generation as these kids are asked to reproduce their babies once more. Evolutionary computation has been used to solve a variety of computational issues, including the traditional knapsack problem, feature selection, and optimization issues. Steps in Genetic Algorithm Genetic Representation(Encoding of Chromosomes) Representation of the Environment Initialization of Population Fitness Function Selection Operator Crossover Operator Mutation Operator In a genetic algorithm, a population of potential solutions to an optimization problem (referred to as individuals, animals, or phenotypes) evolves toward superior solutions. Traditionally, solutions are represented in binary as strings of 0s and 1s, although other encodings are also feasible. Each candidate solution has a set of properties (its chromosomes or genotype) that can be changed and modified. The Genetic Representation (Encoding of chromosomes) Genetic coding of potential members of the original population is necessary for the application of genetic algorithms to a particular problem. The most popular type of encoding employed in GAs was binary. Depending on the issue at hand, many encoding techniques can be employed. The selection of a coding method is crucial for the success of the behaviour of the GAs because the fitness function and genetic operators have an impact on this coding. The pathways (Positions set) that connect two known positions are potential solutions to the path planning problem (starting point and a target point). This path\u2019s nodes must be genuine, that is, they must not correspond to any obstruction. Representation of the Environment We can apply the occupancy grid presentation in which the robot environment is represented by 2D matrix,in which each position (x, y) in the grid has two likely values: 0 for free cells, and 1 for occupied ones. An appropriate solution is a path (set of positions) from the starting point to the goal point crossing a set of free positions. Initialization of Population As GA begins its searching process for the optimal path by acting on the initial population which is as set of potential candidates, the initialization method is a very important step since it alters the efficiency of the GA. Hence the choice of an efficient initial population method enhances the GA search effectiveness. Fitness Function Once the initial population has been established, the GA must assess each member\u2019s performance using an adaptive function that gives each potential solution a fitness value that reflects its calibre. The FF must take into account a number of factors, including distance, safety, smoothness, etc. The challenge of defining an appropriate fitness function is vital since the GA uses the data produced by this function to select people for reproduction, mutation, and to select the optimal outcome in the final analysis.Population based on its level of fitness. Four factors need to be considered when the suggested. Path length, Safety First Level (SFL), Safety Second Level (SSL), and energy make up the fitness function. Selection Operator The selection operator\u2019s primary goal is to select people who are highly adaptable for the following generation. The performance of GA is significantly impacted by the selection pressure, which is a crucial requirement [13]. If there is strong selection pressure, the GA converges. A low selection pressure results in random solutions, and fast without fully utilising the search space. In our elitist, which has a high pressure selection, is used to govern the pressure selection in the (TRS) approach.Utilised to give weak chromosomes a chance whereas TRS is used to keep the fittest solutions throughout generations. To avoid the dominance of the prior generation by choosing individuals from the previous one to reproduce in the present one superior person. Crossover Operator The crossover is used after individuals have been chosen using the selection operator. \u201cCrossover\u201d is a genetic operator that combines the genes from the two chosen chromosomes (parents) to produce new chromosomes (offspring/child), maintain the population\u2019s heterogeneity, and increase the fitness value of potential solutions. Crossover\u2019s core tenet is that new chromosomes take the best traits from their parents. The end outcome is a child who does better than both of its parents. The likelihood of performing a crossover is known as the crossover rate. Mutation Operator A genetic operator called mutation is used to increase diversity and delay the algorithm\u2019s premature convergence. Typically, this operator picks a gene at random and replaces it with a new gene that is not already present in the path. However, as stated in random mutation, invalid routes can be produced. Even though a solution is correct prior to the use of the mutation operator, the newly transformed gene may contain a barrier, which causes it to construct an unsuitable path. The mutation operator suggested in this publication is what we use in our study. References Github Link International Journal of Computational Engineering Research","title":"Genetic Algorithm"},{"location":"automation/PathPlanners/GA/#genetic-algorithm","text":"The class of evolutionary algorithms that includes genetic algorithms was largely influenced by biological evolution. We are all aware of the basic principles of biological evolution, which include the choice of parents, reproduction, and offspring mutation. To produce offspring that are biologically superior to their parents is the primary goal of evolution. A genetic algorithm attempts to imitate Darwin\u2019s Theory of Evolution by Natural Selection. It is based primarily on this theory. The basic idea is to choose the population\u2019s best individuals to serve as parents, then ask them to increase the size of their generation by reproducing and bearing children. However, when genes from both parents cross over during reproduction, this can result in mutations, which are errors that can occur. The process continues, resulting in a healthier generation as these kids are asked to reproduce their babies once more. Evolutionary computation has been used to solve a variety of computational issues, including the traditional knapsack problem, feature selection, and optimization issues.","title":"Genetic Algorithm"},{"location":"automation/PathPlanners/GA/#steps-in-genetic-algorithm","text":"Genetic Representation(Encoding of Chromosomes) Representation of the Environment Initialization of Population Fitness Function Selection Operator Crossover Operator Mutation Operator In a genetic algorithm, a population of potential solutions to an optimization problem (referred to as individuals, animals, or phenotypes) evolves toward superior solutions. Traditionally, solutions are represented in binary as strings of 0s and 1s, although other encodings are also feasible. Each candidate solution has a set of properties (its chromosomes or genotype) that can be changed and modified.","title":"Steps in Genetic Algorithm"},{"location":"automation/PathPlanners/GA/#the-genetic-representation-encoding-of-chromosomes","text":"Genetic coding of potential members of the original population is necessary for the application of genetic algorithms to a particular problem. The most popular type of encoding employed in GAs was binary. Depending on the issue at hand, many encoding techniques can be employed. The selection of a coding method is crucial for the success of the behaviour of the GAs because the fitness function and genetic operators have an impact on this coding. The pathways (Positions set) that connect two known positions are potential solutions to the path planning problem (starting point and a target point). This path\u2019s nodes must be genuine, that is, they must not correspond to any obstruction.","title":"The Genetic Representation (Encoding of chromosomes)"},{"location":"automation/PathPlanners/GA/#representation-of-the-environment","text":"We can apply the occupancy grid presentation in which the robot environment is represented by 2D matrix,in which each position (x, y) in the grid has two likely values: 0 for free cells, and 1 for occupied ones. An appropriate solution is a path (set of positions) from the starting point to the goal point crossing a set of free positions.","title":"Representation of the Environment"},{"location":"automation/PathPlanners/GA/#initialization-of-population","text":"As GA begins its searching process for the optimal path by acting on the initial population which is as set of potential candidates, the initialization method is a very important step since it alters the efficiency of the GA. Hence the choice of an efficient initial population method enhances the GA search effectiveness.","title":"Initialization of Population"},{"location":"automation/PathPlanners/GA/#fitness-function","text":"Once the initial population has been established, the GA must assess each member\u2019s performance using an adaptive function that gives each potential solution a fitness value that reflects its calibre. The FF must take into account a number of factors, including distance, safety, smoothness, etc. The challenge of defining an appropriate fitness function is vital since the GA uses the data produced by this function to select people for reproduction, mutation, and to select the optimal outcome in the final analysis.Population based on its level of fitness. Four factors need to be considered when the suggested. Path length, Safety First Level (SFL), Safety Second Level (SSL), and energy make up the fitness function.","title":"Fitness Function"},{"location":"automation/PathPlanners/GA/#selection-operator","text":"The selection operator\u2019s primary goal is to select people who are highly adaptable for the following generation. The performance of GA is significantly impacted by the selection pressure, which is a crucial requirement [13]. If there is strong selection pressure, the GA converges. A low selection pressure results in random solutions, and fast without fully utilising the search space. In our elitist, which has a high pressure selection, is used to govern the pressure selection in the (TRS) approach.Utilised to give weak chromosomes a chance whereas TRS is used to keep the fittest solutions throughout generations. To avoid the dominance of the prior generation by choosing individuals from the previous one to reproduce in the present one superior person.","title":"Selection Operator"},{"location":"automation/PathPlanners/GA/#crossover-operator","text":"The crossover is used after individuals have been chosen using the selection operator. \u201cCrossover\u201d is a genetic operator that combines the genes from the two chosen chromosomes (parents) to produce new chromosomes (offspring/child), maintain the population\u2019s heterogeneity, and increase the fitness value of potential solutions. Crossover\u2019s core tenet is that new chromosomes take the best traits from their parents. The end outcome is a child who does better than both of its parents. The likelihood of performing a crossover is known as the crossover rate.","title":"Crossover Operator"},{"location":"automation/PathPlanners/GA/#mutation-operator","text":"A genetic operator called mutation is used to increase diversity and delay the algorithm\u2019s premature convergence. Typically, this operator picks a gene at random and replaces it with a new gene that is not already present in the path. However, as stated in random mutation, invalid routes can be produced. Even though a solution is correct prior to the use of the mutation operator, the newly transformed gene may contain a barrier, which causes it to construct an unsuitable path. The mutation operator suggested in this publication is what we use in our study.","title":"Mutation Operator"},{"location":"automation/PathPlanners/GA/#references","text":"Github Link International Journal of Computational Engineering Research","title":"References"},{"location":"automation/PathPlanners/PRM/","text":"Probilistic Roadmap Method A network graph of potential routes in a given map based on open and occupied spaces is known as a probabilistic roadmap (PRM). Based on the PRM algorithm parameters, an object generates nodes at random and connects these nodes. Based on the connection distance and the obstacle positions indicated in the Map, nodes are connected. The number of nodes can be altered to suit the complexity of the map and your goal to discover the quickest route. To discover a path free of obstacles from a starting point to an ending point, the PRM method makes use of a network of connected nodes. A path through an environment can be properly planned by adjusting the connection distance and number of nodes attributes. The node locations are created at random when creating or changing the PRM class, which may have an impact on your final path after several iterations. When you call update, alter the parameters, or specify Map at the beginning, a selection of nodes is made. The state of the random number generation is needed to be preserved to get consistent results with the same node location. Disadvantages of PRM Although this algorithm is incredibly helpful, it does not always provide the best option. Think about a configuration space where there are several obstacles that are quite close to one another. Assume that there is a very little space between two obstacles. Keep in mind that our system creates nodes at random. As a result, there is extremely little chance of creating nodes between such gaps. If we increase the number of iterations, the algorithm might build nodes in that area. Though it may seem like it, the problem is not resolved by increasing the number of iterations. We wouldn\u2019t know whether the path doesn\u2019t exist or the number of iterations is lower for that environment if the system fails to build a path for such configurations of the space. This algorithm\u2019s only shortcoming is this. In the event of failure, it does not give us a clear image. Pseudo Code for Algorithm References MATLAB Documentation CS CMU paper CS Columbia Notes","title":"PRM"},{"location":"automation/PathPlanners/PRM/#probilistic-roadmap-method","text":"A network graph of potential routes in a given map based on open and occupied spaces is known as a probabilistic roadmap (PRM). Based on the PRM algorithm parameters, an object generates nodes at random and connects these nodes. Based on the connection distance and the obstacle positions indicated in the Map, nodes are connected. The number of nodes can be altered to suit the complexity of the map and your goal to discover the quickest route. To discover a path free of obstacles from a starting point to an ending point, the PRM method makes use of a network of connected nodes. A path through an environment can be properly planned by adjusting the connection distance and number of nodes attributes. The node locations are created at random when creating or changing the PRM class, which may have an impact on your final path after several iterations. When you call update, alter the parameters, or specify Map at the beginning, a selection of nodes is made. The state of the random number generation is needed to be preserved to get consistent results with the same node location.","title":"Probilistic Roadmap Method"},{"location":"automation/PathPlanners/PRM/#disadvantages-of-prm","text":"Although this algorithm is incredibly helpful, it does not always provide the best option. Think about a configuration space where there are several obstacles that are quite close to one another. Assume that there is a very little space between two obstacles. Keep in mind that our system creates nodes at random. As a result, there is extremely little chance of creating nodes between such gaps. If we increase the number of iterations, the algorithm might build nodes in that area. Though it may seem like it, the problem is not resolved by increasing the number of iterations. We wouldn\u2019t know whether the path doesn\u2019t exist or the number of iterations is lower for that environment if the system fails to build a path for such configurations of the space. This algorithm\u2019s only shortcoming is this. In the event of failure, it does not give us a clear image.","title":"Disadvantages of PRM"},{"location":"automation/PathPlanners/PRM/#pseudo-code-for-algorithm","text":"","title":"Pseudo Code for Algorithm"},{"location":"automation/PathPlanners/PRM/#references","text":"MATLAB Documentation CS CMU paper CS Columbia Notes","title":"References"},{"location":"automation/PathPlanners/RRT/","text":"Rapidly Exploring Random Trees Salient Features Randomly samples nodes in the Configuration space of the robot to build a tree of valid configurations. It is Probabilistically Complete ,having the probability to find a solution if it exists . In worst case, time taken to find a solution can be very long (longer than exhaustive search). The probability of finding a solution goes to \\(1\\) as number of sampled nodes goes to \\(\\infty\\) . In practise, the algorithm tends to be very effecitve in high dimensional spaces. There is no gaurantee regarding the optimality of the solution. The path produced my bot the the shortest path. Post processing of the path generated is required as the path generated is often very unordered or in zig-zag fashion. Collision Checking Function One important requirement of sampling algorithms, is the ability to check if a configuration is valid or not. To check if a configuration \\(X\\) is valid in a configuration free space \\(\\mathbb{C}\\) , a function as such can be used: \\[ CollisionCheck(X) = \\begin{cases} 0 \\quad &\\text{if} \\, X \\in \\mathbb{C} \\\\ 1 \\quad &\\text{if} \\, X \\notin \\mathbb{C} \\end{cases} \\\\ \\] Psuedo Code def RRT ( START , GOAL ): TREE = [] TREE . add ( START ) DELTA = maximum distance between sampled node and nearest node . REPEAT n times : X = generateNewConfiguration () if X in FREE_SPACE : for nodes in TREE : Y = argmin ( nodes , criteria = distance ) if DIST ( X , Y ) < DELTA : Find a configuration Z that is at DELTA distance along the path from X to Y if TRAVERSABLE ( X , Z ): X . parent = Y TREE . add ( X ) else : if TRAVERSABLE ( X , Y ): X . parent = Y TREE . add ( X ) if X is GOAL : report \"SUCCESS\" break Notations and Functions used in Psuedo Code: Function used to check if a path is traversable: \\[ Traversable(X, Y) = \\begin{cases} 1 \\quad &\\text{if} \\, \\operatorname{LineJoining}(X, Y) \\in \\mathbb{C} \\\\ 0 \\quad &\\text{if} \\, \\operatorname{LineJoining}(X, Y) \\notin \\mathbb{C} \\\\ \\end{cases} \\] In case of Rotations: \\[ Dist(X, Y) = \\min{(\\lvert X_n - Y_n \\rvert}, \\lvert\\ 2\\pi - \\lvert X_n - Y_n \\rvert \\rvert) \\] References Refer this article for more information about RRT and RRT* A video explaining RRT algorithm. Refer to the paper here","title":"RRT"},{"location":"automation/PathPlanners/RRT/#rapidly-exploring-random-trees","text":"","title":"Rapidly Exploring Random Trees"},{"location":"automation/PathPlanners/RRT/#salient-features","text":"Randomly samples nodes in the Configuration space of the robot to build a tree of valid configurations. It is Probabilistically Complete ,having the probability to find a solution if it exists . In worst case, time taken to find a solution can be very long (longer than exhaustive search). The probability of finding a solution goes to \\(1\\) as number of sampled nodes goes to \\(\\infty\\) . In practise, the algorithm tends to be very effecitve in high dimensional spaces. There is no gaurantee regarding the optimality of the solution. The path produced my bot the the shortest path. Post processing of the path generated is required as the path generated is often very unordered or in zig-zag fashion.","title":"Salient Features"},{"location":"automation/PathPlanners/RRT/#collision-checking-function","text":"One important requirement of sampling algorithms, is the ability to check if a configuration is valid or not. To check if a configuration \\(X\\) is valid in a configuration free space \\(\\mathbb{C}\\) , a function as such can be used: \\[ CollisionCheck(X) = \\begin{cases} 0 \\quad &\\text{if} \\, X \\in \\mathbb{C} \\\\ 1 \\quad &\\text{if} \\, X \\notin \\mathbb{C} \\end{cases} \\\\ \\]","title":"Collision Checking Function"},{"location":"automation/PathPlanners/RRT/#psuedo-code","text":"def RRT ( START , GOAL ): TREE = [] TREE . add ( START ) DELTA = maximum distance between sampled node and nearest node . REPEAT n times : X = generateNewConfiguration () if X in FREE_SPACE : for nodes in TREE : Y = argmin ( nodes , criteria = distance ) if DIST ( X , Y ) < DELTA : Find a configuration Z that is at DELTA distance along the path from X to Y if TRAVERSABLE ( X , Z ): X . parent = Y TREE . add ( X ) else : if TRAVERSABLE ( X , Y ): X . parent = Y TREE . add ( X ) if X is GOAL : report \"SUCCESS\" break","title":"Psuedo Code"},{"location":"automation/PathPlanners/RRT/#notations-and-functions-used-in-psuedo-code","text":"Function used to check if a path is traversable: \\[ Traversable(X, Y) = \\begin{cases} 1 \\quad &\\text{if} \\, \\operatorname{LineJoining}(X, Y) \\in \\mathbb{C} \\\\ 0 \\quad &\\text{if} \\, \\operatorname{LineJoining}(X, Y) \\notin \\mathbb{C} \\\\ \\end{cases} \\] In case of Rotations: \\[ Dist(X, Y) = \\min{(\\lvert X_n - Y_n \\rvert}, \\lvert\\ 2\\pi - \\lvert X_n - Y_n \\rvert \\rvert) \\]","title":"Notations and Functions used in Psuedo Code:"},{"location":"automation/PathPlanners/RRT/#references","text":"Refer this article for more information about RRT and RRT* A video explaining RRT algorithm. Refer to the paper here","title":"References"},{"location":"automation/PathPlanners/intro/","text":"Introduction to Path Planning In robotics, path planning refers to how a robot should move around in space to accomplish its goals (often just getting from point A to point B without crashing into anything along the way). Things to consider Spatial reasoning/understanding of robots, as it can have many dimensions in space, obstacles can be complicated. Global Planning of the path according to the the given environment. Online Local Planning is required to know whether environment is dynamic. Besides collision-free, should a path be optimal in time,energy or safety. Computing exact collision free paths is computationally expensive in 3D problem Kinematic, dynamic, and temporal reasoning may also be required Space Representation A mapped representation of their surroundings is either given to or implicitly built into robots. This map can be saved as a discrete approximation with chunks of equal or varying sizes (like a grid map) (like a topological map, for example road-maps).Continuous map approximations can be saved by defining inner and outer boundaries as polygons and paths around boundaries as a sequence of real valued points. Although continuous maps have obvious memory advantages, discrete maps are more commonly used in robotic path planning because they map well to graph representations, which have a long history of search and optimization algorithms with simple computation complexity. The occupancy grid discretizes a space into squares of arbitrary resolution and assigns each square a binary or probabilistic value of full or empty. Grid maps can be optimised for memory by storing them as a k-d tree, with only important boundary information saved at full resolution. To account for the fact that robots have physical embodiments that require space within the spatial map, configuration space is defined in such a way that the robot is reduced to a point-mass and all obstacles are enlarged by half of the robot\u2019s longest extension. Path Planning algorithms The problem to find an optimal path has been studied since many decades. There are many algorithms that are graph-based , sampling-based . Each branch follows a particular approach to solve the path planning problem. Deliberative Graph Based Algorithms Graph-based algorithms search for an optimal path by superimposing a topological graph on a robot\u2019s configurational space. Some of the notable graph-based algorithms are: A-Star (A*) Dynamic A-Star (D*) Dijkstra\u2019s Algorithm Pros Resolution Optimal Resolution Complete Cons Time Comlexity Discrete States Discrete Action Sets Holonomicity(Can be controlled with a different modeling. Not implemented in given code.) Sampling Based Algorithms Algorithms based on sampling represent the configuration space with a roadmap or construct a tree by randomly sampling states in the configuration space. Pros PRM Probalistically Optimal Probalistically Complete Reasonable Computation Time RRT Probalistically Complete Near real time performance. Cons PRM Narrow corridor problem Roadmap generation not for dynamic environments Holonomicity(Can be controlled with a different modeling. Not implemented in given code.) RRT Narrow corridor problem Not optimal and voronoi bias Practically not complete Some of the notable sampling-based algorithms are: Rapidly exploring Random Tree (RRT) RRT Star (RRT*) Probabilistic Roadmap Method (PRM) Optimization Based Algorithms It is a slow gradual process that works by making changes to the making slight and slow changes. Also, makes slight changes to its solutions slowly until getting the best solution. Pros Probabilistically Complete Probabitistically Optimal Cons Narrow corridor problem Computationally Expensive Practically not Complete One of the notable optimization-based algorithms is: Genetic Algorithm Reactive Fuzzy Logic Algorithm Artificial Potential Fields Resources Github Repository Cornell Website . Youtube Video .","title":"Introduction to Path Planning"},{"location":"automation/PathPlanners/intro/#introduction-to-path-planning","text":"In robotics, path planning refers to how a robot should move around in space to accomplish its goals (often just getting from point A to point B without crashing into anything along the way).","title":"Introduction to Path Planning"},{"location":"automation/PathPlanners/intro/#things-to-consider","text":"Spatial reasoning/understanding of robots, as it can have many dimensions in space, obstacles can be complicated. Global Planning of the path according to the the given environment. Online Local Planning is required to know whether environment is dynamic. Besides collision-free, should a path be optimal in time,energy or safety. Computing exact collision free paths is computationally expensive in 3D problem Kinematic, dynamic, and temporal reasoning may also be required","title":"Things to consider"},{"location":"automation/PathPlanners/intro/#space-representation","text":"A mapped representation of their surroundings is either given to or implicitly built into robots. This map can be saved as a discrete approximation with chunks of equal or varying sizes (like a grid map) (like a topological map, for example road-maps).Continuous map approximations can be saved by defining inner and outer boundaries as polygons and paths around boundaries as a sequence of real valued points. Although continuous maps have obvious memory advantages, discrete maps are more commonly used in robotic path planning because they map well to graph representations, which have a long history of search and optimization algorithms with simple computation complexity. The occupancy grid discretizes a space into squares of arbitrary resolution and assigns each square a binary or probabilistic value of full or empty. Grid maps can be optimised for memory by storing them as a k-d tree, with only important boundary information saved at full resolution. To account for the fact that robots have physical embodiments that require space within the spatial map, configuration space is defined in such a way that the robot is reduced to a point-mass and all obstacles are enlarged by half of the robot\u2019s longest extension.","title":"Space Representation"},{"location":"automation/PathPlanners/intro/#path-planning-algorithms","text":"The problem to find an optimal path has been studied since many decades. There are many algorithms that are graph-based , sampling-based . Each branch follows a particular approach to solve the path planning problem.","title":"Path Planning algorithms"},{"location":"automation/PathPlanners/intro/#deliberative","text":"","title":"Deliberative"},{"location":"automation/PathPlanners/intro/#graph-based-algorithms","text":"Graph-based algorithms search for an optimal path by superimposing a topological graph on a robot\u2019s configurational space. Some of the notable graph-based algorithms are: A-Star (A*) Dynamic A-Star (D*) Dijkstra\u2019s Algorithm Pros Resolution Optimal Resolution Complete Cons Time Comlexity Discrete States Discrete Action Sets Holonomicity(Can be controlled with a different modeling. Not implemented in given code.)","title":"Graph Based Algorithms"},{"location":"automation/PathPlanners/intro/#sampling-based-algorithms","text":"Algorithms based on sampling represent the configuration space with a roadmap or construct a tree by randomly sampling states in the configuration space. Pros PRM Probalistically Optimal Probalistically Complete Reasonable Computation Time RRT Probalistically Complete Near real time performance. Cons PRM Narrow corridor problem Roadmap generation not for dynamic environments Holonomicity(Can be controlled with a different modeling. Not implemented in given code.) RRT Narrow corridor problem Not optimal and voronoi bias Practically not complete Some of the notable sampling-based algorithms are: Rapidly exploring Random Tree (RRT) RRT Star (RRT*) Probabilistic Roadmap Method (PRM)","title":"Sampling Based Algorithms"},{"location":"automation/PathPlanners/intro/#optimization-based-algorithms","text":"It is a slow gradual process that works by making changes to the making slight and slow changes. Also, makes slight changes to its solutions slowly until getting the best solution. Pros Probabilistically Complete Probabitistically Optimal Cons Narrow corridor problem Computationally Expensive Practically not Complete One of the notable optimization-based algorithms is: Genetic Algorithm","title":"Optimization Based Algorithms"},{"location":"automation/PathPlanners/intro/#reactive","text":"Fuzzy Logic Algorithm Artificial Potential Fields","title":"Reactive"},{"location":"automation/PathPlanners/intro/#resources","text":"Github Repository Cornell Website . Youtube Video .","title":"Resources"},{"location":"automation/ROS/gettingstartedros/","text":"Getting Started with Robot Operating System What is ROS? ROS (Robot Operating System) is a BSD-licensed system for controlling robotic components from a PC. A ROS system is comprised of a number of independent nodes, each of which communicates with the other nodes using a publish/subscribe messaging model. For example, a particular sensor\u2019s driver might be implemented as a node, which publishes sensor data in a stream of messages. These messages could be consumed by any number of other nodes, including filters, loggers, and also higher-level systems such as guidance, pathfinding, etc. ROS is best thought of as a collection of tools and frameworks that make automating robotics projects much easier for someone who is absolutely new to it. Every ROS project has a specific structure that must be followed. It would be your responsibility to fill in the automation code and define how the various components of your code communicate with one another. After that, the underlying ROS framework handles the networking and connectivity. Resources : \u200b Youtube Tutorials A ROS system can be visualized as a graph where all the vertices are \u200bnodes and the edges between them are known as \u200btopics. In simple terms nodes are programs that perform a particular task and send out/receive data in the form of messages. These messages are exchanged between two nodes over the topic (edge) connecting them. Why ROS? Note that nodes in ROS do not have to be on the same system (multiple computers) or even of the same architecture! You could have a Arduino publishing messages, a laptop subscribing to them, and an Android phone driving motors. This makes ROS really flexible and adaptable to the needs of the user. ROS is also open source, maintained by many people. Basic Terminologies and Commands Nodes: A \u200bnode is an executable file (could be python or C++) which performs a specific task and communicates with other nodes through \u200b topics. Topics: Topics and are ways of communication between nodes. They depend from each node (see node definitions). Services rely on a query made by a given node or from terminal, getting a response from the node offering the service. ROS messages have to be specially defined for each user defined topic. Apart from the standard message types that come with ROS like \u200bstring, int32, etc. you can also define your custom message types in ROS for custom uses. Resources : Go through ROS wiki on Topics \u200b to know more. Note: A single node can simultaneously act as a subscriber to one topic and a publisher of another topic and a server for one service and the client for another. Packages: \u200b Packages are used to organise all of ROS\u2019s coding and software. ROS Nodes, libraries utilised in those codes, message and service definitions, as well as any dependencies, may all be contained in a package. Two files, CMakeLists.txt and package.xml, will be used throughout our workplan once we create the package. There is a separate directory src from these files. The code for the package\u2019s ROS nodes is stored here (as mentioned before, nodes are nothing but programmes that perform specific tasks). It must be built after the ROS package is created before it can be used. Resources : Go through catkins method of creating ROS Packages Go through ROS wiki Package Building Tutorial \u200b Catkin: Catkin is the build system used for ROS.catkin is the ROS build system: the set of tools that ROS uses to generate executable programs, libraries, scripts, and interfaces that other code can use. If you use C++ to write your ROS code, you need to know a fair bit about catkin. To build packages you must have a catkin workspace where all your projects are contained. You will have to use it to \u200b build \u200b not only yours but any other packages that may be in your workspace. A catkin workspace or package can be built running either of these two commands : catkin_make or catkin build in the root of your catkin workspace. Resources : Catkin wiki page \u200b and Catkin conceptual overview to learn more about catkin. Note: The command used to build a workspace should be consistent every time; for example, if the workspace was built using catkin make the first time while initialising it, all subsequent builds should use catkin make . To change the build process in an existing workspace, run the command catkin clean , which will remove everything but the workspace\u2019s source space (src folder). The desired command can then be used to rebuild it. Workspace: \u200bA ROS workspace is just a hierarchical directory where all of your linked ROS codes are stored. A workspace has packages, which contain, among other things, the code for nodes. On your computer, you can have numerous workspaces, but you can only work in one at a time. Resources : Catkin Workspace Tutorial \u200b Colcon: Colcon is another build system just like catkin. It comes with a vast array of features which can be used to organise your workspace. Similar to catkin, to build a workspace, you need to run colcon build in the root of the folder your workspace. Resources : Go through Colcon documentation for complete overview. Publisher-Subscriber Model Two nodes can exchange data in the form of messages asynchronously, usually used when a one way stream of information is involved.The object of a ROS node which publishes the data in the form of messages over a topic is called Publisher . The rate of publishing of messages can be defined by user. The data published by the publisher of one ROS node can be received through the object of a ROS node called Subscriber . Resources : Writing Publishers-Subcribers in C++\u200b \u200b Writing Publishers-Subcribers in Pytho\u200bn Client-Server Model Another common mode of communication, especially suited when there is a transaction style relationship between the two nodes is the service - consisting of a server and a client . The node which sends requests to a server is called Client . A special function that acts as a proxy between the client and server can be created. When called, the function sends a request to the server with the arguments passed to it as parameters. The node which constantly monitors for requests from the client is called Server .It does the required task independently of the client and returns the response when the task is completed. Resources : Writing Client-Service in C++\u200b \u200bWriting Client-Service in Python \u200b ROS Master: It is a central server to which all nodes are connected by default. It allows any node to look up information about any other node, essentially it is needed for connecting nodes within the system. A node gets the network address of another node from ROS Master. rosrun: On starting the ROS Master one can now start their own ROS nodes. For this ROS has a special command called rosrun which lets you run the executable files for their own node from anywhere by running following command (replace and appropriately) : - rosrun <package_name> <executable_name>.py Note : If using python, before attempting to run any ROS nodes that you have written, make sure that you have given executable permission to the code files. For more info on linux file permission look \u200b here\u200b by running the following command (replace appropriately) : - chmod u+x <executable_name>.py When one runs roscore or their own ROS node, the terminal is held until it is terminated. As a result, if you are running many nodes, each one must be run in a different terminal window. In such scenario \u200b terminator comes handy. \u200b roslaunch: There can be a lot of nodes in a ROS project, and launching them one by one can be a pain. roslaunch is a command that uses launch-files to launch a certain set of nodes all at once in a single terminal. These files usually contain a list of nodes and other related info and are generally stored in the launch directory inside a package. Resources : ROS Launch tutorial roscd: roscd is a command line tool which allows you to navigate or cd (change directory) to (in command line terms) a package without knowing its exact path. Note: The workspace in which the package is present needs to be sourced. E.g. If you wish to navigate into the turtlebot3_gazebo package you\u2019ll just type the following command in the terminal: roscd turtlebot3_gazebo rqt_graph: Once you have your system running, you can obtain a diagram along with other details of the system by running the rqt_graph command in another terminal window. General Understandings ROS starts with the ROS Master. The Master allows all other ROS pieces of software (Nodes) to find and talk to each other. That way, we do not have to ever specifically state \u201cSend this sensor data to that computer at 127.0.0.1. We can simply tell Node 1 to send messages to Node 2. Nodes do this by publishing and subscribing to Topics . Let\u2019s say we have a camera on our Robot. We want to be able to see the images from the camera, both on the Robot itself, and on another laptop. In our example, we have a Camera Node that takes care of communication with the camera, a Image Processing Node on the robot that process image data, and a Image Display Node that displays images on a screen. To start with, all Nodes have registered with the Master. Think of the Master as a lookup table where all the nodes go to find where exactly to send messages. In registering with the ROS Master, the Camera Node states that it will Publish a Topic called /image_data (for example). Both of the other Nodes register that they areSubscribed to the Topic /image_data. Thus, once the Camera Node receives some data from the Camera, it sends the /image_data message directly to the other two nodes. (Through what is essentially TCP/IP) Now you may be thinking, what if I want the Image Processing Node to request data from the Camera Node at a specific time? To do this, ROS implements Services. A Node can register a specific service with the ROS Master, just as it registers its messages. In the below example, the Image Processing Node first requests /image_data, the Camera Node gathers data from the Camera, and then sends the reply. ROS Parameters and Parameter Server A parameter server is a collection of values or parameters that nodes can retrieve or modify during runtime in response to requests made via command prompt, nodes, or launch files. Parameters are static, globally accessible values such as integers, floats, texts, and boolean values that can be saved separately or within a YAML file. Nodes may readily check the configuration status of the system and make changes if necessary because parameters are supposed to be gloablly accessible. Accessing and setting Parameters Via command line Parameters can be accessed, modified or deleted using the rosparam command line utility in the rosbash suite of terminal commands. To list all the parameters : rosparam list Or to list all the parameters in a specific namespace : rosparam list </namespace> To assign a value to an already existing parameter or to set a new one : rosparam set <parameter_name> <parameter_value> Note : You can also load the parameters into the parameter server from a YAML file using rosparam load <filename> <namepsace> To get/read a parameter value : rosparam get <parameter_name> Note : You can also dump/save the parameters into a YAML file from parameter server using rosparam dump <filename> <namespace> For more insights regarding the rosparam tool refer to ROS wiki . Via the rospy API library Parameters from the parameter server can be accessed and modified using rospy API library. This is generally used when the parameters are to be used by a node during the runtime. For more imformation on handling parameters using rospy API library go through rospy overview Via launch files Parameters can be set, created and loaded into the parameter server while creating launch files. For more information on handling parameters in launch files go through roslaunch wiki . For more information go through ROS wiki on Parameter Server Learning Materials A Gentle Introduction to ROS by Jason M.\u2019O Kane\u200b (use IIT BBS email-id to access link) Programming Robots with ROS by Morgon Quigley (use IIT BBS email-id to access link) Official ROS Tutorials .","title":"Getting Started with ROS"},{"location":"automation/ROS/gettingstartedros/#getting-started-with-robot-operating-system","text":"","title":"Getting Started with Robot Operating System"},{"location":"automation/ROS/gettingstartedros/#what-is-ros","text":"ROS (Robot Operating System) is a BSD-licensed system for controlling robotic components from a PC. A ROS system is comprised of a number of independent nodes, each of which communicates with the other nodes using a publish/subscribe messaging model. For example, a particular sensor\u2019s driver might be implemented as a node, which publishes sensor data in a stream of messages. These messages could be consumed by any number of other nodes, including filters, loggers, and also higher-level systems such as guidance, pathfinding, etc. ROS is best thought of as a collection of tools and frameworks that make automating robotics projects much easier for someone who is absolutely new to it. Every ROS project has a specific structure that must be followed. It would be your responsibility to fill in the automation code and define how the various components of your code communicate with one another. After that, the underlying ROS framework handles the networking and connectivity. Resources : \u200b Youtube Tutorials A ROS system can be visualized as a graph where all the vertices are \u200bnodes and the edges between them are known as \u200btopics. In simple terms nodes are programs that perform a particular task and send out/receive data in the form of messages. These messages are exchanged between two nodes over the topic (edge) connecting them.","title":"What is ROS?"},{"location":"automation/ROS/gettingstartedros/#why-ros","text":"Note that nodes in ROS do not have to be on the same system (multiple computers) or even of the same architecture! You could have a Arduino publishing messages, a laptop subscribing to them, and an Android phone driving motors. This makes ROS really flexible and adaptable to the needs of the user. ROS is also open source, maintained by many people.","title":"Why ROS?"},{"location":"automation/ROS/gettingstartedros/#basic-terminologies-and-commands","text":"Nodes: A \u200bnode is an executable file (could be python or C++) which performs a specific task and communicates with other nodes through \u200b topics. Topics: Topics and are ways of communication between nodes. They depend from each node (see node definitions). Services rely on a query made by a given node or from terminal, getting a response from the node offering the service. ROS messages have to be specially defined for each user defined topic. Apart from the standard message types that come with ROS like \u200bstring, int32, etc. you can also define your custom message types in ROS for custom uses. Resources : Go through ROS wiki on Topics \u200b to know more. Note: A single node can simultaneously act as a subscriber to one topic and a publisher of another topic and a server for one service and the client for another. Packages: \u200b Packages are used to organise all of ROS\u2019s coding and software. ROS Nodes, libraries utilised in those codes, message and service definitions, as well as any dependencies, may all be contained in a package. Two files, CMakeLists.txt and package.xml, will be used throughout our workplan once we create the package. There is a separate directory src from these files. The code for the package\u2019s ROS nodes is stored here (as mentioned before, nodes are nothing but programmes that perform specific tasks). It must be built after the ROS package is created before it can be used. Resources : Go through catkins method of creating ROS Packages Go through ROS wiki Package Building Tutorial \u200b Catkin: Catkin is the build system used for ROS.catkin is the ROS build system: the set of tools that ROS uses to generate executable programs, libraries, scripts, and interfaces that other code can use. If you use C++ to write your ROS code, you need to know a fair bit about catkin. To build packages you must have a catkin workspace where all your projects are contained. You will have to use it to \u200b build \u200b not only yours but any other packages that may be in your workspace. A catkin workspace or package can be built running either of these two commands : catkin_make or catkin build in the root of your catkin workspace. Resources : Catkin wiki page \u200b and Catkin conceptual overview to learn more about catkin. Note: The command used to build a workspace should be consistent every time; for example, if the workspace was built using catkin make the first time while initialising it, all subsequent builds should use catkin make . To change the build process in an existing workspace, run the command catkin clean , which will remove everything but the workspace\u2019s source space (src folder). The desired command can then be used to rebuild it. Workspace: \u200bA ROS workspace is just a hierarchical directory where all of your linked ROS codes are stored. A workspace has packages, which contain, among other things, the code for nodes. On your computer, you can have numerous workspaces, but you can only work in one at a time. Resources : Catkin Workspace Tutorial \u200b Colcon: Colcon is another build system just like catkin. It comes with a vast array of features which can be used to organise your workspace. Similar to catkin, to build a workspace, you need to run colcon build in the root of the folder your workspace. Resources : Go through Colcon documentation for complete overview. Publisher-Subscriber Model Two nodes can exchange data in the form of messages asynchronously, usually used when a one way stream of information is involved.The object of a ROS node which publishes the data in the form of messages over a topic is called Publisher . The rate of publishing of messages can be defined by user. The data published by the publisher of one ROS node can be received through the object of a ROS node called Subscriber . Resources : Writing Publishers-Subcribers in C++\u200b \u200b Writing Publishers-Subcribers in Pytho\u200bn Client-Server Model Another common mode of communication, especially suited when there is a transaction style relationship between the two nodes is the service - consisting of a server and a client . The node which sends requests to a server is called Client . A special function that acts as a proxy between the client and server can be created. When called, the function sends a request to the server with the arguments passed to it as parameters. The node which constantly monitors for requests from the client is called Server .It does the required task independently of the client and returns the response when the task is completed. Resources : Writing Client-Service in C++\u200b \u200bWriting Client-Service in Python \u200b ROS Master: It is a central server to which all nodes are connected by default. It allows any node to look up information about any other node, essentially it is needed for connecting nodes within the system. A node gets the network address of another node from ROS Master. rosrun: On starting the ROS Master one can now start their own ROS nodes. For this ROS has a special command called rosrun which lets you run the executable files for their own node from anywhere by running following command (replace and appropriately) : - rosrun <package_name> <executable_name>.py Note : If using python, before attempting to run any ROS nodes that you have written, make sure that you have given executable permission to the code files. For more info on linux file permission look \u200b here\u200b by running the following command (replace appropriately) : - chmod u+x <executable_name>.py When one runs roscore or their own ROS node, the terminal is held until it is terminated. As a result, if you are running many nodes, each one must be run in a different terminal window. In such scenario \u200b terminator comes handy. \u200b roslaunch: There can be a lot of nodes in a ROS project, and launching them one by one can be a pain. roslaunch is a command that uses launch-files to launch a certain set of nodes all at once in a single terminal. These files usually contain a list of nodes and other related info and are generally stored in the launch directory inside a package. Resources : ROS Launch tutorial roscd: roscd is a command line tool which allows you to navigate or cd (change directory) to (in command line terms) a package without knowing its exact path. Note: The workspace in which the package is present needs to be sourced. E.g. If you wish to navigate into the turtlebot3_gazebo package you\u2019ll just type the following command in the terminal: roscd turtlebot3_gazebo rqt_graph: Once you have your system running, you can obtain a diagram along with other details of the system by running the rqt_graph command in another terminal window.","title":"Basic Terminologies and Commands"},{"location":"automation/ROS/gettingstartedros/#general-understandings","text":"ROS starts with the ROS Master. The Master allows all other ROS pieces of software (Nodes) to find and talk to each other. That way, we do not have to ever specifically state \u201cSend this sensor data to that computer at 127.0.0.1. We can simply tell Node 1 to send messages to Node 2. Nodes do this by publishing and subscribing to Topics . Let\u2019s say we have a camera on our Robot. We want to be able to see the images from the camera, both on the Robot itself, and on another laptop. In our example, we have a Camera Node that takes care of communication with the camera, a Image Processing Node on the robot that process image data, and a Image Display Node that displays images on a screen. To start with, all Nodes have registered with the Master. Think of the Master as a lookup table where all the nodes go to find where exactly to send messages. In registering with the ROS Master, the Camera Node states that it will Publish a Topic called /image_data (for example). Both of the other Nodes register that they areSubscribed to the Topic /image_data. Thus, once the Camera Node receives some data from the Camera, it sends the /image_data message directly to the other two nodes. (Through what is essentially TCP/IP) Now you may be thinking, what if I want the Image Processing Node to request data from the Camera Node at a specific time? To do this, ROS implements Services. A Node can register a specific service with the ROS Master, just as it registers its messages. In the below example, the Image Processing Node first requests /image_data, the Camera Node gathers data from the Camera, and then sends the reply.","title":"General Understandings"},{"location":"automation/ROS/gettingstartedros/#ros-parameters-and-parameter-server","text":"A parameter server is a collection of values or parameters that nodes can retrieve or modify during runtime in response to requests made via command prompt, nodes, or launch files. Parameters are static, globally accessible values such as integers, floats, texts, and boolean values that can be saved separately or within a YAML file. Nodes may readily check the configuration status of the system and make changes if necessary because parameters are supposed to be gloablly accessible.","title":"ROS Parameters and Parameter Server"},{"location":"automation/ROS/gettingstartedros/#accessing-and-setting-parameters","text":"","title":"Accessing and setting Parameters"},{"location":"automation/ROS/gettingstartedros/#via-command-line","text":"Parameters can be accessed, modified or deleted using the rosparam command line utility in the rosbash suite of terminal commands. To list all the parameters : rosparam list Or to list all the parameters in a specific namespace : rosparam list </namespace> To assign a value to an already existing parameter or to set a new one : rosparam set <parameter_name> <parameter_value> Note : You can also load the parameters into the parameter server from a YAML file using rosparam load <filename> <namepsace> To get/read a parameter value : rosparam get <parameter_name> Note : You can also dump/save the parameters into a YAML file from parameter server using rosparam dump <filename> <namespace> For more insights regarding the rosparam tool refer to ROS wiki .","title":"Via command line"},{"location":"automation/ROS/gettingstartedros/#via-the-rospy-api-library","text":"Parameters from the parameter server can be accessed and modified using rospy API library. This is generally used when the parameters are to be used by a node during the runtime. For more imformation on handling parameters using rospy API library go through rospy overview","title":"Via the rospy API library"},{"location":"automation/ROS/gettingstartedros/#via-launch-files","text":"Parameters can be set, created and loaded into the parameter server while creating launch files. For more information on handling parameters in launch files go through roslaunch wiki . For more information go through ROS wiki on Parameter Server","title":"Via launch files"},{"location":"automation/ROS/gettingstartedros/#learning-materials","text":"A Gentle Introduction to ROS by Jason M.\u2019O Kane\u200b (use IIT BBS email-id to access link) Programming Robots with ROS by Morgon Quigley (use IIT BBS email-id to access link) Official ROS Tutorials .","title":"Learning Materials"},{"location":"automation/ROS/installation/","text":"Installation Setting up Operating System Ubuntu 22.04 is recommended for ROS if you already have Ubuntu 20.04, that is also fine although for versions older than this we recommend upgrading to 22.04. For those who currently have Windows as the only OS on their machine, the best way to start using Ubuntu would be to dual boot . Here is a guide on how to do this or you can go through this Youtube video . For MacOS users, dual booting is an option but it is recommend to use a virtual machine. If you are unable to dual boot for any reason, you can try setting up a virtual machine . The first step in this is to install a virtualisation software. For Windows you can use either VirtualBox (free) or Vmware Workstation and for MacOS either VirtualBox (free), Vmware Fusion or Parallels. After getting one of the above, follow the instructions given here (skip ahead to the Download Image section). After completing the given procedure you will be equipped with all the basic tools required for Robotics including ROS,catkin and git. In the unfortunate case that the above options do not work , for Windows users there is still a way - WSL . Do be warned however, this path is fraught with frustration and much debugging. Only continue if you have exhausted other options. For a guide on setting up WSL for ROS, look here . For those whom none of the above are possible, consider using the online browser based ROS Development Studio . Keep in mind that it has a limited access time per week and performance may be questionable. Installing Robot Operating System (ROS) For Ubuntu 22.04 users : ROS Humble Hawksbill For Ubuntu 20.04 users : ROS Noetic Code Editors : VSCode is recommended for boosting productivity\u200b which has plugins for python and ROS. A comprehensive guide for how to integrate ROS into your favourite IDE can be found \u200bhere \u200b. For installing developed ROS packages replace with name of the ROS package. sudo apt install ros- $ROS_DISTRO -<package_name> Because of having conflicting python path Anaconda and ROS can\u2019t be used in same. For dealing with this edit your .bashrc file by commenting the anaconda python path like this // export PATH = \"/home//anaconda3/bin: $PATH \" It is recommended to source the workspace on startup by editing your .bashrc file by including following line. Replace with the path of your workspace source <workspace_path>/devel/setup.bash Note : Two workspaces can\u2019t be sourced at the same time.","title":"Installation"},{"location":"automation/ROS/installation/#installation","text":"","title":"Installation"},{"location":"automation/ROS/installation/#setting-up-operating-system","text":"Ubuntu 22.04 is recommended for ROS if you already have Ubuntu 20.04, that is also fine although for versions older than this we recommend upgrading to 22.04. For those who currently have Windows as the only OS on their machine, the best way to start using Ubuntu would be to dual boot . Here is a guide on how to do this or you can go through this Youtube video . For MacOS users, dual booting is an option but it is recommend to use a virtual machine. If you are unable to dual boot for any reason, you can try setting up a virtual machine . The first step in this is to install a virtualisation software. For Windows you can use either VirtualBox (free) or Vmware Workstation and for MacOS either VirtualBox (free), Vmware Fusion or Parallels. After getting one of the above, follow the instructions given here (skip ahead to the Download Image section). After completing the given procedure you will be equipped with all the basic tools required for Robotics including ROS,catkin and git. In the unfortunate case that the above options do not work , for Windows users there is still a way - WSL . Do be warned however, this path is fraught with frustration and much debugging. Only continue if you have exhausted other options. For a guide on setting up WSL for ROS, look here . For those whom none of the above are possible, consider using the online browser based ROS Development Studio . Keep in mind that it has a limited access time per week and performance may be questionable.","title":"Setting up Operating System"},{"location":"automation/ROS/installation/#installing-robot-operating-system-ros","text":"For Ubuntu 22.04 users : ROS Humble Hawksbill For Ubuntu 20.04 users : ROS Noetic Code Editors : VSCode is recommended for boosting productivity\u200b which has plugins for python and ROS. A comprehensive guide for how to integrate ROS into your favourite IDE can be found \u200bhere \u200b. For installing developed ROS packages replace with name of the ROS package. sudo apt install ros- $ROS_DISTRO -<package_name> Because of having conflicting python path Anaconda and ROS can\u2019t be used in same. For dealing with this edit your .bashrc file by commenting the anaconda python path like this // export PATH = \"/home//anaconda3/bin: $PATH \" It is recommended to source the workspace on startup by editing your .bashrc file by including following line. Replace with the path of your workspace source <workspace_path>/devel/setup.bash Note : Two workspaces can\u2019t be sourced at the same time.","title":"Installing Robot Operating System (ROS)"},{"location":"automation/simulation/intro/","text":"Introduction Robotics automation requires simulation as a key component. They give you a flexible environment to rapidly test your code for errors and performance, as well as to try out novel concepts. Although robots are getting easier to access all the time, we\u2019re still not at the point where you can test your program on them directly.","title":"Introduction"},{"location":"automation/simulation/intro/#introduction","text":"Robotics automation requires simulation as a key component. They give you a flexible environment to rapidly test your code for errors and performance, as well as to try out novel concepts. Although robots are getting easier to access all the time, we\u2019re still not at the point where you can test your program on them directly.","title":"Introduction"},{"location":"automation/simulation/gazebo/basics/","text":"Gazebo Gazebo is the most popular physics simulator for robotics development. It can simulate robots in a 3D environment and can be fully integrated into ROS integrated with Gazebo using the gazebo_ros ROS package. You can interface your robots in the simulation using ROS and control them using ROS messages and services. 2.1 Installation Gazebo and gazebo_ros package are both automatically installed when you install ROS. To make sure you have all the ROS packages necessary for running Gazebo simulations are installed sudo apt-get install ros-melodic-gazebo-* Gazebo can also be installed independently of ROS by using the command curl -sSL http://get.gazebosim.org | sh in the terminal for Ubuntu. Alternative methods of installing gazebo and installation guides for installling gazebo on other operating systems can be found here . 2.2 Getting Started You can launch the Gazebo GUI simulator window by just running the command gazebo in the terminal. To understand how to spawn robot models in gazebo it is recommended to first get familiar with .urdf , .sdf and .world files. You can refer to the Robot Description section to read about these. A file can be opened simply by running the follwing command in the command line: gazebo <path/to/file> 2.3 Client Server Separation Running the gazebo command starts two programmes, namely the gzserver and the gzclient . The gzserver is responsible for doing most of the \u2018processing\u2019 part, i.e., doing all the calculations for the simulation, sensor data generation, basically all the backend processing. The gzclient is responsible for generating the user interface. It provides a nice visualization of simulation, and convenient controls over various simulation properties. gzserver is capable of running independently of gzclient and vice-versa. For eg; in many cases gzserver is run on a cloud computer in case enough processing power is not available locally. Try running the command gzserver in one terminal and the command gzclient in other terminal. You will notice that the gazebo window pops up only when you run the gzclient command. The term run headless is used to refer to cases when only the gzserver is being used. 2.4 Environment Variables in Gazebo Environment Variables are variables whose values are valid throughout the system and are used by different applications and the OS for several purposes. These environment variables can contain different types of things ranging from parameter values to paths to certain files depending on what they are used for. Gazebo uses various such environment variables too. These variables and their uses are described below: GAZEBO_MODEL_PATH : This environment variable contains colon-separated paths to different directories where gazebo will search for models. Models refers to the sdf file describing the robot. For more information on this refer to the Robot Description section of the handbook. GAZEBO_RESOURCE_PATH: This environment variable contains colon-separated set of directories where Gazebo will search for other resources such as world and media files. For eg. if you run the command gazebo worlds/pioneer2dx.world . You will see gazebo window pop up with an empty environment. In fact you can execute this command in any directory. You might ask how does gazebo know where the worlds directory is stored?. The answer is that the path to the world directory, that is /usr/share/gazebo-7/worlds is stored in the environment variable GAZEBO_RESOURCE_PATH . GAZEBO_MASTER__URI: URI of the Gazebo master . This specifies the IP and port where the server(gzserver) will be started and tells the clients(gzclients) where to connect to. GAZEBO_PLUGIN_PATH: colon-separated set of directories where Gazebo will search for the plugin shared libraries at runtime. Plugins are basically..... You can refer to this section to read more about gazebo plugins. GAZEBO_MODEL_DATABASE_URI: URI of the online model database where Gazebo will download models from. The default values of these environment variables are stored in the <install_path>/share/gazebo/setup.sh file. If you want to change the values of this variables for example, add or remove a path from GITHUB_MODEL_PATH you will have to source this file first using the command source <install_path>/share/gazebo/setup.sh Once this is done you can edit that value of the variable by editing the value by opening the setup.sh file or directly thorugh the terminal/command line using the command: GITHUB_MODEL_PATH=$GITHUB_MODEL_PATH:<path of the directory you want to add>","title":"Basics of Gazebo"},{"location":"automation/simulation/gazebo/basics/#gazebo","text":"Gazebo is the most popular physics simulator for robotics development. It can simulate robots in a 3D environment and can be fully integrated into ROS integrated with Gazebo using the gazebo_ros ROS package. You can interface your robots in the simulation using ROS and control them using ROS messages and services.","title":"Gazebo"},{"location":"automation/simulation/gazebo/basics/#21-installation","text":"Gazebo and gazebo_ros package are both automatically installed when you install ROS. To make sure you have all the ROS packages necessary for running Gazebo simulations are installed sudo apt-get install ros-melodic-gazebo-* Gazebo can also be installed independently of ROS by using the command curl -sSL http://get.gazebosim.org | sh in the terminal for Ubuntu. Alternative methods of installing gazebo and installation guides for installling gazebo on other operating systems can be found here .","title":"2.1 Installation"},{"location":"automation/simulation/gazebo/basics/#22-getting-started","text":"You can launch the Gazebo GUI simulator window by just running the command gazebo in the terminal. To understand how to spawn robot models in gazebo it is recommended to first get familiar with .urdf , .sdf and .world files. You can refer to the Robot Description section to read about these. A file can be opened simply by running the follwing command in the command line: gazebo <path/to/file>","title":"2.2 Getting Started"},{"location":"automation/simulation/gazebo/basics/#23-client-server-separation","text":"Running the gazebo command starts two programmes, namely the gzserver and the gzclient . The gzserver is responsible for doing most of the \u2018processing\u2019 part, i.e., doing all the calculations for the simulation, sensor data generation, basically all the backend processing. The gzclient is responsible for generating the user interface. It provides a nice visualization of simulation, and convenient controls over various simulation properties. gzserver is capable of running independently of gzclient and vice-versa. For eg; in many cases gzserver is run on a cloud computer in case enough processing power is not available locally. Try running the command gzserver in one terminal and the command gzclient in other terminal. You will notice that the gazebo window pops up only when you run the gzclient command. The term run headless is used to refer to cases when only the gzserver is being used.","title":"2.3 Client Server Separation"},{"location":"automation/simulation/gazebo/basics/#24-environment-variables-in-gazebo","text":"Environment Variables are variables whose values are valid throughout the system and are used by different applications and the OS for several purposes. These environment variables can contain different types of things ranging from parameter values to paths to certain files depending on what they are used for. Gazebo uses various such environment variables too. These variables and their uses are described below: GAZEBO_MODEL_PATH : This environment variable contains colon-separated paths to different directories where gazebo will search for models. Models refers to the sdf file describing the robot. For more information on this refer to the Robot Description section of the handbook. GAZEBO_RESOURCE_PATH: This environment variable contains colon-separated set of directories where Gazebo will search for other resources such as world and media files. For eg. if you run the command gazebo worlds/pioneer2dx.world . You will see gazebo window pop up with an empty environment. In fact you can execute this command in any directory. You might ask how does gazebo know where the worlds directory is stored?. The answer is that the path to the world directory, that is /usr/share/gazebo-7/worlds is stored in the environment variable GAZEBO_RESOURCE_PATH . GAZEBO_MASTER__URI: URI of the Gazebo master . This specifies the IP and port where the server(gzserver) will be started and tells the clients(gzclients) where to connect to. GAZEBO_PLUGIN_PATH: colon-separated set of directories where Gazebo will search for the plugin shared libraries at runtime. Plugins are basically..... You can refer to this section to read more about gazebo plugins. GAZEBO_MODEL_DATABASE_URI: URI of the online model database where Gazebo will download models from. The default values of these environment variables are stored in the <install_path>/share/gazebo/setup.sh file. If you want to change the values of this variables for example, add or remove a path from GITHUB_MODEL_PATH you will have to source this file first using the command source <install_path>/share/gazebo/setup.sh Once this is done you can edit that value of the variable by editing the value by opening the setup.sh file or directly thorugh the terminal/command line using the command: GITHUB_MODEL_PATH=$GITHUB_MODEL_PATH:<path of the directory you want to add>","title":"2.4 Environment Variables in Gazebo"},{"location":"automation/simulation/stdr/Basics/","text":"General Introduction STDR is a simple two dimensional robot simulator. It is very useful in cases where there is no need for computationally costly 3-D simulation of robots. It is computationally light and serves the purpose good. Hence it is very useful for learning based robotics or for multi robot simulation. Installation For ROS Humble Hawksbil , stdr can be installed using apt-get. For ROS Melodic, it is advisible to install stdr from source . Architecture Overview (Reference: ROS Wiki ) Basic Usage The stdr_launchers package contains launch files basic usage. However, custom launch files can be created to serve personal purposes easily. Some of the launch files are server_no_map.launch launches the stdr server without any map, robot or the gui. server_with_map_and_gui.launch launches the serve with preloaded map and gui. server_with_map_and_gui_plus_robot.launch launches the stdr_server, with preloaded map and robot along with the gui You can also launch Rviz with a preset config file using rviz.launch file in the stdr_launchers package. Robot Namespaces The topics corresponding to each robot have a unique namespace attached to it. For example the first robot launched has a namespace /robot0 . Published topics pertaining to that robot are published as /robot0/topic_name . Note that whenever a new robot is spawned the robot number is incremented by 1. This happens even though you delete a robot. such namespacing avoids conflicts of topic names when doing multi robot simulation. References For more information refer the stdr_simulator page in ROS Wiki . The github repository for stdr_simulator.","title":"Basics"},{"location":"automation/simulation/stdr/Basics/#general-introduction","text":"STDR is a simple two dimensional robot simulator. It is very useful in cases where there is no need for computationally costly 3-D simulation of robots. It is computationally light and serves the purpose good. Hence it is very useful for learning based robotics or for multi robot simulation.","title":"General Introduction"},{"location":"automation/simulation/stdr/Basics/#installation","text":"For ROS Humble Hawksbil , stdr can be installed using apt-get. For ROS Melodic, it is advisible to install stdr from source .","title":"Installation"},{"location":"automation/simulation/stdr/Basics/#architecture-overview","text":"(Reference: ROS Wiki )","title":"Architecture Overview"},{"location":"automation/simulation/stdr/Basics/#basic-usage","text":"The stdr_launchers package contains launch files basic usage. However, custom launch files can be created to serve personal purposes easily. Some of the launch files are server_no_map.launch launches the stdr server without any map, robot or the gui. server_with_map_and_gui.launch launches the serve with preloaded map and gui. server_with_map_and_gui_plus_robot.launch launches the stdr_server, with preloaded map and robot along with the gui You can also launch Rviz with a preset config file using rviz.launch file in the stdr_launchers package.","title":"Basic Usage"},{"location":"automation/simulation/stdr/Basics/#robot-namespaces","text":"The topics corresponding to each robot have a unique namespace attached to it. For example the first robot launched has a namespace /robot0 . Published topics pertaining to that robot are published as /robot0/topic_name . Note that whenever a new robot is spawned the robot number is incremented by 1. This happens even though you delete a robot. such namespacing avoids conflicts of topic names when doing multi robot simulation.","title":"Robot Namespaces"},{"location":"automation/simulation/stdr/Basics/#references","text":"For more information refer the stdr_simulator page in ROS Wiki . The github repository for stdr_simulator.","title":"References"},{"location":"electronics/intro/","text":"Introduction Electronics are essential to robotics, from connecting microprocessors to building logical circuits. At the end of the day, every action a robot takes is ultimately based on a signal it has received. Any robotics project that requires electronics must complete duties like establishing the power source, connecting sensors, establishing the compute unit, etc. Most robots include a processing unit on board that gathers information from sensors and does all calculations to determine the actions the robot should take. Popular robot processors include the Raspberry Pi, Nvidia Jetson, Arduino, and others.","title":"Introduction"},{"location":"electronics/intro/#introduction","text":"Electronics are essential to robotics, from connecting microprocessors to building logical circuits. At the end of the day, every action a robot takes is ultimately based on a signal it has received. Any robotics project that requires electronics must complete duties like establishing the power source, connecting sensors, establishing the compute unit, etc. Most robots include a processing unit on board that gathers information from sensors and does all calculations to determine the actions the robot should take. Popular robot processors include the Raspberry Pi, Nvidia Jetson, Arduino, and others.","title":"Introduction"},{"location":"electronics/Development_Boards/Arduino/","text":"Arduino The Arduino is basically a very accessible and easy to program microcontroller. Unlike other microcontrollers, which need knowledge of registers and ports, the Arduino is programmed by a very basic C-derived language. This video explains what an Arduino is, what it is capable of, and the numerous projects one can use it for. Arduino Board Layout The above diagram shows an Arduino UNO board with all the parts labelled and explained below: USB Port: Arduino can be powered by connecting it to your computer using a USB cable. It is also used for uploading code and communicating via the serial port. Power Jack: Used to power an arduino directly from a wall adaptor. Voltage Regulator: Controls and stabilises the voltage used by the Arduino and its components. Crystal Oscillator: A microcontroller is a clock based device. The crystal oscillator present on the arduino generates a clock of frequency 16MHz. Reset controllers: Resetting the arduino board starts the execution of a program from the beginning. Arduino can be reset in 2 ways : by pressing the reset button (17) and sending a 0V signal to the RESET pin (5). 3.3V power 5V power GND (0V) VIN: This pin can be used to power the arduino board from an external power source, from 7-20V. Analog Pins: These pins (labeled A0-A5) can be used to read continuous analog values (between 0 and 5V). They are often used to interface the Arduino with analog sensors. Main Microcontroller: This IC is the main microcontroller, that executes the code you program it with. ICSP Pin: Can be used to program the arduino board\u2019s firmware. For advanced users only. Power LED indicator: Indicates whether the board is powered up correctly. TX/RX LEDs: The TX/RX pins flash to indicate transfer/receival of serial data between the computer and Arduino. Digital I/O Pins: These pins can be programmed as input/output pins. When used as output, they can be set HIGH (+5V) or LOW (0V). Analog Reference(AREF): Can be used to set an external reference voltage(0-5V) as the upper limit for analog input pins. Reset Button: Pressing it causes the Arduino to restart its code. The Blink Sketch The Blink sketch is like the \u201cHello World\u201d program in the Arduino world. It simply consists of blinking the onboard LED (labeled \u2018L\u2019). No actual circuit connections are required! Code You can copy the code from here . How to code an Arduino in Arduino IDE Download and install Arduino Software (IDE) from here . The Integrated Development Environment (IDE) is a common coding environment for all arduino boards. Open the IDE and a new sketch will open up which would look like the image below. Sketch is just a name arduino uses for a program. Then just paste the entire code here. Now connect your Arduino UNO board to your PC using an A B USB cable and select the option \u201cArduino/Genuino Uno\u201d under Tools > Board menu. Also make sure to select the correct port through which the PC is connected to the board under Tools > Port menu. Click on the \u201ctick\u201d button in upper left corner to compile the code and check for errors. After resolving any and all errors click on the \u201carrow\u201d button next to it to upload the code to the board. After successful upload the Arduino Uno will start executing the code while drawing power from the PC through the USB cable. Explanation Every Arduino sketch must have two particular functions: void setup() The setup() function is called when a sketch starts and will only run once, after each powerup or reset of the Arduino board. void loop() This function does precisely what its name suggests, that is loops consecutively, allowing your program to change and respond. Whatever code you write inside loop() will keep running as long as the Arduino is receiving power. Let us examine the Blink sketch now, line by line. int led = 13 ; This line assigns a name to the pin that the LED is attached to, i.e. pin 13. Then we have the setup() function, which runs only once. It includes the following line. pinMode ( led , OUTPUT ); This tells the Arduino to configure that pin as an output. Then we have the following loop() function. void loop () { digitalWrite ( led , HIGH ); // turn the LED on (HIGH is the voltage level) delay ( 1000 ); // wait for a second digitalWrite ( led , LOW ); // turn the LED off by making the voltage LOW delay ( 1000 ); // wait for a second } The digitalWrite() function tells a pin to either switch on (HIGH, or +5V) or off (LOW, or 0V). The delay() function tells the Arduino to wait for a specified number of milliseconds. Reading Analog Values The following circuit reads the voltage from a potentiometer and sends it via USB to the serial port. Schematic Code Copy the code from here and paste it into a new sketch in the Arduino IDE and upload the code to the board. After successful uploading open the serial monitor in the IDE by clicking on its button on top right corner. Trying varying the potentiometer\u2019s knob - you should see the stream of values of the serial monitor change. Explanation Whenever the serial port is to be used, it should be initialised with the following line inside void setup(). The 9600 refers to the communication speed in bits-per-second. Serial . begin ( 9600 ); The analogRead function reads the voltage at an analog pin and linearly converts it to a value between 0 and 1023. The Serial.println() function prints a variable to the serial monitor, followed by a newline (using Serial.print() to print data without the newline). The delay(1) is to limit the amount of data printed to the serial monitor. References For some more detailed tutorials do read the documentation of Arduino . For some video tutorials check out Jeremy Blum\u2019s playlist for Arduino. For more DIY project ideas and inspirations check out Great Scott\u2019s youtube channel. To read more about the projects made by people using Arduino, check out Arduino\u2019s blog as well.","title":"Arduino"},{"location":"electronics/Development_Boards/Arduino/#arduino","text":"The Arduino is basically a very accessible and easy to program microcontroller. Unlike other microcontrollers, which need knowledge of registers and ports, the Arduino is programmed by a very basic C-derived language. This video explains what an Arduino is, what it is capable of, and the numerous projects one can use it for.","title":"Arduino"},{"location":"electronics/Development_Boards/Arduino/#arduino-board-layout","text":"The above diagram shows an Arduino UNO board with all the parts labelled and explained below: USB Port: Arduino can be powered by connecting it to your computer using a USB cable. It is also used for uploading code and communicating via the serial port. Power Jack: Used to power an arduino directly from a wall adaptor. Voltage Regulator: Controls and stabilises the voltage used by the Arduino and its components. Crystal Oscillator: A microcontroller is a clock based device. The crystal oscillator present on the arduino generates a clock of frequency 16MHz. Reset controllers: Resetting the arduino board starts the execution of a program from the beginning. Arduino can be reset in 2 ways : by pressing the reset button (17) and sending a 0V signal to the RESET pin (5). 3.3V power 5V power GND (0V) VIN: This pin can be used to power the arduino board from an external power source, from 7-20V. Analog Pins: These pins (labeled A0-A5) can be used to read continuous analog values (between 0 and 5V). They are often used to interface the Arduino with analog sensors. Main Microcontroller: This IC is the main microcontroller, that executes the code you program it with. ICSP Pin: Can be used to program the arduino board\u2019s firmware. For advanced users only. Power LED indicator: Indicates whether the board is powered up correctly. TX/RX LEDs: The TX/RX pins flash to indicate transfer/receival of serial data between the computer and Arduino. Digital I/O Pins: These pins can be programmed as input/output pins. When used as output, they can be set HIGH (+5V) or LOW (0V). Analog Reference(AREF): Can be used to set an external reference voltage(0-5V) as the upper limit for analog input pins. Reset Button: Pressing it causes the Arduino to restart its code.","title":"Arduino Board Layout"},{"location":"electronics/Development_Boards/Arduino/#the-blink-sketch","text":"The Blink sketch is like the \u201cHello World\u201d program in the Arduino world. It simply consists of blinking the onboard LED (labeled \u2018L\u2019). No actual circuit connections are required!","title":"The Blink Sketch"},{"location":"electronics/Development_Boards/Arduino/#code","text":"You can copy the code from here .","title":"Code"},{"location":"electronics/Development_Boards/Arduino/#how-to-code-an-arduino-in-arduino-ide","text":"Download and install Arduino Software (IDE) from here . The Integrated Development Environment (IDE) is a common coding environment for all arduino boards. Open the IDE and a new sketch will open up which would look like the image below. Sketch is just a name arduino uses for a program. Then just paste the entire code here. Now connect your Arduino UNO board to your PC using an A B USB cable and select the option \u201cArduino/Genuino Uno\u201d under Tools > Board menu. Also make sure to select the correct port through which the PC is connected to the board under Tools > Port menu. Click on the \u201ctick\u201d button in upper left corner to compile the code and check for errors. After resolving any and all errors click on the \u201carrow\u201d button next to it to upload the code to the board. After successful upload the Arduino Uno will start executing the code while drawing power from the PC through the USB cable.","title":"How to code an Arduino in Arduino IDE"},{"location":"electronics/Development_Boards/Arduino/#explanation","text":"Every Arduino sketch must have two particular functions: void setup() The setup() function is called when a sketch starts and will only run once, after each powerup or reset of the Arduino board. void loop() This function does precisely what its name suggests, that is loops consecutively, allowing your program to change and respond. Whatever code you write inside loop() will keep running as long as the Arduino is receiving power. Let us examine the Blink sketch now, line by line. int led = 13 ; This line assigns a name to the pin that the LED is attached to, i.e. pin 13. Then we have the setup() function, which runs only once. It includes the following line. pinMode ( led , OUTPUT ); This tells the Arduino to configure that pin as an output. Then we have the following loop() function. void loop () { digitalWrite ( led , HIGH ); // turn the LED on (HIGH is the voltage level) delay ( 1000 ); // wait for a second digitalWrite ( led , LOW ); // turn the LED off by making the voltage LOW delay ( 1000 ); // wait for a second } The digitalWrite() function tells a pin to either switch on (HIGH, or +5V) or off (LOW, or 0V). The delay() function tells the Arduino to wait for a specified number of milliseconds.","title":"Explanation"},{"location":"electronics/Development_Boards/Arduino/#reading-analog-values","text":"The following circuit reads the voltage from a potentiometer and sends it via USB to the serial port.","title":"Reading Analog Values"},{"location":"electronics/Development_Boards/Arduino/#schematic","text":"","title":"Schematic"},{"location":"electronics/Development_Boards/Arduino/#code_1","text":"Copy the code from here and paste it into a new sketch in the Arduino IDE and upload the code to the board. After successful uploading open the serial monitor in the IDE by clicking on its button on top right corner. Trying varying the potentiometer\u2019s knob - you should see the stream of values of the serial monitor change.","title":"Code"},{"location":"electronics/Development_Boards/Arduino/#explanation_1","text":"Whenever the serial port is to be used, it should be initialised with the following line inside void setup(). The 9600 refers to the communication speed in bits-per-second. Serial . begin ( 9600 ); The analogRead function reads the voltage at an analog pin and linearly converts it to a value between 0 and 1023. The Serial.println() function prints a variable to the serial monitor, followed by a newline (using Serial.print() to print data without the newline). The delay(1) is to limit the amount of data printed to the serial monitor.","title":"Explanation"},{"location":"electronics/Development_Boards/Arduino/#references","text":"For some more detailed tutorials do read the documentation of Arduino . For some video tutorials check out Jeremy Blum\u2019s playlist for Arduino. For more DIY project ideas and inspirations check out Great Scott\u2019s youtube channel. To read more about the projects made by people using Arduino, check out Arduino\u2019s blog as well.","title":"References"},{"location":"electronics/Development_Boards/ESP32/","text":"ESP32 Introduction ESP32 is a series of feature-rich MCU with integrated Wi-Fi and Bluetooth connectivity for a wide range of applications. Espressif Systems, China, produce it.ESP32 is cheap and nearly ten times faster than Arduino Uno and is a 32-bit versatile device. Developers of ESP32 IC made a small module board with edge castellations. One popular version of such a module board is called ESP-WROOM-32. It is a dual-core, 32-bit microcontroller unit, and all the cores can be controlled individually. It has integrated Wi-Fi, Bluetooth, and Bluetooth Low Energy with multiple digital and analog I/O pins. Comparison Of ESP32 and Arduino Uno Parameter ESP32 ARDUINO UNO Processor Xtensa dual-core ATMega328P Number of Cores 2 1 Architecture 32 bit 8 bit Operating Voltage 2.2 to 3.6V 5V CPU Frequency 160 or 240 MHz 16 MHz WiFi YES NO Bluetooth YES NO RAM 512 KB 2 KB Flash 16 MB 32 KB GPIO pins 36 14 Busses SPI,I\u00b2C,UART,I2S,CAN SPI,I\u00b2C,UART ADC Pins 18 6 DAC Pins 2 0 USB Conector Micro Type B UART 3 1 SPI 3 1 I\u00b2C 2 1 Pinout You can refer to the manual provided by Espressif Systems to view the complete pinout in detail. Peripherals and Features Now that we have seen the ESP32 Pinout , let us now focus on some of the important peripherals of ESP32 and their associated pins. ESP32 Microcontroller has: Up to 18 12-bit Analog to Digital converters. 2, 8-bit Digital to Analog converters. 10 capacitive touch switch sensors. 4 SPI channels. 2 I\u00b2C interfaces. 2 I2S interfaces (for digital audio). 3 UARTs for communications. Up to 8 channels of IR remote control. Up to 16 channels of LED PWM (pulse width modulation). An integrated Hall-effect sensor. An ultra-low-power analog preamp. An internal low-dropout regulator. GPIO 34 pins, each pin carries out more than one function ( only one will be active). You can configure a pin as either a GPIO or an ADC or an UART in the program.ADC and DAC pins are predefined, and you have to use the manufacturer specified pins. But other functions like PWM, SPI, UART, I2C etc. can be assigned to any GPIO pin through the program. RTC GPIO part of the RTC Low-Power subsystem. These pins can be used to wake ESP32 from a deep sleep as an external wake-up source. ADC ESP32 has two 12-bit SAR Analog to Digital Converter Modules with 8-channels and 10-channels each. So, ADC1 and ADC2 blocks combined together have 18 channels of 12-bit ADC.With 12-bit resolution, the Digital output values will be in the range of 0 \u2013 4093. DAC ESP32 Microcontroller has two independent 8-bit Digital to Analog Converter channels to convert digital values to analog voltage signals. The DAC has an internal resistor network and uses a power supply as an input reference voltage. The following two GPIO Pins are associated with DAC functionalities. DAC1 \u2014 GPIO25 DAC2 \u2014 GPIO26 Capacitive Touch GPIOs can detect variations in capacitance on a pin due to touching or approaching the GPIO Pin with a finger or stylus. These Touch GPIOs can be used in implementing capacitive touch pads without any additional hardware. SPI three SPI blocks (SPI, HSPI and VSPI) are present in both master and slave modes. SPI is used to interface with Flash Memory. So, you have two SPI interfaces. I\u00b2C There are two I2C interfaces in ESP32 with complete flexibility on assigning pins, i.e., SCL and SDA pins for both I2C interfaces can be assigned in the program by the user.If you are using Arduino IDE, then the default I2C pins are: SDA \u2013 GPIO21 SCL \u2013 GPIO22 PWM The PWM Controller in ESP32 has 16 independent PWM waveform channels with configurable frequency and duty cycle. The PWM waveform can be used to drive motors and LEDs. You can configure the PWM signal frequency, channel, GPIO pin and also the duty cycle. How To Program ESP32 One can use C++ and MicroPython to program the ESP32. It supports multiple programming environments : Arduino IDE PlatformIO IDE (VS Code) LUA MicroPython Espressif IDF (IoT Development Framework) JavaScript To fully utilise the features , one must use the ESP-IDF.You can chek it out in detail here . Using the Arduino IDE You can program ESP32 using the Arduino IDE. You can refer to this tutorial to understand the complete process. LED Blink Sketch For more examples and initial projects for practice you can refer here . References Video on Introduction to ESP 32-Getting Started by DroneBot Workshop For more details you can refer to the website of DroneBot Workshop here . ESP 32 webpage by Electronics Hub Programming Guide to ESP 32 by Electronics Hub and OpenLab . Espressif Systems documentation on ESP 32 .","title":"ESP32"},{"location":"electronics/Development_Boards/ESP32/#esp32","text":"","title":"ESP32"},{"location":"electronics/Development_Boards/ESP32/#introduction","text":"ESP32 is a series of feature-rich MCU with integrated Wi-Fi and Bluetooth connectivity for a wide range of applications. Espressif Systems, China, produce it.ESP32 is cheap and nearly ten times faster than Arduino Uno and is a 32-bit versatile device. Developers of ESP32 IC made a small module board with edge castellations. One popular version of such a module board is called ESP-WROOM-32. It is a dual-core, 32-bit microcontroller unit, and all the cores can be controlled individually. It has integrated Wi-Fi, Bluetooth, and Bluetooth Low Energy with multiple digital and analog I/O pins.","title":"Introduction"},{"location":"electronics/Development_Boards/ESP32/#comparison-of-esp32-and-arduino-uno","text":"Parameter ESP32 ARDUINO UNO Processor Xtensa dual-core ATMega328P Number of Cores 2 1 Architecture 32 bit 8 bit Operating Voltage 2.2 to 3.6V 5V CPU Frequency 160 or 240 MHz 16 MHz WiFi YES NO Bluetooth YES NO RAM 512 KB 2 KB Flash 16 MB 32 KB GPIO pins 36 14 Busses SPI,I\u00b2C,UART,I2S,CAN SPI,I\u00b2C,UART ADC Pins 18 6 DAC Pins 2 0 USB Conector Micro Type B UART 3 1 SPI 3 1 I\u00b2C 2 1","title":"Comparison Of ESP32 and Arduino Uno"},{"location":"electronics/Development_Boards/ESP32/#pinout","text":"You can refer to the manual provided by Espressif Systems to view the complete pinout in detail.","title":"Pinout"},{"location":"electronics/Development_Boards/ESP32/#peripherals-and-features","text":"Now that we have seen the ESP32 Pinout , let us now focus on some of the important peripherals of ESP32 and their associated pins. ESP32 Microcontroller has: Up to 18 12-bit Analog to Digital converters. 2, 8-bit Digital to Analog converters. 10 capacitive touch switch sensors. 4 SPI channels. 2 I\u00b2C interfaces. 2 I2S interfaces (for digital audio). 3 UARTs for communications. Up to 8 channels of IR remote control. Up to 16 channels of LED PWM (pulse width modulation). An integrated Hall-effect sensor. An ultra-low-power analog preamp. An internal low-dropout regulator.","title":"Peripherals and Features"},{"location":"electronics/Development_Boards/ESP32/#gpio","text":"34 pins, each pin carries out more than one function ( only one will be active). You can configure a pin as either a GPIO or an ADC or an UART in the program.ADC and DAC pins are predefined, and you have to use the manufacturer specified pins. But other functions like PWM, SPI, UART, I2C etc. can be assigned to any GPIO pin through the program.","title":"GPIO"},{"location":"electronics/Development_Boards/ESP32/#rtc-gpio","text":"part of the RTC Low-Power subsystem. These pins can be used to wake ESP32 from a deep sleep as an external wake-up source.","title":"RTC GPIO"},{"location":"electronics/Development_Boards/ESP32/#adc","text":"ESP32 has two 12-bit SAR Analog to Digital Converter Modules with 8-channels and 10-channels each. So, ADC1 and ADC2 blocks combined together have 18 channels of 12-bit ADC.With 12-bit resolution, the Digital output values will be in the range of 0 \u2013 4093.","title":"ADC"},{"location":"electronics/Development_Boards/ESP32/#dac","text":"ESP32 Microcontroller has two independent 8-bit Digital to Analog Converter channels to convert digital values to analog voltage signals. The DAC has an internal resistor network and uses a power supply as an input reference voltage. The following two GPIO Pins are associated with DAC functionalities. DAC1 \u2014 GPIO25 DAC2 \u2014 GPIO26","title":"DAC"},{"location":"electronics/Development_Boards/ESP32/#capacitive-touch-gpios","text":"can detect variations in capacitance on a pin due to touching or approaching the GPIO Pin with a finger or stylus. These Touch GPIOs can be used in implementing capacitive touch pads without any additional hardware.","title":"Capacitive Touch GPIOs"},{"location":"electronics/Development_Boards/ESP32/#spi","text":"three SPI blocks (SPI, HSPI and VSPI) are present in both master and slave modes. SPI is used to interface with Flash Memory. So, you have two SPI interfaces.","title":"SPI"},{"location":"electronics/Development_Boards/ESP32/#i2c","text":"There are two I2C interfaces in ESP32 with complete flexibility on assigning pins, i.e., SCL and SDA pins for both I2C interfaces can be assigned in the program by the user.If you are using Arduino IDE, then the default I2C pins are: SDA \u2013 GPIO21 SCL \u2013 GPIO22","title":"I\u00b2C"},{"location":"electronics/Development_Boards/ESP32/#pwm","text":"The PWM Controller in ESP32 has 16 independent PWM waveform channels with configurable frequency and duty cycle. The PWM waveform can be used to drive motors and LEDs. You can configure the PWM signal frequency, channel, GPIO pin and also the duty cycle.","title":"PWM"},{"location":"electronics/Development_Boards/ESP32/#how-to-program-esp32","text":"One can use C++ and MicroPython to program the ESP32. It supports multiple programming environments : Arduino IDE PlatformIO IDE (VS Code) LUA MicroPython Espressif IDF (IoT Development Framework) JavaScript To fully utilise the features , one must use the ESP-IDF.You can chek it out in detail here .","title":"How To Program ESP32"},{"location":"electronics/Development_Boards/ESP32/#using-the-arduino-ide","text":"You can program ESP32 using the Arduino IDE. You can refer to this tutorial to understand the complete process.","title":"Using the Arduino IDE"},{"location":"electronics/Development_Boards/ESP32/#led-blink-sketch","text":"For more examples and initial projects for practice you can refer here .","title":"LED Blink Sketch"},{"location":"electronics/Development_Boards/ESP32/#references","text":"Video on Introduction to ESP 32-Getting Started by DroneBot Workshop For more details you can refer to the website of DroneBot Workshop here . ESP 32 webpage by Electronics Hub Programming Guide to ESP 32 by Electronics Hub and OpenLab . Espressif Systems documentation on ESP 32 .","title":"References"},{"location":"electronics/Development_Boards/Pyboard/","text":"Pyboard - MicroPython MicroPython is an implementation of the Python 3 programming language which is optimized to run on many microcontrollers. It has modules to access the hardware of the microcontroller, and the code is compatible to a great extent with normal python code. The Pyboard is the official MicroPython microcontroller board based on a STM3F405RG microcontroller. Pyboard Board Layout The hardware has: STM32F405RG microcontroller 168 MHz Cortex M4 CPU with hardware floating point 1024KiB flash ROM and 192KiB RAM Micro USB connector for power and serial communication Micro SD card slot, supporting standard and high capacity SD cards 3-axis accelerometer (MMA7660) Real time clock with optional battery backup 24 GPIO on left and right edges and 5 GPIO on bottom row, plus LED and switch GPIO available on bottom row 3x 12-bit analog to digital converters, available on 16 pins, 4 with analog ground shielding 2x 12-bit digital to analog (DAC) converters, available on pins X5 and X6 4 LEDs (red, green, yellow and blue) 1 reset and 1 user switch On-board 3.3V LDO voltage regulator, capable of supplying up to 250mA, input voltage range 3.6V to 16V DFU bootloader in ROM for easy upgrading of firmware Blink Sketch Similar to the blink sketch with Arduino, we can make a simple blink sketch with Pyboard using MicroPython. Code You can copy the code from here: import pyb led = pyb . LED ( 4 ) while True : led . on () pyb . delay ( 1000 ) led . off () pyb . delay ( 1000 ) How to Code First connect the Pyboard to your computer using a USB. It will open up as a USB flash device with a boot python file and main python file. There are multiple ways to code a MicroPython program and run it on Pyboard. One beginner friendly way is to use a serial communication program like putty, which opens the interactive REPL prompt and now you can execute commands directly. Follow this tutorial to setup putty. NOTE: you have to press delete after the indented at the end of the while loop to end the indented block and then only will the loop start running. To exit out of the while loop, use ctrl+c. Another way is to run scripts from the built-in file system. Write to the main python file script using any text editor, save and close it. Make sure you eject the Pyboard USB drive and then only press the reset button on the PyBoard. You can use putty as a serial monitor. References For documentation and quick reference, check out the official MicroPython website . For a quick introduction to MicroPython and Pyboard, check out this video. For a comparison with the Arduino, check out this video. To discuss all things related to MicroPython with an online community check out the MicroPython Forum .","title":"Pyboard - (STM32F405)MicroPython"},{"location":"electronics/Development_Boards/Pyboard/#pyboard-micropython","text":"MicroPython is an implementation of the Python 3 programming language which is optimized to run on many microcontrollers. It has modules to access the hardware of the microcontroller, and the code is compatible to a great extent with normal python code. The Pyboard is the official MicroPython microcontroller board based on a STM3F405RG microcontroller.","title":"Pyboard - MicroPython"},{"location":"electronics/Development_Boards/Pyboard/#pyboard-board-layout","text":"The hardware has: STM32F405RG microcontroller 168 MHz Cortex M4 CPU with hardware floating point 1024KiB flash ROM and 192KiB RAM Micro USB connector for power and serial communication Micro SD card slot, supporting standard and high capacity SD cards 3-axis accelerometer (MMA7660) Real time clock with optional battery backup 24 GPIO on left and right edges and 5 GPIO on bottom row, plus LED and switch GPIO available on bottom row 3x 12-bit analog to digital converters, available on 16 pins, 4 with analog ground shielding 2x 12-bit digital to analog (DAC) converters, available on pins X5 and X6 4 LEDs (red, green, yellow and blue) 1 reset and 1 user switch On-board 3.3V LDO voltage regulator, capable of supplying up to 250mA, input voltage range 3.6V to 16V DFU bootloader in ROM for easy upgrading of firmware","title":"Pyboard Board Layout"},{"location":"electronics/Development_Boards/Pyboard/#blink-sketch","text":"Similar to the blink sketch with Arduino, we can make a simple blink sketch with Pyboard using MicroPython.","title":"Blink Sketch"},{"location":"electronics/Development_Boards/Pyboard/#code","text":"You can copy the code from here: import pyb led = pyb . LED ( 4 ) while True : led . on () pyb . delay ( 1000 ) led . off () pyb . delay ( 1000 )","title":"Code"},{"location":"electronics/Development_Boards/Pyboard/#how-to-code","text":"First connect the Pyboard to your computer using a USB. It will open up as a USB flash device with a boot python file and main python file. There are multiple ways to code a MicroPython program and run it on Pyboard. One beginner friendly way is to use a serial communication program like putty, which opens the interactive REPL prompt and now you can execute commands directly. Follow this tutorial to setup putty. NOTE: you have to press delete after the indented at the end of the while loop to end the indented block and then only will the loop start running. To exit out of the while loop, use ctrl+c. Another way is to run scripts from the built-in file system. Write to the main python file script using any text editor, save and close it. Make sure you eject the Pyboard USB drive and then only press the reset button on the PyBoard. You can use putty as a serial monitor.","title":"How to Code"},{"location":"electronics/Development_Boards/Pyboard/#references","text":"For documentation and quick reference, check out the official MicroPython website . For a quick introduction to MicroPython and Pyboard, check out this video. For a comparison with the Arduino, check out this video. To discuss all things related to MicroPython with an online community check out the MicroPython Forum .","title":"References"},{"location":"electronics/Development_Boards/STM32/","text":"Blue Pill (STM32F103C8T6) Introduction The STM32F103C8T6 (also known as \u2018STM32\u2019 or \u2018Blue Pill\u201d) is a cheap development board based on the ARM Cortex M3 microprocessor. This video by Great Scott can prove to be an introductory video to understand what it exactly is and how it can be used. Naming Convention of STM microcontrollers Parameter Meaning STM name of the manufacturer (STMicroelectronics) 32 32 bit ARM architecture F Foundation 1 Core (ARM Cortex M3) 03 Line (describes peripherals and speed) C 48 pins 8 64 KB flash memory T LQFP package (Low Profile Quad Flat Pack) 6 Operating Temperature Range (-40 \u00b0C to 85 \u00b0C) Technical Specifications of STM32 Parameter Meaning Architecture 32 bit ARM Cortex M3 Operating Voltage 2.7V to 3.6V CPU Frequency 72 MHz Number of GPIO pins 37 Number of PWM pins 12 Analog Input Pins 10 (12 bit resolution) I2C Peripherals 2 SPI Peripherals 2 CAN 2.0 Peripheral 1 Timers 3(16-bit), 1 Flash Memory 64KB RAM 20kB For more insights about the technical specifcations refer to the official datsheet and reference manual by STMicroelectronics. Pinout Programming STM32 1) Using STM32duino bootloader (Arduino IDE) You can program your STM32 development board using Arduino IDE, too. You will require FTDI (USB to UART converter) for this process. This tutorial explains the complete process. 2) Using Keil UVision and STM32CubeMX This is one step further than the last mentioned process and is more professional in terms of usage. You will require the softwares ARM\u2019s Keil Uvision and STM32CubeMX for this method of programming BluePill. You will also need the STLink/V2 which is a debugger cum programmer hardware provided by STMicroelectronics. These softwares provide a more sophisticated and professional programming environment for programming embedded systems. You may refer to this guide to know this method in detail.","title":"BluePill - STM32F103C8T6"},{"location":"electronics/Development_Boards/STM32/#blue-pill-stm32f103c8t6","text":"","title":"Blue Pill (STM32F103C8T6)"},{"location":"electronics/Development_Boards/STM32/#introduction","text":"The STM32F103C8T6 (also known as \u2018STM32\u2019 or \u2018Blue Pill\u201d) is a cheap development board based on the ARM Cortex M3 microprocessor. This video by Great Scott can prove to be an introductory video to understand what it exactly is and how it can be used.","title":"Introduction"},{"location":"electronics/Development_Boards/STM32/#naming-convention-of-stm-microcontrollers","text":"Parameter Meaning STM name of the manufacturer (STMicroelectronics) 32 32 bit ARM architecture F Foundation 1 Core (ARM Cortex M3) 03 Line (describes peripherals and speed) C 48 pins 8 64 KB flash memory T LQFP package (Low Profile Quad Flat Pack) 6 Operating Temperature Range (-40 \u00b0C to 85 \u00b0C)","title":"Naming Convention of STM microcontrollers "},{"location":"electronics/Development_Boards/STM32/#technical-specifications-of-stm32","text":"Parameter Meaning Architecture 32 bit ARM Cortex M3 Operating Voltage 2.7V to 3.6V CPU Frequency 72 MHz Number of GPIO pins 37 Number of PWM pins 12 Analog Input Pins 10 (12 bit resolution) I2C Peripherals 2 SPI Peripherals 2 CAN 2.0 Peripheral 1 Timers 3(16-bit), 1 Flash Memory 64KB RAM 20kB For more insights about the technical specifcations refer to the official datsheet and reference manual by STMicroelectronics.","title":"Technical Specifications of STM32 "},{"location":"electronics/Development_Boards/STM32/#pinout","text":"","title":"Pinout"},{"location":"electronics/Development_Boards/STM32/#programming-stm32","text":"","title":"Programming STM32 "},{"location":"electronics/Development_Boards/STM32/#1-using-stm32duino-bootloader-arduino-ide","text":"You can program your STM32 development board using Arduino IDE, too. You will require FTDI (USB to UART converter) for this process. This tutorial explains the complete process.","title":"1) Using STM32duino bootloader (Arduino IDE)"},{"location":"electronics/Development_Boards/STM32/#2-using-keil-uvision-and-stm32cubemx","text":"This is one step further than the last mentioned process and is more professional in terms of usage. You will require the softwares ARM\u2019s Keil Uvision and STM32CubeMX for this method of programming BluePill. You will also need the STLink/V2 which is a debugger cum programmer hardware provided by STMicroelectronics. These softwares provide a more sophisticated and professional programming environment for programming embedded systems. You may refer to this guide to know this method in detail.","title":"2) Using Keil UVision and STM32CubeMX"},{"location":"electronics/Modules/ESP8266/","text":"Wi-Fi module Wifi modules or wifi microcontrollers are used to send and recieve data over Wi-Fi. They can also accept commands over the Wi-Fi. Wi-Fi modules are used for communications bewtween devices. They are most commonly used in the field of Internet of Thnigs. ESP8266 ESP8266 is the most widely used Wi-Fi module. It is a low-cost microchip with a full TCP/IP stack and microcontroller capability, produced by Espressif Systems. This small module allows microcontrollers to connect to a Wi-Fi network and make simple TCP/IP connections. ESP8226 comes with the capabilites of:- 1. 2.4 Ghz Wi-Fi 2. General-purpose input/output (16 GPIO) 3. Inter-Integrated Circuit (I\u00b2C) serial communication protocol 4. Analog-to-digital conversion (10-bit ADC) It runs at operating voltage of 3V and can handle maximum voltage of around 3.6V. It can be easily interfaced with microcontrollers board via Serial Port. There are numerous breakout boards available based on ESP8266 Wifi Module like ESP8266 NodeMCU V3. Because of its compact size, its most importantly used in autonomous project. ESP8266 pinout Pin Number Pin Name Working 1 RX Serial Receiver Pin 2 VCC Power Pin (+3.3 V; can handle up to 3.6 V 3 GPIO 0 General-Purpose I/O No. 0 4 RST Reset 5 CH_PD Chip power-down 6 GPIO 2 General-purpose I/O No. 2 7 TX Serial Transmitter Pin 8 GND Ground Scanning and dispalying available WiFi networks using ESP8266 ESP8266 comes with a built in micro-controller. It has a Arduino support and can be programmed easily. Arduino support for ESP8266 Download Arduino IDE from Arduino.cc(1.6.4 or greater) https://www.arduino.cc/en/Main/Software Install the ESP8266 Board Package Select Preferences under File Enter http://arduino.esp8266.com/stable/package_esp8266com_index.json into Additional Boards Manager URL\u2019s field under preferences. Select the Board Manager under the Tools. Use the Board Manager to install the ESP8266 package. Restart the Arduino IDE and Select the Generic ESP8266 Module board Connection A USB to serial converter is nedded to program ESP8266. The above image shows connections made from Explore USB to Serial and Explore Wifi boards. Code #include \"ESP8266WiFi.h\" void setup () { Serial . begin ( 115200 ); // Set WiFi to station mode and disconnect from an AP if it was previously connected WiFi . mode ( WIFI_STA ); WiFi . disconnect (); delay ( 100 ); Serial . println ( \"Setup done\" ); } void loop () { Serial . println ( \"scan start\" ); // WiFi.scanNetworks will return the number of networks found int n = WiFi . scanNetworks (); Serial . println ( \"scan done\" ); if ( n == 0 ) Serial . println ( \"no networks found\" ); else { Serial . print ( n ); Serial . println ( \" networks found\" ); for ( int i = 0 ; i < n ; ++ i ) { // Print SSID and RSSI for each network found Serial . print ( i + 1 ); Serial . print ( \": \" ); Serial . print ( WiFi . SSID ( i )); Serial . print ( \" (\" ); Serial . print ( WiFi . RSSI ( i )); Serial . print ( \")\" ); Serial . println (( WiFi . encryptionType ( i ) == ENC_TYPE_NONE ) ? \" \" : \"*\" ); delay ( 10 ); } } Serial . println ( \"\" ); // Wait a bit before scanning again delay ( 5000 ); } References Documentation of ESP8266.h library. Technical Reference Manual by Espressif Systems. ESP8266 Community Forum ESP8266 for IoT guide by Nabto.","title":"ESP8266 - Wifi Module"},{"location":"electronics/Modules/ESP8266/#wi-fi-module","text":"Wifi modules or wifi microcontrollers are used to send and recieve data over Wi-Fi. They can also accept commands over the Wi-Fi. Wi-Fi modules are used for communications bewtween devices. They are most commonly used in the field of Internet of Thnigs.","title":"Wi-Fi module"},{"location":"electronics/Modules/ESP8266/#esp8266","text":"ESP8266 is the most widely used Wi-Fi module. It is a low-cost microchip with a full TCP/IP stack and microcontroller capability, produced by Espressif Systems. This small module allows microcontrollers to connect to a Wi-Fi network and make simple TCP/IP connections. ESP8226 comes with the capabilites of:- 1. 2.4 Ghz Wi-Fi 2. General-purpose input/output (16 GPIO) 3. Inter-Integrated Circuit (I\u00b2C) serial communication protocol 4. Analog-to-digital conversion (10-bit ADC) It runs at operating voltage of 3V and can handle maximum voltage of around 3.6V. It can be easily interfaced with microcontrollers board via Serial Port. There are numerous breakout boards available based on ESP8266 Wifi Module like ESP8266 NodeMCU V3. Because of its compact size, its most importantly used in autonomous project.","title":"ESP8266"},{"location":"electronics/Modules/ESP8266/#esp8266-pinout","text":"Pin Number Pin Name Working 1 RX Serial Receiver Pin 2 VCC Power Pin (+3.3 V; can handle up to 3.6 V 3 GPIO 0 General-Purpose I/O No. 0 4 RST Reset 5 CH_PD Chip power-down 6 GPIO 2 General-purpose I/O No. 2 7 TX Serial Transmitter Pin 8 GND Ground","title":"ESP8266 pinout"},{"location":"electronics/Modules/ESP8266/#scanning-and-dispalying-available-wifi-networks-using-esp8266","text":"ESP8266 comes with a built in micro-controller. It has a Arduino support and can be programmed easily.","title":"Scanning and dispalying available WiFi networks using ESP8266"},{"location":"electronics/Modules/ESP8266/#arduino-support-for-esp8266","text":"Download Arduino IDE from Arduino.cc(1.6.4 or greater) https://www.arduino.cc/en/Main/Software Install the ESP8266 Board Package Select Preferences under File Enter http://arduino.esp8266.com/stable/package_esp8266com_index.json into Additional Boards Manager URL\u2019s field under preferences. Select the Board Manager under the Tools. Use the Board Manager to install the ESP8266 package. Restart the Arduino IDE and Select the Generic ESP8266 Module board","title":"Arduino support for ESP8266"},{"location":"electronics/Modules/ESP8266/#connection","text":"A USB to serial converter is nedded to program ESP8266. The above image shows connections made from Explore USB to Serial and Explore Wifi boards.","title":"Connection"},{"location":"electronics/Modules/ESP8266/#code","text":"#include \"ESP8266WiFi.h\" void setup () { Serial . begin ( 115200 ); // Set WiFi to station mode and disconnect from an AP if it was previously connected WiFi . mode ( WIFI_STA ); WiFi . disconnect (); delay ( 100 ); Serial . println ( \"Setup done\" ); } void loop () { Serial . println ( \"scan start\" ); // WiFi.scanNetworks will return the number of networks found int n = WiFi . scanNetworks (); Serial . println ( \"scan done\" ); if ( n == 0 ) Serial . println ( \"no networks found\" ); else { Serial . print ( n ); Serial . println ( \" networks found\" ); for ( int i = 0 ; i < n ; ++ i ) { // Print SSID and RSSI for each network found Serial . print ( i + 1 ); Serial . print ( \": \" ); Serial . print ( WiFi . SSID ( i )); Serial . print ( \" (\" ); Serial . print ( WiFi . RSSI ( i )); Serial . print ( \")\" ); Serial . println (( WiFi . encryptionType ( i ) == ENC_TYPE_NONE ) ? \" \" : \"*\" ); delay ( 10 ); } } Serial . println ( \"\" ); // Wait a bit before scanning again delay ( 5000 ); }","title":"Code"},{"location":"electronics/Modules/ESP8266/#references","text":"Documentation of ESP8266.h library. Technical Reference Manual by Espressif Systems. ESP8266 Community Forum ESP8266 for IoT guide by Nabto.","title":"References"},{"location":"electronics/Motors/ServoMotor/","text":"Servo Motors Servo motors are simply just electric motors which give the users precise control over the angle of rotation, speed and torque of the motor. The shaft of a servo motor can be made to rotate by a certain angle and then it waits till the next signal is given to it. Moreover, the speed and torque, and in certain applications, even the sense of rotation of the motor can be adjusted by changing the command signal given to the motor. Whereas on the other hand, this is not possible in a simple electric motor, as it runs at a constant speed in the same direction as long as it is connected to a constant power supply. Apart from increased control, servo motors also provide high precision owing to its working principle - the servomechanism. What is Servomechanism ? Servomechanism is a closed loop control system which aims at achieving a fixed value of the output based on the given command, without using a variable input signal. It works by calculating the difference between the reference input signal or the command signal and the output signal received from a sensor. The feedback signal thus obtained, acts as the input signal for the device to be controlled. Hence, with the help of this feedback mechanism, we can make the output equal the reference input without having to alter the reference input manually at regular intervals. Once the output signal becomes equal to the command signal, the feedback signal goes to zero and hence the process stops till a new command signal is given. Working of a Servo motor A servo motor construction consists of a simple electric motor, some gears, a potentiometer/encoder/resolver, an error detector amplifier, and a control circuit. Potentiometers, encoders and resolvers all perform the same function by acting as sensors that measure the rotary position of the motor shaft. There are however certain differences in the way they function. If interested, you can take a look at these resources which give a detailed comparison between Potentiometer and Encoder Encoder and Resolver Let us consider the simple case of a potentiometer used in the servo motor to clearly understand its working. The potentiometer gives the output reference signal by sensing the position of the shaft, hence its knob is positioned such that it does not produce any signal in the initial condition. Now, the command signal, i.e. the input reference signal, is introduced. This command signal represents how much we want the motor shaft to rotate. Next, the input reference signal and the output reference signal are fed into the error detector amplifier, where their difference is amplified and then generated as the output. This output from the amplifier acts as the input signal for the servo motor, which now starts rotating. The knob of the potentiometer is linked to the motor shaft with the help of a gear arrangement. Thus, as the shaft rotates, the knob of the potentiometer also rotates in a way such that the difference between the input and output reference signals decreases until it becomes zero. When the difference becomes zero, the output of the amplifier also goes to zero and no input signal will be given to the motor, due to which it stops rotating. Now it will remain in this condition until a new command signal is given, so that it generates a difference with the output from the potentiometer, and the process is repeated again. Applications of Servo motors Servo motors have a wide variety of applications ranging from RC toys to industrial machines. They are built in cameras to adjust the focus of the lens. Servo motors are even found in DVD players, where they are used to open/close the disk tray. Due to their high precision and ability to rotate by a desired angle, they are also used in cutting machines such as the milling machine. Servo motors also find numerous applications in the field of robotics, where they are actively being used for making mobile robots as well as to make movable joints in robotic arms which require highly accurate movements. Depending upon their application, there are different types of servo motors. You can check out these websites ( 1 and 2 ) to know more on this.","title":"Servo Motors"},{"location":"electronics/Motors/ServoMotor/#servo-motors","text":"Servo motors are simply just electric motors which give the users precise control over the angle of rotation, speed and torque of the motor. The shaft of a servo motor can be made to rotate by a certain angle and then it waits till the next signal is given to it. Moreover, the speed and torque, and in certain applications, even the sense of rotation of the motor can be adjusted by changing the command signal given to the motor. Whereas on the other hand, this is not possible in a simple electric motor, as it runs at a constant speed in the same direction as long as it is connected to a constant power supply. Apart from increased control, servo motors also provide high precision owing to its working principle - the servomechanism.","title":"Servo Motors"},{"location":"electronics/Motors/ServoMotor/#what-is-servomechanism","text":"Servomechanism is a closed loop control system which aims at achieving a fixed value of the output based on the given command, without using a variable input signal. It works by calculating the difference between the reference input signal or the command signal and the output signal received from a sensor. The feedback signal thus obtained, acts as the input signal for the device to be controlled. Hence, with the help of this feedback mechanism, we can make the output equal the reference input without having to alter the reference input manually at regular intervals. Once the output signal becomes equal to the command signal, the feedback signal goes to zero and hence the process stops till a new command signal is given.","title":"What is Servomechanism ?"},{"location":"electronics/Motors/ServoMotor/#working-of-a-servo-motor","text":"A servo motor construction consists of a simple electric motor, some gears, a potentiometer/encoder/resolver, an error detector amplifier, and a control circuit. Potentiometers, encoders and resolvers all perform the same function by acting as sensors that measure the rotary position of the motor shaft. There are however certain differences in the way they function. If interested, you can take a look at these resources which give a detailed comparison between Potentiometer and Encoder Encoder and Resolver Let us consider the simple case of a potentiometer used in the servo motor to clearly understand its working. The potentiometer gives the output reference signal by sensing the position of the shaft, hence its knob is positioned such that it does not produce any signal in the initial condition. Now, the command signal, i.e. the input reference signal, is introduced. This command signal represents how much we want the motor shaft to rotate. Next, the input reference signal and the output reference signal are fed into the error detector amplifier, where their difference is amplified and then generated as the output. This output from the amplifier acts as the input signal for the servo motor, which now starts rotating. The knob of the potentiometer is linked to the motor shaft with the help of a gear arrangement. Thus, as the shaft rotates, the knob of the potentiometer also rotates in a way such that the difference between the input and output reference signals decreases until it becomes zero. When the difference becomes zero, the output of the amplifier also goes to zero and no input signal will be given to the motor, due to which it stops rotating. Now it will remain in this condition until a new command signal is given, so that it generates a difference with the output from the potentiometer, and the process is repeated again.","title":"Working of a Servo motor"},{"location":"electronics/Motors/ServoMotor/#applications-of-servo-motors","text":"Servo motors have a wide variety of applications ranging from RC toys to industrial machines. They are built in cameras to adjust the focus of the lens. Servo motors are even found in DVD players, where they are used to open/close the disk tray. Due to their high precision and ability to rotate by a desired angle, they are also used in cutting machines such as the milling machine. Servo motors also find numerous applications in the field of robotics, where they are actively being used for making mobile robots as well as to make movable joints in robotic arms which require highly accurate movements. Depending upon their application, there are different types of servo motors. You can check out these websites ( 1 and 2 ) to know more on this.","title":"Applications of Servo motors"},{"location":"electronics/Sensors/lidar/","text":"Lidar Lidar is a method for calculating distances between objects with the help of a laser and measuring the amount of time taken for the reflected light to return back. Lidar Sensor A Lidar sensor emits pulsed light waves into the surrounding environment. These pulses bounce off of obstacles and the surrounding environment and then return to the sensor. The sensor then, keeps a track of time it took for the light to bounce off and thus calculating the distance between obstacles. Repeating this process constantly creates a real-time map of the environment. As an example of how a lidar sensor calculates the distance between the sensor and an obstacle, Let\u2019s define the following variables, 1) Speed of light, \\(c = 3 \u00d7 10^8 m/s\\) 2) time taken for light to travel from the lidar sensor, hitting the obstacle and returning back to the sensor, \\(t\\) 3) Distance between the obstacle and the sensor, \\(d\\) Say that the time taken, \\(t = 5 \u00d7 10^{-8} sec\\) (Observe the order of magnitude \\(t\\) ) So, to calculate the distance \\(d\\) , we use the Newton\u2019s second law of motion \\[ S = u \\cdot t + \\frac{1}{2} \\cdot a \\cdot t^2 \\] Since, speed of light constant, replacing, \\(a = 0\\) , \\(u = c\\) , and, \\(S = d\\) we get, \\[ d = c \\cdot t \\] \\[ d = 3 \u00d7 10^8 \u00d7 5 * 10^{-8} \\] \\[ d = 15m \\] Therfore, the distance between the sensor and the obstacle is calculated to be 15 meters. This is the basic calculation that goes into calculating the distances. Types of Lidar Systems 1) Airborne Lidar - This is installed on aerial drones or vehicles like helicopters. It emits light towards the ground surface giving a fairly detailed and quick map of the terrain above which the vehicle or drone is flying. It is also used for topographic survey. 2) Terrestrial Lidar - This is generally installed on vehicles moving on the earth\u2019s surface. These give a detailed map, and can be used to make a robot or a vehicle navigate through it\u2019s evironment. It is also used for observing highways, roads and infrastructure. Components of a basic Lidar Sensor A lidar sensor generally consists of 4 main components: 1) Light source - Generally a laser (or anything that emits light in pulses) 2) Optical components - There are multiple optical components for example, the light through the sensor, falls on a rotating/oscillating mirror so as to change the direction of light to cover a 360 view. An optical lens helps to focus light on the photodetector. 3) photodector - The light is recieved by this photodetector and the signal is processed electronically like frequency of light (for speed measurements) and the time taken for the light to bounce. 4) GPS - These sensors need a GPS system to determine the exact position and orientation of the sensor in 3D space. For a more indepth explaination of a Lidar sensor and the different factors that go into designing one, for example, the wavelength of light to use, the pulsing rate of the light or pulse repetition rate and more factors can be found here. Lidar usage To implement Lidar into your ros program, these are the following steps you must follow: * Connect your Lidar sensor to a power supply, and connect a data transmitter to the Lidar sensor and the computer. * You need to give permissions to the on data input port of the computer. To check the permissions, type ls -l /dev/tty If your permissions are set properly, you should get an output like shown below. Just focus on the starting part, crw-rw-rw . If instead, it is something of the form crw-rw-- , then your permissions are not set properly. crw-rw-rw- 1 root dialout 5 , 0 Sep 6 23 :50 /dev/ttyACM0 To set permissions, (replace ACM0 with whatever your ports are) sudo chmod a+rw /dev/ttyACM0 Next, you need to download the package of your Lidar manufacturer. Following are the common packages and their github links. You need to clone these github repositories in the src directory of your catkin workspace. 1) Slamtec 2) YDLiDAR 3) Hokuyo 4) ROS SICK 5) ROS2 SICK 6) RoboSense * After you have cloned the ros packages, go into your workspace directory, catkin_make source devel/setup.bash Now just run the launch file according to your Lidar manufacturer package. For the above 6 manufacturers, run the following launch files. (If you are getting package not found error, please give appropriate permissions to the launch files using chmod). 1) Slamtec bash roslaunch rplidar_ros rplidar.launch 2) YDLiDAR bash roslaunch ydlidar lidar_view.launch 3) Hokuyo bash roslaunch urg_node urg_lidar.launch 4) ROS SICK - Read the README file in the github repo for which launch file you need for your specific model. 5) ROS2 SICK - Read the README file in the github repo for which launch file you need for your specific model. 6) RoboSense bash roslaunch rslidar_sdk start.launch For a much more detailed guide, use this link. This shows a fairly detailed explaination on how to setup your lidar to interact with ROS and display the results in rviz. It also has some examples of implementation and different repositories that would help you to code. You can also check out this link which provides a simple explaination for setting up a YDLiDAR X4 Sensor. Applications of Lidar 1) Surveying land - Lidar sensors can generate a cost effective solution for generating a 3D digital terrain model of remote or rough areas which are difficult to assess otherwise. (Nasa used Lidar techonology to explore mars). For more information on Airborne Lidar and Topographic survey, check out this research paper . 2) Power line inspection - Power lines span very long distances and thus make the inspection of power lines very difficult. Lidar sensors can make the inspection easier, by identifying faults before they can cause any real damage. 3) Farming and Forest research - These can be deployed to large farms to help determine how to use resources in an efficient manner and boost productivity. They can also be used to research on the impact that humans have caused on natural life in forests, as Lidar sensors can penetrate tree cover. 4) Climate and weather change - Climate scientists use Lidar to study and track changes in the atmosphere. Lidar can also be used to warn people if there is a Tsunami incoming. 5) Robotics - Lidar is used to equip robots with Mapping and navigational capabilities. For example, self driving cars. Companies working on Lidar technologies 1) tuSimple - works on self driving cars which is almost commercial ready. 2) AEye - Develops advanced vision hardware, software and algorithms for autonomous vehicles. 3) SiLC Technologies - Is a leading provider of highly integrated FMCW (Frequency Modulated Continuous Wave) Lidar solutions, which include their FMCW integration chip. References - George, N., 2021. 11 Interesting LiDAR Applications. [online] Blog.cloudfactory.com. Available at: https://blog.cloudfactory.com/interesting-lidar-applications [Accessed 7 September 2021]. Geospatial World. 2021. What is LiDAR technology and how does it work?. [online] Available at: https://www.geospatialworld.net/blogs/what-is-lidar-technology-and-how-does-it-work/ [Accessed 7 September 2021]. Microdrones.com. 2021. 5 Compelling Applications for LiDAR Technology. [online] Available at: https://www.microdrones.com/en/content/5-compelling-applications-for-lidar-technology/ [Accessed 7 September 2021]. Sentech. 2021. The revealing science behind Lidar technology. [online] Available at: https://www.sentech.nl/en/sensor-technology/revealing-science-behind-lidar-technology/ [Accessed 7 September 2021]. Velodyne Lidar. 2021. What is Lidar? Learn How Lidar Works | Velodyne Lidar. [online] Available at: https://velodynelidar.com/what-is-lidar/ [Accessed 7 September 2021].","title":"LIDAR"},{"location":"electronics/Sensors/lidar/#lidar","text":"Lidar is a method for calculating distances between objects with the help of a laser and measuring the amount of time taken for the reflected light to return back.","title":"Lidar"},{"location":"electronics/Sensors/lidar/#lidar-sensor","text":"A Lidar sensor emits pulsed light waves into the surrounding environment. These pulses bounce off of obstacles and the surrounding environment and then return to the sensor. The sensor then, keeps a track of time it took for the light to bounce off and thus calculating the distance between obstacles. Repeating this process constantly creates a real-time map of the environment. As an example of how a lidar sensor calculates the distance between the sensor and an obstacle, Let\u2019s define the following variables, 1) Speed of light, \\(c = 3 \u00d7 10^8 m/s\\) 2) time taken for light to travel from the lidar sensor, hitting the obstacle and returning back to the sensor, \\(t\\) 3) Distance between the obstacle and the sensor, \\(d\\) Say that the time taken, \\(t = 5 \u00d7 10^{-8} sec\\) (Observe the order of magnitude \\(t\\) ) So, to calculate the distance \\(d\\) , we use the Newton\u2019s second law of motion \\[ S = u \\cdot t + \\frac{1}{2} \\cdot a \\cdot t^2 \\] Since, speed of light constant, replacing, \\(a = 0\\) , \\(u = c\\) , and, \\(S = d\\) we get, \\[ d = c \\cdot t \\] \\[ d = 3 \u00d7 10^8 \u00d7 5 * 10^{-8} \\] \\[ d = 15m \\] Therfore, the distance between the sensor and the obstacle is calculated to be 15 meters. This is the basic calculation that goes into calculating the distances.","title":"Lidar Sensor"},{"location":"electronics/Sensors/lidar/#types-of-lidar-systems","text":"1) Airborne Lidar - This is installed on aerial drones or vehicles like helicopters. It emits light towards the ground surface giving a fairly detailed and quick map of the terrain above which the vehicle or drone is flying. It is also used for topographic survey. 2) Terrestrial Lidar - This is generally installed on vehicles moving on the earth\u2019s surface. These give a detailed map, and can be used to make a robot or a vehicle navigate through it\u2019s evironment. It is also used for observing highways, roads and infrastructure.","title":"Types of Lidar Systems"},{"location":"electronics/Sensors/lidar/#components-of-a-basic-lidar-sensor","text":"A lidar sensor generally consists of 4 main components: 1) Light source - Generally a laser (or anything that emits light in pulses) 2) Optical components - There are multiple optical components for example, the light through the sensor, falls on a rotating/oscillating mirror so as to change the direction of light to cover a 360 view. An optical lens helps to focus light on the photodetector. 3) photodector - The light is recieved by this photodetector and the signal is processed electronically like frequency of light (for speed measurements) and the time taken for the light to bounce. 4) GPS - These sensors need a GPS system to determine the exact position and orientation of the sensor in 3D space. For a more indepth explaination of a Lidar sensor and the different factors that go into designing one, for example, the wavelength of light to use, the pulsing rate of the light or pulse repetition rate and more factors can be found here.","title":"Components of a basic Lidar Sensor"},{"location":"electronics/Sensors/lidar/#lidar-usage","text":"To implement Lidar into your ros program, these are the following steps you must follow: * Connect your Lidar sensor to a power supply, and connect a data transmitter to the Lidar sensor and the computer. * You need to give permissions to the on data input port of the computer. To check the permissions, type ls -l /dev/tty If your permissions are set properly, you should get an output like shown below. Just focus on the starting part, crw-rw-rw . If instead, it is something of the form crw-rw-- , then your permissions are not set properly. crw-rw-rw- 1 root dialout 5 , 0 Sep 6 23 :50 /dev/ttyACM0 To set permissions, (replace ACM0 with whatever your ports are) sudo chmod a+rw /dev/ttyACM0 Next, you need to download the package of your Lidar manufacturer. Following are the common packages and their github links. You need to clone these github repositories in the src directory of your catkin workspace. 1) Slamtec 2) YDLiDAR 3) Hokuyo 4) ROS SICK 5) ROS2 SICK 6) RoboSense * After you have cloned the ros packages, go into your workspace directory, catkin_make source devel/setup.bash Now just run the launch file according to your Lidar manufacturer package. For the above 6 manufacturers, run the following launch files. (If you are getting package not found error, please give appropriate permissions to the launch files using chmod). 1) Slamtec bash roslaunch rplidar_ros rplidar.launch 2) YDLiDAR bash roslaunch ydlidar lidar_view.launch 3) Hokuyo bash roslaunch urg_node urg_lidar.launch 4) ROS SICK - Read the README file in the github repo for which launch file you need for your specific model. 5) ROS2 SICK - Read the README file in the github repo for which launch file you need for your specific model. 6) RoboSense bash roslaunch rslidar_sdk start.launch For a much more detailed guide, use this link. This shows a fairly detailed explaination on how to setup your lidar to interact with ROS and display the results in rviz. It also has some examples of implementation and different repositories that would help you to code. You can also check out this link which provides a simple explaination for setting up a YDLiDAR X4 Sensor.","title":"Lidar usage"},{"location":"electronics/Sensors/lidar/#applications-of-lidar","text":"1) Surveying land - Lidar sensors can generate a cost effective solution for generating a 3D digital terrain model of remote or rough areas which are difficult to assess otherwise. (Nasa used Lidar techonology to explore mars). For more information on Airborne Lidar and Topographic survey, check out this research paper . 2) Power line inspection - Power lines span very long distances and thus make the inspection of power lines very difficult. Lidar sensors can make the inspection easier, by identifying faults before they can cause any real damage. 3) Farming and Forest research - These can be deployed to large farms to help determine how to use resources in an efficient manner and boost productivity. They can also be used to research on the impact that humans have caused on natural life in forests, as Lidar sensors can penetrate tree cover. 4) Climate and weather change - Climate scientists use Lidar to study and track changes in the atmosphere. Lidar can also be used to warn people if there is a Tsunami incoming. 5) Robotics - Lidar is used to equip robots with Mapping and navigational capabilities. For example, self driving cars.","title":"Applications of Lidar"},{"location":"electronics/Sensors/lidar/#companies-working-on-lidar-technologies","text":"1) tuSimple - works on self driving cars which is almost commercial ready. 2) AEye - Develops advanced vision hardware, software and algorithms for autonomous vehicles. 3) SiLC Technologies - Is a leading provider of highly integrated FMCW (Frequency Modulated Continuous Wave) Lidar solutions, which include their FMCW integration chip.","title":"Companies working on Lidar technologies"},{"location":"electronics/Sensors/lidar/#references-","text":"George, N., 2021. 11 Interesting LiDAR Applications. [online] Blog.cloudfactory.com. Available at: https://blog.cloudfactory.com/interesting-lidar-applications [Accessed 7 September 2021]. Geospatial World. 2021. What is LiDAR technology and how does it work?. [online] Available at: https://www.geospatialworld.net/blogs/what-is-lidar-technology-and-how-does-it-work/ [Accessed 7 September 2021]. Microdrones.com. 2021. 5 Compelling Applications for LiDAR Technology. [online] Available at: https://www.microdrones.com/en/content/5-compelling-applications-for-lidar-technology/ [Accessed 7 September 2021]. Sentech. 2021. The revealing science behind Lidar technology. [online] Available at: https://www.sentech.nl/en/sensor-technology/revealing-science-behind-lidar-technology/ [Accessed 7 September 2021]. Velodyne Lidar. 2021. What is Lidar? Learn How Lidar Works | Velodyne Lidar. [online] Available at: https://velodynelidar.com/what-is-lidar/ [Accessed 7 September 2021].","title":"References -"},{"location":"electronics/Single_board_computer/Jetsonnano/","text":"Getting Started with NVIDIA Jetson Nano The NVIDIA Jetson Nano Developer Kit is a small edge computer for AI development. The Jetson Nano Developer Kit packs a Quad-core ARM A57 CPU with a clock-rate of 1.43GHz and 4GB of low-power DDR4 Memory. The NVIDIA Jetson Nano Developer Kit is a small edge computer for AI development. The Jetson Nano Developer Kit packs a Quad-core ARM A57 CPU with a clock rate of 1.43GHz and 4GB of low-power DDR4 memory. For the connectors, it has 4x USB 3.0, 1xUSB2.0 Micro-B for powering with 5V, an HDMI and Display Port connector for connecting displays, as well as one or two camera connectors that allow you to connect a Raspberry Pi Camera. Parameter Meaning GPU 128-core Maxwell CPU Quad-core ARM A57 @ 1.43 GHz MEMORY 4 GB 64-bit LPDDR4 25.6 GB/s STORAGE microSD (not included) VIDEO ENCODER 4K @ 30 , 4x 1080p @ 30 , 9x 720p @ 30 (H.264/H.265) VIDEO DECODER 4K @ 60 , 2x 4K @ 30 , 8x 1080p @ 30 , 18x 720p @ 30 (H.264/H.265) CAMERA 2x MIPI CSI-2 DPHY lanes CONNECTIVITY Gigabit Ethernet, M.2 Key E DISPLAY HDMI and display port USB 4x USB 3.0, USB 2.0 Micro-B OTHERS GPIO, I2C, I2S, SPI, UART MECHANICAL 69 mm x 45 mm, 260-pin edge connector Requirements Besides the Jetson Nano Developer Kit, you\u2019ll also need a microSD card, a power supply (5V 2A), and an ethernet cable or WiFi adapter. microSD card The Jetson Nano uses a microSD card as a boot device and primary storage. The minimum size for the microSD card is 16GB, but I would strongly recommend getting at least 32GB. It\u2019s also essential to get a fast microSD as this will make working on the Jetson Nano a lot more fluent. Power Supply The Jetson Nano can be powered in three different ways: over USB Micro-B, Barrel Jack connector, or through the GPIO Header. To power the Jetson Nano over USB Micro-B, the power supply needs to supply 5V 2A. Unfortunately, not every power supply is capable of providing this. NVIDIA specifically recommends a 5V 2.5A power supply from Adafruit, but I use a Raspberry Pi power supply, and it works just fine. If you want to get the full performance out of the Jetson Nano, I\u2019d recommend using the Barrel Jack instead of powering over USB because you can supply 5V 4A over the Barrel Jack. Before connecting the Barrel Jack, you need to place a jumper on J48. The power jumper location can vary depending on if you have the older A02 model or, the newer B01 model. Ethernet cable or WiFi Adapter Lastly, you\u2019ll need an ethernet cable or a WiFi Adapter since the Jetson Nano doesn\u2019t come with one. For the WiFi Adapter, you can either use one that connects through USB or a PCIe WiFi Card like the Intel\u00ae Dual Band Wireless-AC 8265. Setup Before we can get started setting up a Python environment and running some deep learning demos, we have to download the Jetson Nano Developer Kit SD Card Image and flash it to the microSD card. After inserting the microSD card, you can connect the power supply, which will automatically boot up the system. When you boot the system for the first time, you\u2019ll be taken through some initial setup, including: Review and accept NVIDIA Jetson software EULA Select system language, keyboard layout, and time zone Create username, password, and computer name Log in After the initial setup, you should see the following screen: Increasing swap memory Recent releases of JetPack enable swap memory as part of the default distribution using the zram module. By default, 2GB of swap memory is enabled. To change the amount of swap memory, you can either edit the /etc/systemd/nvzramconfig.sh file directly or use the resizeSwapMemory repository from JetsonNanoHacks. git clone https://github.com/JetsonHacksNano/resizeSwapMemory cd resizeSwapMemory ./setSwapMemorySize.sh -g 4 After executing the above command, you\u2019ll have to restart the Jetson Nano for the changes to take effect. Installing prerequisites and configuring your Python environment Now that the Jetson Nano is ready to go, we will create a deep learning environment. We will start by installing all prerequisites and configuring a Python environment, and how to code remote using VSCode Remote SSH. Installing prerequisites sudo apt - get update sudo apt - get upgrade sudo apt - get install git cmake python3 - dev nano sudo apt - get install libhdf5 - serial - dev hdf5 - tools libhdf5 - dev zlib1g - dev zip libjpeg8 - dev Configuring your Python environment Next, we will configure our Python environment. This includes downloading pip3 and virtualenv. Install pip sudo apt - get install python3 - pip sudo pip3 install - U pip testresources setuptools For managing virtual environments, we\u2019ll be using virtualenv, which can be installed as below: sudo pip install virtualenv virtualenvwrapper To get virtualenv to work, we need to add the following lines to the ~/.bashrc file: # virtualenv and virtualenvwrapper export WORKON_HOME =$ HOME /. virtualenvs export VIRTUALENVWRAPPER_PYTHON =/ usr / bin / python3 source / usr / local / bin / virtualenvwrapper . sh To activate the changes, the following command must be executed: source ~/.bashrc Now we can create a virtual environment using the mkvirtualenv command. mkvirtualenv ml -p python3 workon ml","title":"Nvidia Jetson Nano"},{"location":"electronics/Single_board_computer/Jetsonnano/#getting-started-with-nvidia-jetson-nano","text":"The NVIDIA Jetson Nano Developer Kit is a small edge computer for AI development. The Jetson Nano Developer Kit packs a Quad-core ARM A57 CPU with a clock-rate of 1.43GHz and 4GB of low-power DDR4 Memory. The NVIDIA Jetson Nano Developer Kit is a small edge computer for AI development. The Jetson Nano Developer Kit packs a Quad-core ARM A57 CPU with a clock rate of 1.43GHz and 4GB of low-power DDR4 memory. For the connectors, it has 4x USB 3.0, 1xUSB2.0 Micro-B for powering with 5V, an HDMI and Display Port connector for connecting displays, as well as one or two camera connectors that allow you to connect a Raspberry Pi Camera. Parameter Meaning GPU 128-core Maxwell CPU Quad-core ARM A57 @ 1.43 GHz MEMORY 4 GB 64-bit LPDDR4 25.6 GB/s STORAGE microSD (not included) VIDEO ENCODER 4K @ 30 , 4x 1080p @ 30 , 9x 720p @ 30 (H.264/H.265) VIDEO DECODER 4K @ 60 , 2x 4K @ 30 , 8x 1080p @ 30 , 18x 720p @ 30 (H.264/H.265) CAMERA 2x MIPI CSI-2 DPHY lanes CONNECTIVITY Gigabit Ethernet, M.2 Key E DISPLAY HDMI and display port USB 4x USB 3.0, USB 2.0 Micro-B OTHERS GPIO, I2C, I2S, SPI, UART MECHANICAL 69 mm x 45 mm, 260-pin edge connector","title":"Getting Started with NVIDIA Jetson Nano"},{"location":"electronics/Single_board_computer/Jetsonnano/#requirements","text":"Besides the Jetson Nano Developer Kit, you\u2019ll also need a microSD card, a power supply (5V 2A), and an ethernet cable or WiFi adapter.","title":"Requirements"},{"location":"electronics/Single_board_computer/Jetsonnano/#microsd-card","text":"The Jetson Nano uses a microSD card as a boot device and primary storage. The minimum size for the microSD card is 16GB, but I would strongly recommend getting at least 32GB. It\u2019s also essential to get a fast microSD as this will make working on the Jetson Nano a lot more fluent.","title":"microSD card"},{"location":"electronics/Single_board_computer/Jetsonnano/#power-supply","text":"The Jetson Nano can be powered in three different ways: over USB Micro-B, Barrel Jack connector, or through the GPIO Header. To power the Jetson Nano over USB Micro-B, the power supply needs to supply 5V 2A. Unfortunately, not every power supply is capable of providing this. NVIDIA specifically recommends a 5V 2.5A power supply from Adafruit, but I use a Raspberry Pi power supply, and it works just fine. If you want to get the full performance out of the Jetson Nano, I\u2019d recommend using the Barrel Jack instead of powering over USB because you can supply 5V 4A over the Barrel Jack. Before connecting the Barrel Jack, you need to place a jumper on J48. The power jumper location can vary depending on if you have the older A02 model or, the newer B01 model.","title":"Power Supply"},{"location":"electronics/Single_board_computer/Jetsonnano/#ethernet-cable-or-wifi-adapter","text":"Lastly, you\u2019ll need an ethernet cable or a WiFi Adapter since the Jetson Nano doesn\u2019t come with one. For the WiFi Adapter, you can either use one that connects through USB or a PCIe WiFi Card like the Intel\u00ae Dual Band Wireless-AC 8265.","title":"Ethernet cable or WiFi Adapter"},{"location":"electronics/Single_board_computer/Jetsonnano/#setup","text":"Before we can get started setting up a Python environment and running some deep learning demos, we have to download the Jetson Nano Developer Kit SD Card Image and flash it to the microSD card. After inserting the microSD card, you can connect the power supply, which will automatically boot up the system. When you boot the system for the first time, you\u2019ll be taken through some initial setup, including: Review and accept NVIDIA Jetson software EULA Select system language, keyboard layout, and time zone Create username, password, and computer name Log in After the initial setup, you should see the following screen:","title":"Setup"},{"location":"electronics/Single_board_computer/Jetsonnano/#increasing-swap-memory","text":"Recent releases of JetPack enable swap memory as part of the default distribution using the zram module. By default, 2GB of swap memory is enabled. To change the amount of swap memory, you can either edit the /etc/systemd/nvzramconfig.sh file directly or use the resizeSwapMemory repository from JetsonNanoHacks. git clone https://github.com/JetsonHacksNano/resizeSwapMemory cd resizeSwapMemory ./setSwapMemorySize.sh -g 4 After executing the above command, you\u2019ll have to restart the Jetson Nano for the changes to take effect.","title":"Increasing swap memory"},{"location":"electronics/Single_board_computer/Jetsonnano/#installing-prerequisites-and-configuring-your-python-environment","text":"Now that the Jetson Nano is ready to go, we will create a deep learning environment. We will start by installing all prerequisites and configuring a Python environment, and how to code remote using VSCode Remote SSH.","title":"Installing prerequisites and configuring your Python environment"},{"location":"electronics/Single_board_computer/Jetsonnano/#installing-prerequisites","text":"sudo apt - get update sudo apt - get upgrade sudo apt - get install git cmake python3 - dev nano sudo apt - get install libhdf5 - serial - dev hdf5 - tools libhdf5 - dev zlib1g - dev zip libjpeg8 - dev","title":"Installing prerequisites"},{"location":"electronics/Single_board_computer/Jetsonnano/#configuring-your-python-environment","text":"Next, we will configure our Python environment. This includes downloading pip3 and virtualenv.","title":"Configuring your Python environment"},{"location":"electronics/Single_board_computer/Jetsonnano/#install-pip","text":"sudo apt - get install python3 - pip sudo pip3 install - U pip testresources setuptools For managing virtual environments, we\u2019ll be using virtualenv, which can be installed as below: sudo pip install virtualenv virtualenvwrapper To get virtualenv to work, we need to add the following lines to the ~/.bashrc file: # virtualenv and virtualenvwrapper export WORKON_HOME =$ HOME /. virtualenvs export VIRTUALENVWRAPPER_PYTHON =/ usr / bin / python3 source / usr / local / bin / virtualenvwrapper . sh To activate the changes, the following command must be executed: source ~/.bashrc Now we can create a virtual environment using the mkvirtualenv command. mkvirtualenv ml -p python3 workon ml","title":"Install pip"},{"location":"electronics/Single_board_computer/Raspberrypi/","text":"Getting Started with Raspberry Pi Things You will Need Raspberry Pi 4 B [In this guide] A 15W USB-C power supply \u2013 we recommend the official Raspberry Pi USB-C Power Supply Micro SD card reader for flashing Raspian OS. Micro SD card Raspberry Pi OS, installed using the Raspberry Pi Imager A keyboard , display and mouse HDMI to micro HDMI Cable to connect to display via Raspberry Pi 4\u2019s micro HDMI ports An ethernet cable (optional) Pinouts Powering Up Raspberry Pi The Raspberry Pi 4 B requires a charger that can output 5 volts and 3 amps. Most USB Type-C phone chargers don\u2019t have enough amps to get the job done, unless they have USB PD capability, but USB-C laptop chargers should all work. While it\u2019s unlikely to be a problem, note that Pi 4 models that were manufactured in 2019 or early 2020 have a bug which prevents them from charging over high-speed data cables that support USB 3.x 5 or 10 Gbps connections. Note : The Pi doesn\u2019t have a built-in power switch, so the default way to turn it on is to plug it in. However, to avoid data loss, you\u2019ll want to use the shutdown feature in your operating system (OS) before unplugging or switching it off. Headless Install for Raspberry Pi If you just want to experiment with the Pi or use it to control physical objects like lights, motors and sensors, you don\u2019t need to give it its own screen and keyboard then you have to do following steps. Step 1: Installing Raspberry Pi OS on Your microSD card Insert a microSD card into your computer your card should be 8GB or larger(preferrably 32GB). Download, install and run Raspberry Pi Imager. Click the Choose OS button, a menu will appears. Select Raspberry Pi OS (32-bit) from the OS menu. Click Choose SD card and select your card from the menu. Click Write. This process will take several minutes as Raspberry Pi Imager downloads Raspberry Pi OS and burns it to your microSD card. Note:- If you were not setting up a headless Raspberry Pi, you can just pop the card in, connect your Pi to a monitor, keyboard, power source and pointing device and boot it up. However, that\u2019s not our goal here. Write an empty text file named \u201cssh\u201d (no file extension) to the root of the directory of the card. When it sees the \u201cssh\u201d on its first boot-up, Raspberry Pi OS will automatically enable SSH (Secure Socket Shell), which will allow you to remotely access the Pi command line from your PC. Configure a network connection for your Raspberry Pi.Though you\u2019ve enabled SSH, which will let you log in and issue terminal commands, you still need a way to actually reach your Pi. You can connect via Wi-Fi / Ethernet, direct Ethernet connection or direct USB connection (Pi Zero only). Here are instructions for each. Step 2: Headless Wi-Fi / Ethernet To setup a Wi-Fi connection on your headless Raspberry Pi, create a text file called wpa_supplicant.conf, and place it in the root directory of the microSD card. You will need the following text in the file. country = US ctrl_interface = DIR =/ var / run / wpa_supplicant GROUP = netdev update_config = 1 network = { scan_ssid = 1 ssid = \"your_wifi_ssid\" psk = \"your_wifi_password\" } Change the country to \u201cGB\u201d for the UK or to another country code for a different country, and enter your actual SSID and password. Upon boot up, Raspberry Pi OS will log you into that network. However, if you\u2019re on a public Wi-Fi network that requires you to click \u201cOk\u201d on a splash page before you get Internet, this method won\u2019t work. Prefer to use Ethernet? If you plug your Raspberry Pi directly to a wired network, you should be able to access it by its name (raspberrypi or raspberrypi.local) without changing any other files. Step 3: Direct USB Connection (Pi Zero / Zero W Only) My favorite way to connect is via a direct USB connection, plugging my Pi Zero W directly into a port on my PC. This method is great, because it works no matter where you are (even if there\u2019s no available Wi-Fi), and it provides both power and a connection to your Pi, over a single cable. However, you can only do this on a Pi Zero or Zero W. Open the file config.txt in the root directory of the micro SD card, and add the line dtoverlay=dwc2 to the very bottom of the file and save. Open cmdline.txt and add the text modules-load=dwc2,g_ether after the word rootwait, and save the file. There are no linebreaks in this file. Download and install Bonjour Print Services(opens in new tab) from apple.com (if you have Windows). It seems strange that you would need an Apple program to access a Pi from Windows, but this helps your PC see the Pi. Ignore the name; you\u2019re not using this for printing. Connect the micro USB cable to the port labeled \u201cUSB\u201d on the Pi Zero. This will not work if you connect to the port labeled \u201cPWR.\u201d However, the \u201cUSB\u201d port will also supply power to your Pi, so you don\u2019t need to connect a dedicated power wire. Step 4: Direct Ethernet Connection If your PC has a spare Ethernet port or you have an Ethernet-to-USB dongle, you can use a network cable to go directly from your Pi to your computer. Just make sure that you have Bonjour installed on your PC and SSH enabled on the Pi (see above). Then, you can just connect the two devices over Ethernet. If you want the Raspberry Pi to get its Internet connection from your PC over the Ethernet port, you need to do the following in Windows 10: Navigate to the Network Connections menu, which is part of the old-school Control Panel. You can get to this screen by going to Settings->Network & Internet->Wi-Fi and then clicking \u201cChange Adapter Settings\u201d on the right side of the screen. This works whether you are sharing an Internet connection that comes to your PC from Wi-Fi or from Ethernet. Right-click on the adapter that\u2019s connected to the Internet, and select properties. Enable \u201cAllow other network users to connect\u201d on the \u201cSharing\u201d tab. Select the Ethernet port that is connected to the Raspberry Pi from the \u201cHome networking connection\u201d menu, and click Ok. Step 5: Connecting via SSH After you have the Pi connected to your network or directly to your PC, you\u2019ll need to establish an SSH connection. Download and install Putty if you don\u2019t already have it. Putty is the leading SSH client for Windows. Enter raspberrypi or raspberrypi.local as the address you wish to connect to in Putty, and click Open. You usually need to add the .local if the Pi is directly connected to your PC via USB or Ethernet cable. Click Ok if you get a security warning alert. It\u2019s not a problem. Enter pi as your username and raspberry as your password. You may want to change these later. Now you\u2019re connected at the command prompt, but if you want to access the GUI, complete with a desktop and floating windows, you\u2019ll need to enable VNC. Step 6: Enabling and Connecting over VNC Enter sudo raspi-config at the command prompt.A configuration app opens. Select Interfacing Options (number 5 on the list). Select VNC (number 3 on the menu). Select Yes. Hit Enter to acknowledge the VNC server is enabled. Select Finish On your PC: Download, install and launch VNC Viewer. Select New connection from the File menu. Enter raspberry.local in the \u201cVNC Server\u201d field. If this does not work, try again with the name \u201craspberrypi\u201d without .local. Click Ok. Double-click on the connection icon to connect. Click Ok if you are shown a security warning. Enter the Pi\u2019s username and password when prompted. The defaults are username: pi and password: raspberry. Click Ok. Your Raspberry Pi desktop will then appear in a window on your main computer\u2019s desktop. You\u2019ll be able to control everything from there.","title":"Raspberry Pi"},{"location":"electronics/Single_board_computer/Raspberrypi/#getting-started-with-raspberry-pi","text":"","title":"Getting Started with Raspberry Pi"},{"location":"electronics/Single_board_computer/Raspberrypi/#things-you-will-need","text":"Raspberry Pi 4 B [In this guide] A 15W USB-C power supply \u2013 we recommend the official Raspberry Pi USB-C Power Supply Micro SD card reader for flashing Raspian OS. Micro SD card Raspberry Pi OS, installed using the Raspberry Pi Imager A keyboard , display and mouse HDMI to micro HDMI Cable to connect to display via Raspberry Pi 4\u2019s micro HDMI ports An ethernet cable (optional)","title":"Things You will Need"},{"location":"electronics/Single_board_computer/Raspberrypi/#pinouts","text":"","title":"Pinouts"},{"location":"electronics/Single_board_computer/Raspberrypi/#powering-up-raspberry-pi","text":"The Raspberry Pi 4 B requires a charger that can output 5 volts and 3 amps. Most USB Type-C phone chargers don\u2019t have enough amps to get the job done, unless they have USB PD capability, but USB-C laptop chargers should all work. While it\u2019s unlikely to be a problem, note that Pi 4 models that were manufactured in 2019 or early 2020 have a bug which prevents them from charging over high-speed data cables that support USB 3.x 5 or 10 Gbps connections. Note : The Pi doesn\u2019t have a built-in power switch, so the default way to turn it on is to plug it in. However, to avoid data loss, you\u2019ll want to use the shutdown feature in your operating system (OS) before unplugging or switching it off.","title":"Powering Up Raspberry Pi"},{"location":"electronics/Single_board_computer/Raspberrypi/#headless-install-for-raspberry-pi","text":"If you just want to experiment with the Pi or use it to control physical objects like lights, motors and sensors, you don\u2019t need to give it its own screen and keyboard then you have to do following steps. Step 1: Installing Raspberry Pi OS on Your microSD card Insert a microSD card into your computer your card should be 8GB or larger(preferrably 32GB). Download, install and run Raspberry Pi Imager. Click the Choose OS button, a menu will appears. Select Raspberry Pi OS (32-bit) from the OS menu. Click Choose SD card and select your card from the menu. Click Write. This process will take several minutes as Raspberry Pi Imager downloads Raspberry Pi OS and burns it to your microSD card. Note:- If you were not setting up a headless Raspberry Pi, you can just pop the card in, connect your Pi to a monitor, keyboard, power source and pointing device and boot it up. However, that\u2019s not our goal here. Write an empty text file named \u201cssh\u201d (no file extension) to the root of the directory of the card. When it sees the \u201cssh\u201d on its first boot-up, Raspberry Pi OS will automatically enable SSH (Secure Socket Shell), which will allow you to remotely access the Pi command line from your PC. Configure a network connection for your Raspberry Pi.Though you\u2019ve enabled SSH, which will let you log in and issue terminal commands, you still need a way to actually reach your Pi. You can connect via Wi-Fi / Ethernet, direct Ethernet connection or direct USB connection (Pi Zero only). Here are instructions for each. Step 2: Headless Wi-Fi / Ethernet To setup a Wi-Fi connection on your headless Raspberry Pi, create a text file called wpa_supplicant.conf, and place it in the root directory of the microSD card. You will need the following text in the file. country = US ctrl_interface = DIR =/ var / run / wpa_supplicant GROUP = netdev update_config = 1 network = { scan_ssid = 1 ssid = \"your_wifi_ssid\" psk = \"your_wifi_password\" } Change the country to \u201cGB\u201d for the UK or to another country code for a different country, and enter your actual SSID and password. Upon boot up, Raspberry Pi OS will log you into that network. However, if you\u2019re on a public Wi-Fi network that requires you to click \u201cOk\u201d on a splash page before you get Internet, this method won\u2019t work. Prefer to use Ethernet? If you plug your Raspberry Pi directly to a wired network, you should be able to access it by its name (raspberrypi or raspberrypi.local) without changing any other files. Step 3: Direct USB Connection (Pi Zero / Zero W Only) My favorite way to connect is via a direct USB connection, plugging my Pi Zero W directly into a port on my PC. This method is great, because it works no matter where you are (even if there\u2019s no available Wi-Fi), and it provides both power and a connection to your Pi, over a single cable. However, you can only do this on a Pi Zero or Zero W. Open the file config.txt in the root directory of the micro SD card, and add the line dtoverlay=dwc2 to the very bottom of the file and save. Open cmdline.txt and add the text modules-load=dwc2,g_ether after the word rootwait, and save the file. There are no linebreaks in this file. Download and install Bonjour Print Services(opens in new tab) from apple.com (if you have Windows). It seems strange that you would need an Apple program to access a Pi from Windows, but this helps your PC see the Pi. Ignore the name; you\u2019re not using this for printing. Connect the micro USB cable to the port labeled \u201cUSB\u201d on the Pi Zero. This will not work if you connect to the port labeled \u201cPWR.\u201d However, the \u201cUSB\u201d port will also supply power to your Pi, so you don\u2019t need to connect a dedicated power wire. Step 4: Direct Ethernet Connection If your PC has a spare Ethernet port or you have an Ethernet-to-USB dongle, you can use a network cable to go directly from your Pi to your computer. Just make sure that you have Bonjour installed on your PC and SSH enabled on the Pi (see above). Then, you can just connect the two devices over Ethernet. If you want the Raspberry Pi to get its Internet connection from your PC over the Ethernet port, you need to do the following in Windows 10: Navigate to the Network Connections menu, which is part of the old-school Control Panel. You can get to this screen by going to Settings->Network & Internet->Wi-Fi and then clicking \u201cChange Adapter Settings\u201d on the right side of the screen. This works whether you are sharing an Internet connection that comes to your PC from Wi-Fi or from Ethernet. Right-click on the adapter that\u2019s connected to the Internet, and select properties. Enable \u201cAllow other network users to connect\u201d on the \u201cSharing\u201d tab. Select the Ethernet port that is connected to the Raspberry Pi from the \u201cHome networking connection\u201d menu, and click Ok. Step 5: Connecting via SSH After you have the Pi connected to your network or directly to your PC, you\u2019ll need to establish an SSH connection. Download and install Putty if you don\u2019t already have it. Putty is the leading SSH client for Windows. Enter raspberrypi or raspberrypi.local as the address you wish to connect to in Putty, and click Open. You usually need to add the .local if the Pi is directly connected to your PC via USB or Ethernet cable. Click Ok if you get a security warning alert. It\u2019s not a problem. Enter pi as your username and raspberry as your password. You may want to change these later. Now you\u2019re connected at the command prompt, but if you want to access the GUI, complete with a desktop and floating windows, you\u2019ll need to enable VNC. Step 6: Enabling and Connecting over VNC Enter sudo raspi-config at the command prompt.A configuration app opens. Select Interfacing Options (number 5 on the list). Select VNC (number 3 on the menu). Select Yes. Hit Enter to acknowledge the VNC server is enabled. Select Finish On your PC: Download, install and launch VNC Viewer. Select New connection from the File menu. Enter raspberry.local in the \u201cVNC Server\u201d field. If this does not work, try again with the name \u201craspberrypi\u201d without .local. Click Ok. Double-click on the connection icon to connect. Click Ok if you are shown a security warning. Enter the Pi\u2019s username and password when prompted. The defaults are username: pi and password: raspberry. Click Ok. Your Raspberry Pi desktop will then appear in a window on your main computer\u2019s desktop. You\u2019ll be able to control everything from there.","title":"Headless Install for Raspberry Pi"},{"location":"mechanical/Forward%20and%20Inverse%20Kinematics/","text":"Forward Kinematics The forward kinematics problem for a serial-chain manipulator is to find the position and orientation of the end-effector relative to the base given the positions of all of the joints and the values of all of the geometric link parameters. Often, a frame fixed in the end-effector is referred to as the tool frame, and while fixed in the final link N, it in general has a constant offset in both position and orientation from frame N. Likewise, a station frame is often located in the base to establish the location of the task to be performed. This frame generally has a constant offset in its pose relative to frame 0, which is also fixed in the base. In practice, the forward kinematics problem is solved by calculating the transformation between a coordinate frame fixed in the end-effector and another coordinate frame fixed in the base, i.e., between the tool and station frames. This is straightforward for a serial chain since the transformation describing the position of the end-effector relative to the base is obtained by simply concatenating transformations between frames fixed in adjacent links of the chain. Inverse Kinematics The inverse kinematics problem for a serial-chain manipulator is to find the values of the joint positions given the position and orientation of the end-effector relative to the base and the values of all of the geometric link parameters. Once again, this is a simplified statement applying only to serial chains. A more general statement is: given the relative positions and orientations of two members of a mechanism, find the values of all of the joint positions. This amounts to finding all of the joint positions given the homogeneous transformation between the two members of interest. When solving the inverse problem, we often have to choose one solution from a number of valid solutions. There are also degenerate cases with an infinite number of solutions Some solutions of the inverse mapping may not be physically realizable. This is due to manipulators having physical joint limits that prevent the mechanism from achieving certain joint configurations that may be solutions to the inverse kinematics problem (e.g. a joint may not have a full 360 degree motion) To get a more detailed idea of solving inverse and forward kinematics problems for robotic system do checkout this 3 part video series from milfordrobotics Part-1 | Part-2 | Part-3","title":"Forward and Inverse Kinematics"},{"location":"mechanical/Forward%20and%20Inverse%20Kinematics/#forward-kinematics","text":"The forward kinematics problem for a serial-chain manipulator is to find the position and orientation of the end-effector relative to the base given the positions of all of the joints and the values of all of the geometric link parameters. Often, a frame fixed in the end-effector is referred to as the tool frame, and while fixed in the final link N, it in general has a constant offset in both position and orientation from frame N. Likewise, a station frame is often located in the base to establish the location of the task to be performed. This frame generally has a constant offset in its pose relative to frame 0, which is also fixed in the base. In practice, the forward kinematics problem is solved by calculating the transformation between a coordinate frame fixed in the end-effector and another coordinate frame fixed in the base, i.e., between the tool and station frames. This is straightforward for a serial chain since the transformation describing the position of the end-effector relative to the base is obtained by simply concatenating transformations between frames fixed in adjacent links of the chain.","title":"Forward Kinematics"},{"location":"mechanical/Forward%20and%20Inverse%20Kinematics/#inverse-kinematics","text":"The inverse kinematics problem for a serial-chain manipulator is to find the values of the joint positions given the position and orientation of the end-effector relative to the base and the values of all of the geometric link parameters. Once again, this is a simplified statement applying only to serial chains. A more general statement is: given the relative positions and orientations of two members of a mechanism, find the values of all of the joint positions. This amounts to finding all of the joint positions given the homogeneous transformation between the two members of interest. When solving the inverse problem, we often have to choose one solution from a number of valid solutions. There are also degenerate cases with an infinite number of solutions Some solutions of the inverse mapping may not be physically realizable. This is due to manipulators having physical joint limits that prevent the mechanism from achieving certain joint configurations that may be solutions to the inverse kinematics problem (e.g. a joint may not have a full 360 degree motion) To get a more detailed idea of solving inverse and forward kinematics problems for robotic system do checkout this 3 part video series from milfordrobotics Part-1 | Part-2 | Part-3","title":"Inverse Kinematics"},{"location":"mechanical/Gears/","text":"Gears What are Gears? Gears are defined as toothed element which are used for transmitting rotary motion from one shaft to another. Gears are most often used in transmissions to convert an electric motor\u2019s high speed and low torque to a shaft\u2019s requirements for low speed high torque. Gears essentially allow positive engagement between Teeth, so high forces can be transmitted while still undergoing essentially rolling contact. Gears do not depend on friction as belt drives and do best when friction is minimized. The motion and power transmitted by gears is kinematically equivalent to that transmitted by friction wheels or discs. (Transmission of Power) In order to avoid the slipping, a number of projections (called teeth) as shown in Fig. (b), are provided on the periphery of the wheel A, which will fit into the corresponding recesses on the periphery of the wheel B. A friction wheel with the teeth cut on it is known as toothed wheel or gear. The usual connection to show the toothed wheels is by their pitch circles Advantages and Disadvantages Advantages It transmits exact velocity ratio. It may be used to transmit large power. It has high efficiency. It has reliable service. It has compact layout. Disadvantages The manufacture of gears require special tools and equipment. The error in cutting teeth may cause vibrations and noise during operation. Types of Gears According to the position of axes of the shaft Parallel: Spur gear, Helical gear, Rack and Pinion Intersecting: Bevel Gear Non Intersecting and Non Parallel: Worm and Worm Gears According to the periphery velocity Low Velocity Medium Velocity High Velocity According to the type of gearing External Gearing Internal Gearing Rack and Pinion According to the position of teeth on surface Straight Inclined Curved Spur Gear Spur gears are a type of cylindrical gear, with shafts that are parallel and coplanar, and teeth that are straight and oriented parallel to the shafts. They\u2019re arguably the simplest and most common type of gear \u2013 easy to manufacture and suitable for a wide range of applications. The teeth of a spur gear have an involute profile and mesh one tooth at a time. The involute form means that spur gears only produce radial forces (no axial forces), but the method of tooth meshing causes high stress on the gear teeth and high noise production. Because of this, spur gears are typically used for lower speed applications, although they can be used at almost any speed. Spur gears are generally seen as best for applications that require speed reduction and torque multiplication, such as ball mills and crushing equipment. Examples of high-speed applications that use spur gears \u2013 despite their high noise levels \u2013 include consumer appliances such as washing machines and blenders. And while noise limits the use of spur gears in passenger automobiles, they are often used in aircraft engines, trains, and even bicycles. Helical Gear The teeth of a helical gear are set at an angle (relative to axis of the gear) and take the shape of a helix. This allows the teeth to mesh gradually, starting as point contact and developing into line contact as engagement progresses. One of the most noticeable benefits of helical gears over spur gears is less noise, especially at medium- to high-speeds. Also, with helical gears, multiple teeth are always in mesh, which means less load on each individual tooth. This results in a smoother transition of forces from one tooth to the next, so that vibrations, shock loads, and wear are reduced. One interesting thing about helical gears is that if the angles of the gear teeth are correct, they can be mounted on perpendicular shafts, adjusting the rotation angle by 90 degrees. Helical gears are often the default choice in applications that are suitable for spur gears but have non-parallel shafts. They are also used in applications that require high speeds or high loading. And regardless of the load or speed, they generally provide smoother, quieter operation than spur gears. Bevel Gear Bevel gears are gears where the axes of the two shafts intersect and the tooth-bearing faces of the gears themselves are conically shaped. Bevel gears are most often mounted on shafts that are 90 degrees apart, but can be designed to work at other angles as well. The pitch surface of bevel gears is a cone. There are several types of bevel gears based on the shape of their teeth. Straight They have conical pitch surface and teeth are straight and tapering towards apex. They are useful to verify the transmission of the motion that is generated between axes that intersect within one same plane, almost always at a 90-degree angle. Straight bevel gears have many uses in watches, dentist drills, hand drills and vending machines. Spiral They have curved teeth at an angle allowing tooth contact to be gradual and smooth and operate at very steep planes. Spiral bevel gears provide a high level of control over the way in which teeth mesh, and their design allows for certain mounting deflections without excessively increasing the load on either end of the teeth. They can be used at high speeds, and are usually employed in motorcycle and bicycle gears. Hypoid These are similar to spiral bevel, but the pitch surfaces are hyberbolic and not conical. The pinion can be offset above or below the gear center, thus allowing larger pinion diameter, longer life, and smoother mesh. In addition to being used in industrial machinery, they are commonly used in the automotive industry, where it is used in rear-wheel drive vehicles to connect the driveshaft with the wheels. Worm Gears Worm gears are constructed of a worm and a gear (sometimes referred to as a worm wheel), with non-parallel, non-intersecting shafts oriented 90 degrees to each other. The worm is analogous to a screw with a V-type thread, and the gear is analogous to a spur gear. The worm is typically the driving component, with the worm\u2019s thread advancing the teeth of the gear. The primary benefit of worm gears is their ability to provide high reduction ratios (like 20:1 and even up to 300:1 or greater) and correspondingly high torque multiplication. They can also be used as speed reducers in low- to medium-speed applications. And, because their reduction ratio is based on the number of gear teeth alone, they are more compact than other types of gears. Worm gears are used widely in material handling and transportation machinery, machine tools, automobiles etc. Herringbone Gear The herringbone gear consists of two sets of gear teeth on the same gear, one right hand and one left hand. Having both hands of gear teeth, causes the thrust of one set to cancel out the thrust of the other. It is used for transmitting power between parallel shafts. It was developed to overcome the disadvantage of the high-end thrust that is present with single-helical gears. Also another advantage of this gear type is quiet, smooth operation at higher speeds. They are mostly used on heavy machinery. Rack and Pinion A rack and pinion drive system consists of a rack (or a \u201clinear gear\u201d) and a pinion (or \u201ccircular gear\u201d), which operate to convert rotational motion into linear motion. A rack and pinion drive can use both straight and helical gears. These systems provide high-speed travel over extremely long lengths and are frequently used in large gantry systems for material handling, machining, welding and assembly, especially in the automotive, machine tool, and packaging industries. Planetary Gear A planetary gear set is made up of three types of gears; a sun gear, planet gears, and a ring gear. The sun gear is located at the center, and transmits torque to the planet gears which are typically mounted on a moveable carrier. The planet gears orbit around the sun gear and mesh with an outer ring gear. Planetary gear systems can vary in complexity from very simple to intricate compound systems, depending on the application. Planetary gear systems are able to produce a lot of torque because the load is shared among multiple planet gears. This arrangement also creates more contact surfaces and a larger contact area between the gears than a traditional parallel axis gear system. Because of this, in the load is more evenly distributed and therefore the gears are more resistant to damage. Planetary gears are often used when space and weight are an issue, but a large amount of speed reduction and torque are needed. This requirement applies to a variety of industries, including tractors and construction equipment where a large amount of torque is needed to drive the wheels. Other places you will find planetary gear sets include turbine engines, automatic transmissions, and even electric screwdrivers.","title":"Gears"},{"location":"mechanical/Gears/#gears","text":"","title":"Gears"},{"location":"mechanical/Gears/#what-are-gears","text":"Gears are defined as toothed element which are used for transmitting rotary motion from one shaft to another. Gears are most often used in transmissions to convert an electric motor\u2019s high speed and low torque to a shaft\u2019s requirements for low speed high torque. Gears essentially allow positive engagement between Teeth, so high forces can be transmitted while still undergoing essentially rolling contact. Gears do not depend on friction as belt drives and do best when friction is minimized. The motion and power transmitted by gears is kinematically equivalent to that transmitted by friction wheels or discs. (Transmission of Power) In order to avoid the slipping, a number of projections (called teeth) as shown in Fig. (b), are provided on the periphery of the wheel A, which will fit into the corresponding recesses on the periphery of the wheel B. A friction wheel with the teeth cut on it is known as toothed wheel or gear. The usual connection to show the toothed wheels is by their pitch circles","title":"What are Gears?"},{"location":"mechanical/Gears/#advantages-and-disadvantages","text":"","title":"Advantages and Disadvantages"},{"location":"mechanical/Gears/#advantages","text":"It transmits exact velocity ratio. It may be used to transmit large power. It has high efficiency. It has reliable service. It has compact layout.","title":"Advantages"},{"location":"mechanical/Gears/#disadvantages","text":"The manufacture of gears require special tools and equipment. The error in cutting teeth may cause vibrations and noise during operation.","title":"Disadvantages"},{"location":"mechanical/Gears/#types-of-gears","text":"According to the position of axes of the shaft Parallel: Spur gear, Helical gear, Rack and Pinion Intersecting: Bevel Gear Non Intersecting and Non Parallel: Worm and Worm Gears According to the periphery velocity Low Velocity Medium Velocity High Velocity According to the type of gearing External Gearing Internal Gearing Rack and Pinion According to the position of teeth on surface Straight Inclined Curved","title":"Types of Gears"},{"location":"mechanical/Gears/#spur-gear","text":"Spur gears are a type of cylindrical gear, with shafts that are parallel and coplanar, and teeth that are straight and oriented parallel to the shafts. They\u2019re arguably the simplest and most common type of gear \u2013 easy to manufacture and suitable for a wide range of applications. The teeth of a spur gear have an involute profile and mesh one tooth at a time. The involute form means that spur gears only produce radial forces (no axial forces), but the method of tooth meshing causes high stress on the gear teeth and high noise production. Because of this, spur gears are typically used for lower speed applications, although they can be used at almost any speed. Spur gears are generally seen as best for applications that require speed reduction and torque multiplication, such as ball mills and crushing equipment. Examples of high-speed applications that use spur gears \u2013 despite their high noise levels \u2013 include consumer appliances such as washing machines and blenders. And while noise limits the use of spur gears in passenger automobiles, they are often used in aircraft engines, trains, and even bicycles.","title":"Spur Gear"},{"location":"mechanical/Gears/#helical-gear","text":"The teeth of a helical gear are set at an angle (relative to axis of the gear) and take the shape of a helix. This allows the teeth to mesh gradually, starting as point contact and developing into line contact as engagement progresses. One of the most noticeable benefits of helical gears over spur gears is less noise, especially at medium- to high-speeds. Also, with helical gears, multiple teeth are always in mesh, which means less load on each individual tooth. This results in a smoother transition of forces from one tooth to the next, so that vibrations, shock loads, and wear are reduced. One interesting thing about helical gears is that if the angles of the gear teeth are correct, they can be mounted on perpendicular shafts, adjusting the rotation angle by 90 degrees. Helical gears are often the default choice in applications that are suitable for spur gears but have non-parallel shafts. They are also used in applications that require high speeds or high loading. And regardless of the load or speed, they generally provide smoother, quieter operation than spur gears.","title":"Helical Gear"},{"location":"mechanical/Gears/#bevel-gear","text":"Bevel gears are gears where the axes of the two shafts intersect and the tooth-bearing faces of the gears themselves are conically shaped. Bevel gears are most often mounted on shafts that are 90 degrees apart, but can be designed to work at other angles as well. The pitch surface of bevel gears is a cone. There are several types of bevel gears based on the shape of their teeth. Straight They have conical pitch surface and teeth are straight and tapering towards apex. They are useful to verify the transmission of the motion that is generated between axes that intersect within one same plane, almost always at a 90-degree angle. Straight bevel gears have many uses in watches, dentist drills, hand drills and vending machines. Spiral They have curved teeth at an angle allowing tooth contact to be gradual and smooth and operate at very steep planes. Spiral bevel gears provide a high level of control over the way in which teeth mesh, and their design allows for certain mounting deflections without excessively increasing the load on either end of the teeth. They can be used at high speeds, and are usually employed in motorcycle and bicycle gears. Hypoid These are similar to spiral bevel, but the pitch surfaces are hyberbolic and not conical. The pinion can be offset above or below the gear center, thus allowing larger pinion diameter, longer life, and smoother mesh. In addition to being used in industrial machinery, they are commonly used in the automotive industry, where it is used in rear-wheel drive vehicles to connect the driveshaft with the wheels.","title":"Bevel Gear"},{"location":"mechanical/Gears/#worm-gears","text":"Worm gears are constructed of a worm and a gear (sometimes referred to as a worm wheel), with non-parallel, non-intersecting shafts oriented 90 degrees to each other. The worm is analogous to a screw with a V-type thread, and the gear is analogous to a spur gear. The worm is typically the driving component, with the worm\u2019s thread advancing the teeth of the gear. The primary benefit of worm gears is their ability to provide high reduction ratios (like 20:1 and even up to 300:1 or greater) and correspondingly high torque multiplication. They can also be used as speed reducers in low- to medium-speed applications. And, because their reduction ratio is based on the number of gear teeth alone, they are more compact than other types of gears. Worm gears are used widely in material handling and transportation machinery, machine tools, automobiles etc.","title":"Worm Gears"},{"location":"mechanical/Gears/#herringbone-gear","text":"The herringbone gear consists of two sets of gear teeth on the same gear, one right hand and one left hand. Having both hands of gear teeth, causes the thrust of one set to cancel out the thrust of the other. It is used for transmitting power between parallel shafts. It was developed to overcome the disadvantage of the high-end thrust that is present with single-helical gears. Also another advantage of this gear type is quiet, smooth operation at higher speeds. They are mostly used on heavy machinery.","title":"Herringbone Gear"},{"location":"mechanical/Gears/#rack-and-pinion","text":"A rack and pinion drive system consists of a rack (or a \u201clinear gear\u201d) and a pinion (or \u201ccircular gear\u201d), which operate to convert rotational motion into linear motion. A rack and pinion drive can use both straight and helical gears. These systems provide high-speed travel over extremely long lengths and are frequently used in large gantry systems for material handling, machining, welding and assembly, especially in the automotive, machine tool, and packaging industries.","title":"Rack and Pinion"},{"location":"mechanical/Gears/#planetary-gear","text":"A planetary gear set is made up of three types of gears; a sun gear, planet gears, and a ring gear. The sun gear is located at the center, and transmits torque to the planet gears which are typically mounted on a moveable carrier. The planet gears orbit around the sun gear and mesh with an outer ring gear. Planetary gear systems can vary in complexity from very simple to intricate compound systems, depending on the application. Planetary gear systems are able to produce a lot of torque because the load is shared among multiple planet gears. This arrangement also creates more contact surfaces and a larger contact area between the gears than a traditional parallel axis gear system. Because of this, in the load is more evenly distributed and therefore the gears are more resistant to damage. Planetary gears are often used when space and weight are an issue, but a large amount of speed reduction and torque are needed. This requirement applies to a variety of industries, including tractors and construction equipment where a large amount of torque is needed to drive the wheels. Other places you will find planetary gear sets include turbine engines, automatic transmissions, and even electric screwdrivers.","title":"Planetary Gear"},{"location":"mechanical/Introduction%20to%20Dynamics/","text":"Introduction to Dynamics For many applications with fixed-based robots we need to find a multi-body dynamics formulated as: \\[ M(q)\\ddot{q} + b(q,\\dot{q}) + g(q) = \\tau \\: + J_{c}(q)^{T}F_{c} \\] consisting of the following components: \\(M(q)\\) \\(\\epsilon\\) \\(\\mathbf{R}\\) \\(^{n_{q}Xn_{q}}\\) Generalized Mass matrix(orthogonal) \\(q, \\dot{q}, \\ddot{q}\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\) Generalized position, velocity and acceleration vectors \\(b(q, \\dot{q})\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\) Coriolis and centrifugal terms. \\(g(q)\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\) Gravitational terms. \\(\\tau\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\) External generalized forces. \\(F_{c}\\) \\(\\epsilon\\) $ \\(\\mathbf{R}^{n_{q}}\\) External Cartesian forces (e.g. from contacts) \\(J_{c}(q)\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}Xn_{q}}\\) Geometric Jacobian corresponding to the external forces. Different methods exist to compute the so-called Equations of Motion (EoM) of a given system, i.e., a closed-form mathematical model of the system dynamics. The two most common methods used in robotics are Newton-Euler method which essentially applies the principles of conservation of linear and angular momentum for all links of a robot and Lagrange Method which utilizes scalar energy-based functions over the the space of generalized coordinates which adhere to certain minimization principles, thus resulting in trajectories which automatically satisfy the kinematic constraints of the system. to understand better how problems related to dynamics in robotics are tackled do give a watch to this lecture on robot dynamics by IIT KGP Prof. Dilip Kumar Pratihar Newton-Euler Method Newton-Euler for Single Bodies a very well known formulation formed by Newton and Euler using law of angular and linear momentum is : \u200b \\(\\dot{\\mathsf{p}} _{S}\\) = \\(F_{ext,S}\\) \u200b \\(\\dot{\\mathbf{N}}_{S}\\) = \\(T_{ext}\\) where \\(F_{ext,S}\\) are the resultant external forces that act through the COG and \\(T_{ext}\\) are the resultant external torques. External forces which do not act through the COG need to be shifted to an equivalent force/moment pair of which the force acts through the COG. Newton-Euler for Multi-Body Systems When dealing with multi-body systems, a valid approach is to separate all bodies at the joints as depicted in and to consider every body as a single unit. Thereby, the constraint forces F \\(_{i}\\) at the joints must be introduced as external forces acting on each of the bodies when cut free. For all these bodies, we must then apply conservation of linear and angular momentum in all DoFs, subject to external forces (which now include the joint forces F \\(_{i}\\) , too). For a general 3D case and a fixed base, this results in a 6 \\(n_{j}\\) -dimensional systems of equations. Additionally, there are 5 \\(n_{j}\\) motion constraint due to the ideal joints. They ensure that the two connected bodies only move along the direction of the joint but don\u2019t move in all other directions that are blocked by the joint. Lagrange Method This method is centered around three fundamental concepts: The definition of generalized coordinates$ q$ and generalized velocities \\(\\dot{q}\\) , which may or may not encode the information regarding the constraints applicable to the system. . A scalar function called the Lagrangian function \\(\\mathcal{L}\\) . For mechanical systems, it is exactly the difference between the total kinetic energy \\(\\mathcal{T}\\) and the total potential energy \\(\\mathcal{U}\\) , of the system at each instant: \u200b \\(\\mathcal{L} = \\mathcal{T} - \\mathcal{U}\\) The so-called Euler-Lagrange equation, also known as the Euler-Lagrange of the second kind, which applies to the Lagrangian function \\(\\mathcal{L}\\) and to the total external generalized forces \\(\\tau\\) : \u200b \\(\\frac{d}{dt} (\\frac{\\partial{\\mathcal{L}}}{\\partial{\\dot{q}}} )\\) - \\((\\frac{\\partial{L}}{\\partial{\\dot{q}}})\\) = \\(\\tau\\) In the most general case, the Lagrangian is a function of the generalized coordinates and velocities q and q\u02d9 , and it may also have an explicit dependence on time t, hence we redefine the aforementioned scalar energy functions as \\(\\mathcal{T} = \\mathcal{T}(t, q, \\dot{q})\\) and \\(\\mathcal{U} = \\mathcal{U}(t,q)\\) , thus \\(\\mathcal{L} = \\mathcal{L}(t,q,\\dot{q})\\) . In the end, one of the most notable properties of this formulation is the capacity to eliminate all internal reaction forces of the system from the final EoM, in contrast to the Newton-Euler formulation where there they are explicitly accounted for. To get a more detailed insight on how to formulate Newton-Euler equation and Lagrange equation for different robot system check out this lecture by IIT Delhi prof S.K SAHA some of the other resources you can checkout to know more about kinematics and dynamics involved in robotics are: A Mathematical Introduction to Robotic Manipulation by Richard Murray Robot dynamics and control by Mark Spong Springer Handbook on Robotics by Oussama Khatib","title":"Introduction to Dynamics"},{"location":"mechanical/Introduction%20to%20Dynamics/#introduction-to-dynamics","text":"For many applications with fixed-based robots we need to find a multi-body dynamics formulated as: \\[ M(q)\\ddot{q} + b(q,\\dot{q}) + g(q) = \\tau \\: + J_{c}(q)^{T}F_{c} \\] consisting of the following components: \\(M(q)\\) \\(\\epsilon\\) \\(\\mathbf{R}\\) \\(^{n_{q}Xn_{q}}\\) Generalized Mass matrix(orthogonal) \\(q, \\dot{q}, \\ddot{q}\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\) Generalized position, velocity and acceleration vectors \\(b(q, \\dot{q})\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\) Coriolis and centrifugal terms. \\(g(q)\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\) Gravitational terms. \\(\\tau\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}}\\) External generalized forces. \\(F_{c}\\) \\(\\epsilon\\) $ \\(\\mathbf{R}^{n_{q}}\\) External Cartesian forces (e.g. from contacts) \\(J_{c}(q)\\) \\(\\epsilon\\) \\(\\mathbf{R}^{n_{q}Xn_{q}}\\) Geometric Jacobian corresponding to the external forces. Different methods exist to compute the so-called Equations of Motion (EoM) of a given system, i.e., a closed-form mathematical model of the system dynamics. The two most common methods used in robotics are Newton-Euler method which essentially applies the principles of conservation of linear and angular momentum for all links of a robot and Lagrange Method which utilizes scalar energy-based functions over the the space of generalized coordinates which adhere to certain minimization principles, thus resulting in trajectories which automatically satisfy the kinematic constraints of the system. to understand better how problems related to dynamics in robotics are tackled do give a watch to this lecture on robot dynamics by IIT KGP Prof. Dilip Kumar Pratihar","title":"Introduction to Dynamics"},{"location":"mechanical/Introduction%20to%20Dynamics/#newton-euler-method","text":"","title":"Newton-Euler Method"},{"location":"mechanical/Introduction%20to%20Dynamics/#newton-euler-for-single-bodies","text":"a very well known formulation formed by Newton and Euler using law of angular and linear momentum is : \u200b \\(\\dot{\\mathsf{p}} _{S}\\) = \\(F_{ext,S}\\) \u200b \\(\\dot{\\mathbf{N}}_{S}\\) = \\(T_{ext}\\) where \\(F_{ext,S}\\) are the resultant external forces that act through the COG and \\(T_{ext}\\) are the resultant external torques. External forces which do not act through the COG need to be shifted to an equivalent force/moment pair of which the force acts through the COG.","title":"Newton-Euler for Single Bodies"},{"location":"mechanical/Introduction%20to%20Dynamics/#newton-euler-for-multi-body-systems","text":"When dealing with multi-body systems, a valid approach is to separate all bodies at the joints as depicted in and to consider every body as a single unit. Thereby, the constraint forces F \\(_{i}\\) at the joints must be introduced as external forces acting on each of the bodies when cut free. For all these bodies, we must then apply conservation of linear and angular momentum in all DoFs, subject to external forces (which now include the joint forces F \\(_{i}\\) , too). For a general 3D case and a fixed base, this results in a 6 \\(n_{j}\\) -dimensional systems of equations. Additionally, there are 5 \\(n_{j}\\) motion constraint due to the ideal joints. They ensure that the two connected bodies only move along the direction of the joint but don\u2019t move in all other directions that are blocked by the joint.","title":"Newton-Euler for Multi-Body Systems"},{"location":"mechanical/Introduction%20to%20Dynamics/#lagrange-method","text":"This method is centered around three fundamental concepts: The definition of generalized coordinates$ q$ and generalized velocities \\(\\dot{q}\\) , which may or may not encode the information regarding the constraints applicable to the system. . A scalar function called the Lagrangian function \\(\\mathcal{L}\\) . For mechanical systems, it is exactly the difference between the total kinetic energy \\(\\mathcal{T}\\) and the total potential energy \\(\\mathcal{U}\\) , of the system at each instant: \u200b \\(\\mathcal{L} = \\mathcal{T} - \\mathcal{U}\\) The so-called Euler-Lagrange equation, also known as the Euler-Lagrange of the second kind, which applies to the Lagrangian function \\(\\mathcal{L}\\) and to the total external generalized forces \\(\\tau\\) : \u200b \\(\\frac{d}{dt} (\\frac{\\partial{\\mathcal{L}}}{\\partial{\\dot{q}}} )\\) - \\((\\frac{\\partial{L}}{\\partial{\\dot{q}}})\\) = \\(\\tau\\) In the most general case, the Lagrangian is a function of the generalized coordinates and velocities q and q\u02d9 , and it may also have an explicit dependence on time t, hence we redefine the aforementioned scalar energy functions as \\(\\mathcal{T} = \\mathcal{T}(t, q, \\dot{q})\\) and \\(\\mathcal{U} = \\mathcal{U}(t,q)\\) , thus \\(\\mathcal{L} = \\mathcal{L}(t,q,\\dot{q})\\) . In the end, one of the most notable properties of this formulation is the capacity to eliminate all internal reaction forces of the system from the final EoM, in contrast to the Newton-Euler formulation where there they are explicitly accounted for. To get a more detailed insight on how to formulate Newton-Euler equation and Lagrange equation for different robot system check out this lecture by IIT Delhi prof S.K SAHA some of the other resources you can checkout to know more about kinematics and dynamics involved in robotics are: A Mathematical Introduction to Robotic Manipulation by Richard Murray Robot dynamics and control by Mark Spong Springer Handbook on Robotics by Oussama Khatib","title":"Lagrange Method"},{"location":"mechanical/Joint%20Kinematics/","text":"Joint Kinematics The links that compose the robotic mechanism are assumed to be perfectly rigid bodies having surfaces that are geometrically perfect in both position and shape. Accordingly, these rigid bodies are connected together at joints where their idealized surfaces are in ideal contact without any clearance between them. The respective geometries of these surfaces in contact determine the freedom of motion between the two links, or the joint kinematics. Revolute The most general form of a revolute joint, often abbreviated as R and sometimes referred to colloquially as a hinge or pin joint, is a lower pair composed of two congruent surfaces of revolution. The surfaces are the same except one of them is an external surface, convex in any plane normal to the axis of revolution, and one is an internal surface, concave in any plane normal to the axis. The position of one body relative to the other may be expressed as the angle between two lines normal to the joint axis, one fixed in each body. Thus, the joint has one degree of freedom (DOF). Prismatic The most general form of a prismatic joint, often abbreviated as P and sometimes referred colloquially as a sliding joint, is a lower pair formed from two congruent general cylindrical surfaces. A prismatic joint permits only sliding of one of the members joined relative to the other along the direction of extrusion. The position of one body relative to the other is determined by the distance between two points on a line parallel to the direction of sliding, with one point fixed in each body. Thus, this joint also has one degree of freedom. Helical The most general form of a helical joint, often abbreviated as H and sometimes referred to colloquially as a screw joint, is a lower pair formed from two helicoidal surfaces formed by extruding any curve along a helical path. The simple example is a bolt and nut wherein the basic generating curve is a pair of straight lines. Other types of joints include Planar, Spherical , Cylindrical , etc. 6-DOF Joint The motion of two bodies not jointed together can be modeled as a six-degree-of-freedom joint that introduces no constraints. This is particularly useful for mobile robots, such as aircraft, that make at most intermittent contact with the ground, and thus, a body in free motion relative to the fixed frame is termed a floating base. Such a free motion joint model enables the position and orientation of a floating base in space to be expressed with six joint variables. Geometric Representation The geometry of a robotic mechanism is conveniently defined by attaching coordinate frames to each link. While these frames could be located arbitrarily, it is advantageous both for consistency and computational efficiency to adhere to a convention for locating the frames on the links. A commonly used convention for selecting frames of reference in robotic applications is the Denavit-Hartenberg, or D-H convention. In this convention, each homogeneous transformation \\(A_{i}\\) is represented as a product of four basic transformations where the four quantities \\(\\theta_{i} , a_{i} , d_{i} , \\alpha_{i}\\) are parameters associated with link i and joint i. The four parameters \\(a_{i} ,\\alpha_{i} ,d_{i} , and \\: \\theta_{i}\\) in are generally given the names link length, link twist, link offset, and joint angle, respectively, three of the above four quantities are constant for a given link, while the fourth parameter, \\(\\theta i\\) for a revolute joint and \\(d_{i}\\) for a prismatic joint, is the joint variable. Check out this video to know more about how to use DH parameters for geometric representation or go here for know about DH notation in more detail.","title":"Joint Kinematics"},{"location":"mechanical/Joint%20Kinematics/#joint-kinematics","text":"The links that compose the robotic mechanism are assumed to be perfectly rigid bodies having surfaces that are geometrically perfect in both position and shape. Accordingly, these rigid bodies are connected together at joints where their idealized surfaces are in ideal contact without any clearance between them. The respective geometries of these surfaces in contact determine the freedom of motion between the two links, or the joint kinematics.","title":"Joint Kinematics"},{"location":"mechanical/Joint%20Kinematics/#revolute","text":"The most general form of a revolute joint, often abbreviated as R and sometimes referred to colloquially as a hinge or pin joint, is a lower pair composed of two congruent surfaces of revolution. The surfaces are the same except one of them is an external surface, convex in any plane normal to the axis of revolution, and one is an internal surface, concave in any plane normal to the axis. The position of one body relative to the other may be expressed as the angle between two lines normal to the joint axis, one fixed in each body. Thus, the joint has one degree of freedom (DOF).","title":"Revolute"},{"location":"mechanical/Joint%20Kinematics/#prismatic","text":"The most general form of a prismatic joint, often abbreviated as P and sometimes referred colloquially as a sliding joint, is a lower pair formed from two congruent general cylindrical surfaces. A prismatic joint permits only sliding of one of the members joined relative to the other along the direction of extrusion. The position of one body relative to the other is determined by the distance between two points on a line parallel to the direction of sliding, with one point fixed in each body. Thus, this joint also has one degree of freedom.","title":"Prismatic"},{"location":"mechanical/Joint%20Kinematics/#helical","text":"The most general form of a helical joint, often abbreviated as H and sometimes referred to colloquially as a screw joint, is a lower pair formed from two helicoidal surfaces formed by extruding any curve along a helical path. The simple example is a bolt and nut wherein the basic generating curve is a pair of straight lines. Other types of joints include Planar, Spherical , Cylindrical , etc.","title":"Helical"},{"location":"mechanical/Joint%20Kinematics/#6-dof-joint","text":"The motion of two bodies not jointed together can be modeled as a six-degree-of-freedom joint that introduces no constraints. This is particularly useful for mobile robots, such as aircraft, that make at most intermittent contact with the ground, and thus, a body in free motion relative to the fixed frame is termed a floating base. Such a free motion joint model enables the position and orientation of a floating base in space to be expressed with six joint variables.","title":"6-DOF Joint"},{"location":"mechanical/Joint%20Kinematics/#geometric-representation","text":"The geometry of a robotic mechanism is conveniently defined by attaching coordinate frames to each link. While these frames could be located arbitrarily, it is advantageous both for consistency and computational efficiency to adhere to a convention for locating the frames on the links. A commonly used convention for selecting frames of reference in robotic applications is the Denavit-Hartenberg, or D-H convention. In this convention, each homogeneous transformation \\(A_{i}\\) is represented as a product of four basic transformations where the four quantities \\(\\theta_{i} , a_{i} , d_{i} , \\alpha_{i}\\) are parameters associated with link i and joint i. The four parameters \\(a_{i} ,\\alpha_{i} ,d_{i} , and \\: \\theta_{i}\\) in are generally given the names link length, link twist, link offset, and joint angle, respectively, three of the above four quantities are constant for a given link, while the fourth parameter, \\(\\theta i\\) for a revolute joint and \\(d_{i}\\) for a prismatic joint, is the joint variable. Check out this video to know more about how to use DH parameters for geometric representation or go here for know about DH notation in more detail.","title":"Geometric Representation"},{"location":"mechanical/drive_mechanism/","text":"Drive Mechanism Wheeled mobile robots may be classified in two major categories, omnidirectional and nonholonomic. Omnidirectional wheeled mobile robots typically employ either omniwheels or mecanum wheels. An omniwheel is a typical wheel augmented with rollers on its outer circumference. These rollers spin freely about axes in the plane of the wheel and tangential to the wheel\u2019s outer circumference, and they allow sideways sliding while the wheel drives forward or backward without slip in that direction. Mecanum wheels are similar except that the spin axes of the circumferential rollers are not in the plane of the wheel. The sideways sliding allowed by omniwheels and mecanum wheels ensures that there are no velocity constraints on the robot\u2019s chassis. Nonholomic wheeled robots are subject to a single Pfaffian velocity constraint i.e. they cannot move sideways or parallel to the axis of the axel. Example for a nonholomic wheeled robot is a car and despite this velocity constraint, a car can reach any \\((\\phi,x,y)\\) configuration in an obstacle-free plane. In other words, the velocity constraint cannot be integrated to an equivalent configuration constraint, and therefore it is a nonholonomic constraint. If we want to prescribe the robot\u2019s movements in the environment, we need to know how the robot variables relate to the primary variables we can control: the angular positions and velocities of the wheel shafts. Therefore, a kinematical model of the robot has to be developed. Modeling of an Omnibase Robot Generally Omni wheeled robots use either a three wheeled platform or a four wheeled platform. Each design has its own advantages and disadvantages. In a three wheel design, wheels are at \\(120^{\\circ}\\) from each other and they offers greater traction as any reactive force is distributed through only three points and the robot is well balanced even on uneven terrain. The configuration of a robot is defined in the form \\(q = (x,y,\\theta)\\) , \\(d\\) is the distance between wheels and the center of the robot \\(v_i\\) and \\(\\omega_i\\) are the linear and angular velocity of the \\(i^{th}\\) wheel respectively. \\(v, v_n\\) are the two components of the linear velocity of the robot and \\(\\omega\\) is the angular velocity. The well known kinematic model of an omnidirectional robot located a \\((x,y,\\theta)\\) can be written as \\(v_x(t) = dx(t)/dt , v_y(t) = dy(t)/dt\\) and \\(\\omega(t) = d\\theta(t)/dt\\) . For a three wheeled robot \\[ \\begin{bmatrix} v_0(t)\\\\ v_1(t)\\\\ v_2(t) \\end{bmatrix} = \\begin{bmatrix} -sin\\pi/3 & cos\\pi/3 & d\\\\ 0 & -1 & d\\\\ sin\\pi/3 & cos\\pi/3 & d \\end{bmatrix} \\begin{bmatrix} v(t)\\\\ v_n(t)\\\\ \\omega(t) \\end{bmatrix} \\] Applying the inverse kinematics is possible to obtain the equations that determine the robot speeds related the wheels speed. Solving in order of \\(v\\) , \\(v_n\\) and \\(\\omega\\) , the following can be found \\[ v(t) = (\\sqrt{3}/3)(v_2(t) - v_0(t))\\] \\[v_n(t)=(1/3)(v_2(t) +v_0(t))\u2212(2/3)v_1(t)\\] \\[\\omega(t)=(1/(3d))(v_0(t) +v_1(t) +v_2(t)) \\] Modeling of a Nonholomic Robot A nonholomic robot is modelled in differnet ways which will then dictate the drive mechanism that can be applied on the robot. Differnet drive mechanism and modelling for a nonholomic robot are: Unicycle model Differential Drive Ackermann Steering Unicycle Model The simplest wheeled mobile robot is a single upright rolling wheel, or unicycle. The configuration of a robot with a wheel of radius \\(r\\) can be written in the form \\(q = (\\phi,x,y,\\theta)\\) , where \\((x,y)\\) is the contact point, \\(\\phi\\) is the heading direction, and \\(\\theta\\) is the rolling angle of the wheel. The kinematic equations can be written as \\[ \\dot{q} = \\begin{bmatrix} \\dot{\\phi}\\\\ \\dot{x}\\\\ \\dot{y}\\\\ \\dot{\\theta} \\end{bmatrix} = \\begin{bmatrix} 0 & 1\\\\ rcos\\phi & 0\\\\ rsin\\phi & 0\\\\ 1 & 0 \\end{bmatrix} \\begin{bmatrix} u_1\\\\ u_2 \\end{bmatrix} = G(q)u = g_1(q)u_1 + g_2(q)u_2 \\] The control inputs are \\(u = (u_1,u_2)\\) , with \\(u_1\\) the wheel\u2019s forward-backward driving speed and \\(u_2\\) the heading direction turning speed. Three things to notice about these models are: (1) there is no drift - zero controls mean zero velocity; (2) the vector fields \\(g_i(q)\\) are generally functions of the configuration \\(q\\) ; and (3) \\(\\dot{q}\\) is linear in the controls. Differnetial Drive A differential drive is the most basic drive, which consists of two sets of wheels that can be driven independently. This is the most commonly used form of locomotion system used in robots as it\u2019s the simplest and easiest to implement. A differential drive robot consists of two independently driven wheels of radius \\(r\\) that rotate about the same axis, as well as one or more caster wheels, ball casters, or low-friction sliders that keep the robot horizontal. If both the wheels are driven in the same direction and speed, the robot will go in a straight line. If both wheels are turned with equal speed in opposite directions, as is clear from the diagram shown, the robot will rotate about the central point of the axis. Otherwise, depending on the speed of rotation and its direction, the center of rotation may fall anywhere on the line defined by the two contact points of the tires. Let the distance between the driven wheels be \\(2d\\) and choose the \\((x,y)\\) reference point halfway between the wheels. Writing the configuration as \\(q = (\\phi,x,y,\\theta_L,\\theta_R)\\) , where \\(\\theta_L\\) and \\(\\theta_R\\) are the rolling angles of the left and right wheels, respectively, the kinematic equations are \\[ \\dot{q} = \\begin{bmatrix} \\dot{\\phi}\\\\ \\dot{x}\\\\ \\dot{y}\\\\ \\dot{\\theta_L}\\\\ \\dot{\\theta_R} \\end{bmatrix} = \\begin{bmatrix} -r/2d & r/2d\\\\ \\frac{r}{2}cos\\phi & \\frac{r}{2}cos\\phi\\\\ \\frac{r}{2}sin\\phi & \\frac{r}{2}sin\\phi\\\\ 1 & 0\\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} u_L\\\\ u_R \\end{bmatrix} \\] where \\(u_L\\) is the angular speed of the left wheel and \\(u_R\\) that of the right. A positive angular speed of each wheel corresponds to forward motion at that wheel. While we can vary the velocity of each wheel, for the robot to perform rolling motion, the robot must rotate about a point that lies along their common left and right wheel axis. The point that the robot rotates about is known as the ICC - Instantaneous Center of Curvature. By varying the linear velocity of the wheels \\(V_R\\) and \\(V_L\\) , we can vary the radius of curvature \\(R\\) that the robot follows. Because the rate of rotation \\(\\omega\\) about the ICC must be the same for both wheels, we can write the following equations \\[ \\omega(R + d) = V_R\\] \\[\\omega(R - d) = V_L \\] A differential drive robot cannot move in the direction along the axis - this is a singularity. Differential drive vehicles are very sensitive to slight changes in velocity in each of the wheels. Small errors in the relative velocities between the wheels can affect the robot trajectory. Ackermann Steering Drawbacks of the differential drive are its reliance on a caster wheel, which performs poorly at high speeds, and difficulties in driving straight lines as this requires both motors to drive at the exact same speed. These drawbacks are mitigated by car-like mechanisms, which are driven by a single motor and can steer their front wheels. This mechanism is known as Ackermann steering. To define the configuration of the car, we ignore the rolling angles of the four wheels and write \\(q = (\\phi,x,y,\\psi)\\) , where \\((x,y)\\) is the location of the midpoint between the rear wheels, \\(\\phi\\) is the car\u2019s heading direction, and \\(\\psi\\) is the steering angle of the car, defined at a virtual wheel at the midpoint between the front wheels. The controls are the forward speed \\(v\\) of the car at its reference point and the angular speed \\(\\omega\\) of the steering angle. The car\u2019s kinematics are \\[ \\dot{q} = \\begin{bmatrix} \\dot{\\phi}\\\\ \\dot{x}\\\\ \\dot{y}\\\\ \\dot{\\psi} \\end{bmatrix} = \\begin{bmatrix} (tan\\psi)/l & 0\\\\ cos\\phi & 0\\\\ sin\\phi & 0\\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} v\\\\ \\omega \\end{bmatrix} \\] Disadvantages Of Ackermann Steering : The turning mechanism must be accurately controlled. A slight inaccuracy may cause large odometry errors The system is Non \u2013 Holonomic hence path planning is extremely difficult as well as inaccurate There are no direct directional actuators. Other type of Drive Mechanism There are many different ways in which a robot can be modelled and controlled, some other drive mechanism used in various systems are Skid Steering - The left and right wheels are driven independently. Steering is accomplished by actuating each side at a different rate or in a different direction, causing the wheels or tracks to slip, or skid, on the ground. The wheels typically have no separate steering mechanism and hold a fixed straight alignment on the body of the machine. By turning the left and right wheel pairs at different speeds, the machine turns by skidding, or dragging its fixed-orientation wheels across the ground. Synchronous Drive - This system uses synchronous rotation of its wheels to achieve motion & turns. It is made up of a system of motors. One set of which drive the wheels and the other set turns the wheels in a synchronous fashion The two sets can be directly mechanically coupled as they always move in the same direction with same speed. Articulated Drive - Similar to Ackerman Steering concept, Articulated method drives a robot by deforming the entire chassis or frame to turn instead of just the wheels. This is generally used for industrial robots where a four wheeled robot is split into two, the front part and the rear part which is connected by a vertical hinge. A motor changes the angle of front part of chassis which turns the robot in a required direction and other motor drives it. References For more details on these drive mechanisms refer Chapter 13 of the Modern Robotics - Mechanics, Planning, And Control by Kevin M. Lynch and Frank C. Park , a video playlist of the same can be found here . A video on Differential Drive mechanism from Control of Mobile Robots course by Dr. Magnus Egerstedt can be found here . More information on Designing of Ackermann Steering can be read from this paper .","title":"Drive Mechanism"},{"location":"mechanical/drive_mechanism/#drive-mechanism","text":"Wheeled mobile robots may be classified in two major categories, omnidirectional and nonholonomic. Omnidirectional wheeled mobile robots typically employ either omniwheels or mecanum wheels. An omniwheel is a typical wheel augmented with rollers on its outer circumference. These rollers spin freely about axes in the plane of the wheel and tangential to the wheel\u2019s outer circumference, and they allow sideways sliding while the wheel drives forward or backward without slip in that direction. Mecanum wheels are similar except that the spin axes of the circumferential rollers are not in the plane of the wheel. The sideways sliding allowed by omniwheels and mecanum wheels ensures that there are no velocity constraints on the robot\u2019s chassis. Nonholomic wheeled robots are subject to a single Pfaffian velocity constraint i.e. they cannot move sideways or parallel to the axis of the axel. Example for a nonholomic wheeled robot is a car and despite this velocity constraint, a car can reach any \\((\\phi,x,y)\\) configuration in an obstacle-free plane. In other words, the velocity constraint cannot be integrated to an equivalent configuration constraint, and therefore it is a nonholonomic constraint. If we want to prescribe the robot\u2019s movements in the environment, we need to know how the robot variables relate to the primary variables we can control: the angular positions and velocities of the wheel shafts. Therefore, a kinematical model of the robot has to be developed.","title":"Drive Mechanism"},{"location":"mechanical/drive_mechanism/#modeling-of-an-omnibase-robot","text":"Generally Omni wheeled robots use either a three wheeled platform or a four wheeled platform. Each design has its own advantages and disadvantages. In a three wheel design, wheels are at \\(120^{\\circ}\\) from each other and they offers greater traction as any reactive force is distributed through only three points and the robot is well balanced even on uneven terrain. The configuration of a robot is defined in the form \\(q = (x,y,\\theta)\\) , \\(d\\) is the distance between wheels and the center of the robot \\(v_i\\) and \\(\\omega_i\\) are the linear and angular velocity of the \\(i^{th}\\) wheel respectively. \\(v, v_n\\) are the two components of the linear velocity of the robot and \\(\\omega\\) is the angular velocity. The well known kinematic model of an omnidirectional robot located a \\((x,y,\\theta)\\) can be written as \\(v_x(t) = dx(t)/dt , v_y(t) = dy(t)/dt\\) and \\(\\omega(t) = d\\theta(t)/dt\\) . For a three wheeled robot \\[ \\begin{bmatrix} v_0(t)\\\\ v_1(t)\\\\ v_2(t) \\end{bmatrix} = \\begin{bmatrix} -sin\\pi/3 & cos\\pi/3 & d\\\\ 0 & -1 & d\\\\ sin\\pi/3 & cos\\pi/3 & d \\end{bmatrix} \\begin{bmatrix} v(t)\\\\ v_n(t)\\\\ \\omega(t) \\end{bmatrix} \\] Applying the inverse kinematics is possible to obtain the equations that determine the robot speeds related the wheels speed. Solving in order of \\(v\\) , \\(v_n\\) and \\(\\omega\\) , the following can be found \\[ v(t) = (\\sqrt{3}/3)(v_2(t) - v_0(t))\\] \\[v_n(t)=(1/3)(v_2(t) +v_0(t))\u2212(2/3)v_1(t)\\] \\[\\omega(t)=(1/(3d))(v_0(t) +v_1(t) +v_2(t)) \\]","title":"Modeling of an Omnibase Robot"},{"location":"mechanical/drive_mechanism/#modeling-of-a-nonholomic-robot","text":"A nonholomic robot is modelled in differnet ways which will then dictate the drive mechanism that can be applied on the robot. Differnet drive mechanism and modelling for a nonholomic robot are: Unicycle model Differential Drive Ackermann Steering","title":"Modeling of a Nonholomic Robot"},{"location":"mechanical/drive_mechanism/#unicycle-model","text":"The simplest wheeled mobile robot is a single upright rolling wheel, or unicycle. The configuration of a robot with a wheel of radius \\(r\\) can be written in the form \\(q = (\\phi,x,y,\\theta)\\) , where \\((x,y)\\) is the contact point, \\(\\phi\\) is the heading direction, and \\(\\theta\\) is the rolling angle of the wheel. The kinematic equations can be written as \\[ \\dot{q} = \\begin{bmatrix} \\dot{\\phi}\\\\ \\dot{x}\\\\ \\dot{y}\\\\ \\dot{\\theta} \\end{bmatrix} = \\begin{bmatrix} 0 & 1\\\\ rcos\\phi & 0\\\\ rsin\\phi & 0\\\\ 1 & 0 \\end{bmatrix} \\begin{bmatrix} u_1\\\\ u_2 \\end{bmatrix} = G(q)u = g_1(q)u_1 + g_2(q)u_2 \\] The control inputs are \\(u = (u_1,u_2)\\) , with \\(u_1\\) the wheel\u2019s forward-backward driving speed and \\(u_2\\) the heading direction turning speed. Three things to notice about these models are: (1) there is no drift - zero controls mean zero velocity; (2) the vector fields \\(g_i(q)\\) are generally functions of the configuration \\(q\\) ; and (3) \\(\\dot{q}\\) is linear in the controls.","title":"Unicycle Model"},{"location":"mechanical/drive_mechanism/#differnetial-drive","text":"A differential drive is the most basic drive, which consists of two sets of wheels that can be driven independently. This is the most commonly used form of locomotion system used in robots as it\u2019s the simplest and easiest to implement. A differential drive robot consists of two independently driven wheels of radius \\(r\\) that rotate about the same axis, as well as one or more caster wheels, ball casters, or low-friction sliders that keep the robot horizontal. If both the wheels are driven in the same direction and speed, the robot will go in a straight line. If both wheels are turned with equal speed in opposite directions, as is clear from the diagram shown, the robot will rotate about the central point of the axis. Otherwise, depending on the speed of rotation and its direction, the center of rotation may fall anywhere on the line defined by the two contact points of the tires. Let the distance between the driven wheels be \\(2d\\) and choose the \\((x,y)\\) reference point halfway between the wheels. Writing the configuration as \\(q = (\\phi,x,y,\\theta_L,\\theta_R)\\) , where \\(\\theta_L\\) and \\(\\theta_R\\) are the rolling angles of the left and right wheels, respectively, the kinematic equations are \\[ \\dot{q} = \\begin{bmatrix} \\dot{\\phi}\\\\ \\dot{x}\\\\ \\dot{y}\\\\ \\dot{\\theta_L}\\\\ \\dot{\\theta_R} \\end{bmatrix} = \\begin{bmatrix} -r/2d & r/2d\\\\ \\frac{r}{2}cos\\phi & \\frac{r}{2}cos\\phi\\\\ \\frac{r}{2}sin\\phi & \\frac{r}{2}sin\\phi\\\\ 1 & 0\\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} u_L\\\\ u_R \\end{bmatrix} \\] where \\(u_L\\) is the angular speed of the left wheel and \\(u_R\\) that of the right. A positive angular speed of each wheel corresponds to forward motion at that wheel. While we can vary the velocity of each wheel, for the robot to perform rolling motion, the robot must rotate about a point that lies along their common left and right wheel axis. The point that the robot rotates about is known as the ICC - Instantaneous Center of Curvature. By varying the linear velocity of the wheels \\(V_R\\) and \\(V_L\\) , we can vary the radius of curvature \\(R\\) that the robot follows. Because the rate of rotation \\(\\omega\\) about the ICC must be the same for both wheels, we can write the following equations \\[ \\omega(R + d) = V_R\\] \\[\\omega(R - d) = V_L \\] A differential drive robot cannot move in the direction along the axis - this is a singularity. Differential drive vehicles are very sensitive to slight changes in velocity in each of the wheels. Small errors in the relative velocities between the wheels can affect the robot trajectory.","title":"Differnetial Drive"},{"location":"mechanical/drive_mechanism/#ackermann-steering","text":"Drawbacks of the differential drive are its reliance on a caster wheel, which performs poorly at high speeds, and difficulties in driving straight lines as this requires both motors to drive at the exact same speed. These drawbacks are mitigated by car-like mechanisms, which are driven by a single motor and can steer their front wheels. This mechanism is known as Ackermann steering. To define the configuration of the car, we ignore the rolling angles of the four wheels and write \\(q = (\\phi,x,y,\\psi)\\) , where \\((x,y)\\) is the location of the midpoint between the rear wheels, \\(\\phi\\) is the car\u2019s heading direction, and \\(\\psi\\) is the steering angle of the car, defined at a virtual wheel at the midpoint between the front wheels. The controls are the forward speed \\(v\\) of the car at its reference point and the angular speed \\(\\omega\\) of the steering angle. The car\u2019s kinematics are \\[ \\dot{q} = \\begin{bmatrix} \\dot{\\phi}\\\\ \\dot{x}\\\\ \\dot{y}\\\\ \\dot{\\psi} \\end{bmatrix} = \\begin{bmatrix} (tan\\psi)/l & 0\\\\ cos\\phi & 0\\\\ sin\\phi & 0\\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} v\\\\ \\omega \\end{bmatrix} \\] Disadvantages Of Ackermann Steering : The turning mechanism must be accurately controlled. A slight inaccuracy may cause large odometry errors The system is Non \u2013 Holonomic hence path planning is extremely difficult as well as inaccurate There are no direct directional actuators.","title":"Ackermann Steering"},{"location":"mechanical/drive_mechanism/#other-type-of-drive-mechanism","text":"There are many different ways in which a robot can be modelled and controlled, some other drive mechanism used in various systems are Skid Steering - The left and right wheels are driven independently. Steering is accomplished by actuating each side at a different rate or in a different direction, causing the wheels or tracks to slip, or skid, on the ground. The wheels typically have no separate steering mechanism and hold a fixed straight alignment on the body of the machine. By turning the left and right wheel pairs at different speeds, the machine turns by skidding, or dragging its fixed-orientation wheels across the ground. Synchronous Drive - This system uses synchronous rotation of its wheels to achieve motion & turns. It is made up of a system of motors. One set of which drive the wheels and the other set turns the wheels in a synchronous fashion The two sets can be directly mechanically coupled as they always move in the same direction with same speed. Articulated Drive - Similar to Ackerman Steering concept, Articulated method drives a robot by deforming the entire chassis or frame to turn instead of just the wheels. This is generally used for industrial robots where a four wheeled robot is split into two, the front part and the rear part which is connected by a vertical hinge. A motor changes the angle of front part of chassis which turns the robot in a required direction and other motor drives it.","title":"Other type of Drive Mechanism"},{"location":"mechanical/drive_mechanism/#references","text":"For more details on these drive mechanisms refer Chapter 13 of the Modern Robotics - Mechanics, Planning, And Control by Kevin M. Lynch and Frank C. Park , a video playlist of the same can be found here . A video on Differential Drive mechanism from Control of Mobile Robots course by Dr. Magnus Egerstedt can be found here . More information on Designing of Ackermann Steering can be read from this paper .","title":"References"},{"location":"mechanical/intro/","text":"Introduction Designing, creating, and testing mechanical sensors and devices for a robot are all part of the mechanical side of robotics. Among many other factors that go into the development of a new robot, this includes the robot\u2019s design, kind of robot, joint mechanics, axes, heat transfer properties, mounting places, and many others.A novel robot concept and its optimum manufacturing methods are developed using CAD or other design tools.The kinematics and dynamics equations of the robot must be solved as part of mechanical design in order for robots to do any task at all.","title":"Introduction"},{"location":"mechanical/intro/#introduction","text":"Designing, creating, and testing mechanical sensors and devices for a robot are all part of the mechanical side of robotics. Among many other factors that go into the development of a new robot, this includes the robot\u2019s design, kind of robot, joint mechanics, axes, heat transfer properties, mounting places, and many others.A novel robot concept and its optimum manufacturing methods are developed using CAD or other design tools.The kinematics and dynamics equations of the robot must be solved as part of mechanical design in order for robots to do any task at all.","title":"Introduction"},{"location":"mechanical/position%20and%20orientation/","text":"POSITION AND ORIENATION REPRESENTATION Position and translation The minimum number of coordinates required to locate a body in Euclidean space is six. A coordinate frame i consists of an origin, denoted \\(O_{i}\\) and a triad of mutually orthogonal basis vectors, denoted \\((\\hat x_{i} \\hat y_{i } \\hat z_{i})\\) , that are all fixed within a particular body. The pose of a body will always be expressed relative to some other body, so it can be expressed as the pose of one coordinate frame relative to another. Similarly, rigid-body displacements can be expressed as displacements between two coordinate frames, one of which may be referred to as moving, while the other may be referred to as fixed. The position of the origin of coordinate frame i relative to coordinate frame j can be denoted by the 3 X 1 vector \\[ ^{j} \\textbf {p} _{i} = \\begin{pmatrix} ^{j} p^{x} _{i} \\\\ ^{j} p^{y} _{i} \\\\ ^{j} p^{z} _{i} \\end{pmatrix}\\] The components of this vector are the Cartesian coordinates of \\(O_{i}\\) in the j frame, which are the projections of the vector \\(^{j} \\textbf {p} _{i}\\) onto the corresponding axes. Orientation and Rotation A rotation is a displacement in which at least one point in the rigid body remains in its initial position and not all lines in the body remain parallel to their initial orientations. The orientation of coordinate frame i relative to coordinate frame j can be denoted by expressing the basis vectors . \\(( \\hat x_{i} \\hat y_{i} \\hat z_{i})\\) in terms of the basis vectors , \\(( \\hat x_{j} \\hat y_{j} \\hat z_{j})\\) .This yields, \\(( ^{j}\\hat x_{i} ^{j}\\hat y_{i} ^{j}\\hat z_{i})\\) which when written together as a 3X3 matrix is known as the rotation matrix. The components of \\(^{j}R_{i}\\) are the dot products of the basis vectors of the two coordinate frames. \\(^{j}R_{i}\\) = \\(\\begin{pmatrix} \\hat x _{i}.\\hat x _{j} & \\hat y _{i}.\\hat x _{j} & \\hat z _{i}.\\hat x _{j} \\\\ \\hat x _{i}.\\hat y _{j} & \\hat y _{i}.\\hat y _{j} & \\hat z _{i}.\\hat y _{j} \\\\ \\hat x _{i}.\\hat z _{j} & \\hat y _{i}.\\hat z _{j} & \\hat z _{i}.\\hat z _{j} \\end{pmatrix}\\) Because the basis vectors are unit vectors and the dot product of any two unit vectors is the cosine of the angle between them, the components are commonly referred to as direction cosines. An elementary rotation of frame i about the \\(z_{j}\\) axis through an angle \\(\\theta\\) is \\(R_{z}(\\theta) = \\begin{pmatrix} \\cos(\\theta) & -\\sin(\\theta) & 0\\\\ \\sin(\\theta) & \\cos(\\theta) & 0\\\\ 0 & 0 & 1\\end{pmatrix}\\) while the same rotation about \\(\\hat y_{j}\\) axis is \\(R_{Y}(\\theta) = \\begin{pmatrix} \\cos(\\theta) & 0 & \\sin(\\theta)\\\\ 0 & 1 & 0\\\\ -\\sin(\\theta) & 0 & \\cos(\\theta)\\end{pmatrix}\\) and about the axis \\(\\hat x_{j}\\) is \\(R_{X}(\\theta) = \\begin{pmatrix} 1 & 0 & 0\\\\ 0 & \\cos(\\theta) & -\\sin(\\theta)\\\\ 0 & \\sin(\\theta) & \\cos(\\theta)\\end{pmatrix}\\) Rotation matrices are combined through simple matrix multiplication such that the orientation of frame i relative to frame k can be expressed as \\(^{k}R_{i} = ^{k}R_{j} ^{j}R_{i}\\) Euler Angles For a minimal representation, the orientation of coordinate frame i relative to coordinate frame j can be denoted as a vector of three angles \\((\\alpha , \\beta , \\gamma)^{T}\\) . These angles are known as Euler angles when each represents a rotation about an axis of a moving coordinate frame. In this way, the location of the axis of each successive rotation depends upon the preceding rotation(s), so the order of the rotations must accompany the three angles to define the orientation. There are many other representations for orientation such as Fixed-Angles , Quaternions and Angle-Axis . Homogeneous Transformations With homogeneous transformations, position vectors and rotation matrices are combined together in a compact notation. Any vector \\(^{i}r\\) expressed relative to the i coordinate frame can be expressed relative to the j coordinate frame if the position and orientation of the i frame are known relative to the j frame. \\(^{j}r = ^{j}R_{i} ^{i}r + ^{j}p_{i}\\) where \\(^{j}p_{i}\\) is the position of the origin of coordinate frame i relative to coordinate frame j and \\(^{j}R_{i}\\) is the orientation of frame i relative to frame j . The above equation can be written as \\(\\begin{pmatrix} ^{j}r \\\\ 1 \\end{pmatrix}\\) = \\(\\begin{pmatrix} ^{j}R_{i} & ^{j}p_{i}\\\\ 0^{T} & 1 \\end{pmatrix}\\begin{pmatrix} ^{i}r \\\\ 1 \\end{pmatrix}\\) where \\(^{j}T_{i} = \\begin{pmatrix} ^{j}R_{i} & ^{j}p_{i}\\\\ 0^{T} & 1 \\end{pmatrix}\\) is the 4X4 homogeneous transformation matrix . Just like Rotation matrices, homogeneous transformation matrices can also be transformed using matrix cross-multiplication. \\(^{k}T_{i} = ^{k}T_{j} ^{j}T_{i}\\)","title":"Position and Orientation"},{"location":"mechanical/position%20and%20orientation/#position-and-orienation-representation","text":"","title":"POSITION AND ORIENATION REPRESENTATION"},{"location":"mechanical/position%20and%20orientation/#position-and-translation","text":"The minimum number of coordinates required to locate a body in Euclidean space is six. A coordinate frame i consists of an origin, denoted \\(O_{i}\\) and a triad of mutually orthogonal basis vectors, denoted \\((\\hat x_{i} \\hat y_{i } \\hat z_{i})\\) , that are all fixed within a particular body. The pose of a body will always be expressed relative to some other body, so it can be expressed as the pose of one coordinate frame relative to another. Similarly, rigid-body displacements can be expressed as displacements between two coordinate frames, one of which may be referred to as moving, while the other may be referred to as fixed. The position of the origin of coordinate frame i relative to coordinate frame j can be denoted by the 3 X 1 vector \\[ ^{j} \\textbf {p} _{i} = \\begin{pmatrix} ^{j} p^{x} _{i} \\\\ ^{j} p^{y} _{i} \\\\ ^{j} p^{z} _{i} \\end{pmatrix}\\] The components of this vector are the Cartesian coordinates of \\(O_{i}\\) in the j frame, which are the projections of the vector \\(^{j} \\textbf {p} _{i}\\) onto the corresponding axes.","title":"Position and translation"},{"location":"mechanical/position%20and%20orientation/#orientation-and-rotation","text":"A rotation is a displacement in which at least one point in the rigid body remains in its initial position and not all lines in the body remain parallel to their initial orientations. The orientation of coordinate frame i relative to coordinate frame j can be denoted by expressing the basis vectors . \\(( \\hat x_{i} \\hat y_{i} \\hat z_{i})\\) in terms of the basis vectors , \\(( \\hat x_{j} \\hat y_{j} \\hat z_{j})\\) .This yields, \\(( ^{j}\\hat x_{i} ^{j}\\hat y_{i} ^{j}\\hat z_{i})\\) which when written together as a 3X3 matrix is known as the rotation matrix. The components of \\(^{j}R_{i}\\) are the dot products of the basis vectors of the two coordinate frames. \\(^{j}R_{i}\\) = \\(\\begin{pmatrix} \\hat x _{i}.\\hat x _{j} & \\hat y _{i}.\\hat x _{j} & \\hat z _{i}.\\hat x _{j} \\\\ \\hat x _{i}.\\hat y _{j} & \\hat y _{i}.\\hat y _{j} & \\hat z _{i}.\\hat y _{j} \\\\ \\hat x _{i}.\\hat z _{j} & \\hat y _{i}.\\hat z _{j} & \\hat z _{i}.\\hat z _{j} \\end{pmatrix}\\) Because the basis vectors are unit vectors and the dot product of any two unit vectors is the cosine of the angle between them, the components are commonly referred to as direction cosines. An elementary rotation of frame i about the \\(z_{j}\\) axis through an angle \\(\\theta\\) is \\(R_{z}(\\theta) = \\begin{pmatrix} \\cos(\\theta) & -\\sin(\\theta) & 0\\\\ \\sin(\\theta) & \\cos(\\theta) & 0\\\\ 0 & 0 & 1\\end{pmatrix}\\) while the same rotation about \\(\\hat y_{j}\\) axis is \\(R_{Y}(\\theta) = \\begin{pmatrix} \\cos(\\theta) & 0 & \\sin(\\theta)\\\\ 0 & 1 & 0\\\\ -\\sin(\\theta) & 0 & \\cos(\\theta)\\end{pmatrix}\\) and about the axis \\(\\hat x_{j}\\) is \\(R_{X}(\\theta) = \\begin{pmatrix} 1 & 0 & 0\\\\ 0 & \\cos(\\theta) & -\\sin(\\theta)\\\\ 0 & \\sin(\\theta) & \\cos(\\theta)\\end{pmatrix}\\) Rotation matrices are combined through simple matrix multiplication such that the orientation of frame i relative to frame k can be expressed as \\(^{k}R_{i} = ^{k}R_{j} ^{j}R_{i}\\)","title":"Orientation and Rotation"},{"location":"mechanical/position%20and%20orientation/#euler-angles","text":"For a minimal representation, the orientation of coordinate frame i relative to coordinate frame j can be denoted as a vector of three angles \\((\\alpha , \\beta , \\gamma)^{T}\\) . These angles are known as Euler angles when each represents a rotation about an axis of a moving coordinate frame. In this way, the location of the axis of each successive rotation depends upon the preceding rotation(s), so the order of the rotations must accompany the three angles to define the orientation. There are many other representations for orientation such as Fixed-Angles , Quaternions and Angle-Axis .","title":"Euler Angles"},{"location":"mechanical/position%20and%20orientation/#homogeneous-transformations","text":"With homogeneous transformations, position vectors and rotation matrices are combined together in a compact notation. Any vector \\(^{i}r\\) expressed relative to the i coordinate frame can be expressed relative to the j coordinate frame if the position and orientation of the i frame are known relative to the j frame. \\(^{j}r = ^{j}R_{i} ^{i}r + ^{j}p_{i}\\) where \\(^{j}p_{i}\\) is the position of the origin of coordinate frame i relative to coordinate frame j and \\(^{j}R_{i}\\) is the orientation of frame i relative to frame j . The above equation can be written as \\(\\begin{pmatrix} ^{j}r \\\\ 1 \\end{pmatrix}\\) = \\(\\begin{pmatrix} ^{j}R_{i} & ^{j}p_{i}\\\\ 0^{T} & 1 \\end{pmatrix}\\begin{pmatrix} ^{i}r \\\\ 1 \\end{pmatrix}\\) where \\(^{j}T_{i} = \\begin{pmatrix} ^{j}R_{i} & ^{j}p_{i}\\\\ 0^{T} & 1 \\end{pmatrix}\\) is the 4X4 homogeneous transformation matrix . Just like Rotation matrices, homogeneous transformation matrices can also be transformed using matrix cross-multiplication. \\(^{k}T_{i} = ^{k}T_{j} ^{j}T_{i}\\)","title":"Homogeneous Transformations"}]}